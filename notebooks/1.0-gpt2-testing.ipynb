{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f59204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5bd785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_formatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pickle\n",
    "import os, sys\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)\n",
    "\n",
    "from db.dbv2 import Table, AugmentedTable, TrainTestTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5d50bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14993edf22844ac6a2a0a68675e51a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf7ef95397d4de9bb4085b725c69eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1efbafc7a4c4a97a2297dc57a366dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395633897e274bf19c81329dcc4e9f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bccec1e508243ada8c6b3ce3a9d1e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 21:19:21.763184: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-09 21:19:21.763427: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from src.dataset.gpt_augmentor import Augmentor\";\n",
       "                var nbb_formatted_code = \"from src.dataset.gpt_augmentor import Augmentor\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.dataset.gpt_augmentor import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe4d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f97bad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"dataset_type = \\\"committee\\\"\\n\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_formatted_code = \"dataset_type = \\\"committee\\\"\\n\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_type = \"committee\"\n",
    "\n",
    "table = Table(dataset_type)\n",
    "augmented_table = AugmentedTable(dataset_type)\n",
    "train_test_table = TrainTestTable(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ae928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed augmenting 1/2...\n",
      "Completed augmenting 2/2...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"min_sent_tokens = 8\\nmax_sent_tokens = 64\\n\\ntarget_sentences_original = table.get_target_sentences()\\ntarget_sentences = [s[1] for s in target_sentences_original]\\ncleaned_target_sentences = []\\n\\nfor s in target_sentences:\\n    if len(word_tokenize(s)) > min_sent_tokens:\\n        shortened_sentence = \\\" \\\".join(word_tokenize(s)[:max_sent_tokens])\\n        cleaned_target_sentences.append(shortened_sentence)\\n\\naugmented_segments = Augmentor.augment_gpt2(\\n    cleaned_target_sentences[:2],\\n    fast=True,\\n    # multiply by 5 to account for 5 as a max segment\\n    max_seq_word_length=max_sent_tokens * 5,\\n    verbose=True,\\n)\";\n",
       "                var nbb_formatted_code = \"min_sent_tokens = 8\\nmax_sent_tokens = 64\\n\\ntarget_sentences_original = table.get_target_sentences()\\ntarget_sentences = [s[1] for s in target_sentences_original]\\ncleaned_target_sentences = []\\n\\nfor s in target_sentences:\\n    if len(word_tokenize(s)) > min_sent_tokens:\\n        shortened_sentence = \\\" \\\".join(word_tokenize(s)[:max_sent_tokens])\\n        cleaned_target_sentences.append(shortened_sentence)\\n\\naugmented_segments = Augmentor.augment_gpt2(\\n    cleaned_target_sentences[:2],\\n    fast=True,\\n    # multiply by 5 to account for 5 as a max segment\\n    max_seq_word_length=max_sent_tokens * 5,\\n    verbose=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_sent_tokens = 8\n",
    "max_sent_tokens = 64\n",
    "\n",
    "target_sentences_original = table.get_target_sentences()\n",
    "target_sentences = [s[1] for s in target_sentences_original]\n",
    "cleaned_target_sentences = []\n",
    "\n",
    "for s in target_sentences:\n",
    "    if len(word_tokenize(s)) > min_sent_tokens:\n",
    "        shortened_sentence = \" \".join(word_tokenize(s)[:max_sent_tokens])\n",
    "        cleaned_target_sentences.append(shortened_sentence)\n",
    "\n",
    "augmented_segments = Augmentor.augment_gpt2(\n",
    "    cleaned_target_sentences[:2],\n",
    "    fast=True,\n",
    "    # multiply by 5 to account for 5 as a max segment\n",
    "    max_seq_word_length=max_sent_tokens * 5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d31dfd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"thank you very much for that question, chair. i've got to say 'yes ', in many regards. so, the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services. we developed the windscreen model—or we lifted the windscreen model. other models that are very similar have been used in our research. but, it's important to note that this model was first used by the National Institute of Mental Health and its predecessor, the Children's Mental Hospital (MHC) in England and Wales. We used this approach in other areas too, including, in a very short period of time, to develop the first comprehensive model of child mental care. The model used was based on a comprehensive assessment of mental illness and the impact it has on children. It has also been adapted for use by other health care organisations, notably the NHS Trust, which has been using it for over 10 years. The new model uses a more detailed\",\n",
       "  \"thank you very much for that question, chair. i've got to say 'yes ', in many regards. so, the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services. we developed the windscreen model—or we lifted the windscreen model. other models that are very similar to the Windscreen Model are the Child Mental Health and Development Model (CIMM), which we created in 2005 and are available in all parts of England. the CIMMs are based on a number of different models and their performance in terms of child development has been a major challenge for us. as well as the other aspects of mental and behavioural health, such as mental illness, suicide, substance abuse and depression, and mental wellbeing.\\n\\nIt was also important for the team to consider the potential benefits of a 'new approach to mental care' and how it would help to improve access. We believe the 'New Approach' will improve the\",\n",
       "  \"thank you very much for that question, chair. i've got to say 'yes ', in many regards. so, the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services. we developed the windscreen model—or we lifted the windscreen model. other models that are very similar to this one, but they were based on the idea that children and adolescents are not going to be able to afford the care of their parents, and that's how we started to look at how to improve access. So the program was very focused on providing services to the poorest children of this country who were vulnerable to a lot of problems in life. it was designed to help those children get the services they need. the programmes were designed for families that were able-bodied, those that did not have children, who had no money. We were also looking at providing support for the families who needed to go back to school to get their children back,\"],\n",
       " [\"good morning, everyone, and welcome to the children, young people and education committee this morning. we've received apologies for absence from siân gwenllian and there is no substitute this morning. can i ask if members have got any declarations of interest they 'd like to make, please? no? okay. thank you. item 2.\\n\\nA. I would like some clarification on the subject of the'soul-to-body' relation. We have no formal relationship between the body and soul. it is the soul of our body, the person and the spirit of that person. that is our relationship to each other. i.e. to one another.. the relation to our bodies is a relationship of a kind, i t is called a'relationship of spirit', a relation between bodies of two persons of one kind. e.g. a body of an individual is not related to a soul, but a person, i n a physical\",\n",
       "  \"good morning, everyone, and welcome to the children, young people and education committee this morning. we've received apologies for absence from siân gwenllian and there is no substitute this morning. can i ask if members have got any declarations of interest they 'd like to make, please? no? okay. thank you. item 2 of the report is for the members, i am not sure if anyone had made it but i have been told that i was not allowed to do so. i think i will not be allowed in the office for a day or two, but we have to go to bed and then we are sure that the committee will be ready to take it on. we would like you to give us your statement. if you are not happy to say yes, you can ask for an interview with the secretary of state or the head of public prosecutions. you have a right to know whether there will have be an inquiry on it, if there are any questions please\",\n",
       "  \"good morning, everyone, and welcome to the children, young people and education committee this morning. we've received apologies for absence from siân gwenllian and there is no substitute this morning. can i ask if members have got any declarations of interest they 'd like to make, please? no? okay. thank you. item 2. will you please let us know what you have been asked to provide? i 'll give you some information about your role as chairman, if you would kindly? yes?? ok. i hope that is good for your future. and we hope you will do well at the committee. please keep up the good work!..\"]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"augmented_segments\";\n",
       "                var nbb_formatted_code = \"augmented_segments\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augmented_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776e5e6",
   "metadata": {},
   "source": [
    "## Testing generated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c467518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# https://www.kaggle.com/code/tuckerarrants/text-generation-with-huggingface-gpt2/notebook\\nimport tensorflow as tf\\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer, GPT2TokenizerFast\";\n",
       "                var nbb_formatted_code = \"# https://www.kaggle.com/code/tuckerarrants/text-generation-with-huggingface-gpt2/notebook\\nimport tensorflow as tf\\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer, GPT2TokenizerFast\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/tuckerarrants/text-generation-with-huggingface-gpt2/notebook\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer, GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d68ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"tokenizer = GPT2TokenizerFast.from_pretrained(\\\"gpt2\\\")\\n\\ngpt_model = TFGPT2LMHeadModel.from_pretrained(\\n    \\\"gpt2\\\", pad_token_id=tokenizer.eos_token_id\\n)\\n\\nsentence = \\\"thank you very much for that question , chair . i 've got to say 'yes ' , in many regards . so , the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services . we developed the windscreen model\\u2014or we lifted the windscreen model .\\\"\\n\\n# encode context the generation is conditioned on\\ninput_ids = tokenizer.encode(sentence, return_tensors=\\\"tf\\\")\\n\\n# set seed to reproduce results. Feel free to change the seed though to get different results\\ntf.random.set_seed(0)\\n\\nsample_outputs = gpt_model.generate(\\n    input_ids,\\n    do_sample=True,\\n    max_length=200,\\n    top_k=10,\\n    temperature=0.7,\\n    no_repeat_ngram_size = 2,\\n    num_return_sequences=1,\\n)\\n\\ntext_output = [tokenizer.decode(x, skip_special_tokens=True) for x in sample_outputs]\";\n",
       "                var nbb_formatted_code = \"tokenizer = GPT2TokenizerFast.from_pretrained(\\\"gpt2\\\")\\n\\ngpt_model = TFGPT2LMHeadModel.from_pretrained(\\n    \\\"gpt2\\\", pad_token_id=tokenizer.eos_token_id\\n)\\n\\nsentence = \\\"thank you very much for that question , chair . i 've got to say 'yes ' , in many regards . so , the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services . we developed the windscreen model\\u2014or we lifted the windscreen model .\\\"\\n\\n# encode context the generation is conditioned on\\ninput_ids = tokenizer.encode(sentence, return_tensors=\\\"tf\\\")\\n\\n# set seed to reproduce results. Feel free to change the seed though to get different results\\ntf.random.set_seed(0)\\n\\nsample_outputs = gpt_model.generate(\\n    input_ids,\\n    do_sample=True,\\n    max_length=200,\\n    top_k=10,\\n    temperature=0.7,\\n    no_repeat_ngram_size=2,\\n    num_return_sequences=1,\\n)\\n\\ntext_output = [tokenizer.decode(x, skip_special_tokens=True) for x in sample_outputs]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\", pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "sentence = \"thank you very much for that question , chair . i 've got to say 'yes ' , in many regards . so , the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services . we developed the windscreen model—or we lifted the windscreen model .\"\n",
    "\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode(sentence, return_tensors=\"tf\")\n",
    "\n",
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "sample_outputs = gpt_model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=200,\n",
    "    top_k=10,\n",
    "    temperature=0.7,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "\n",
    "text_output = [tokenizer.decode(x, skip_special_tokens=True) for x in sample_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3069fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"thank you very much for that question, chair. i've got to say 'yes ', in many regards. so, the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services. we developed the windscreen model—or we lifted the windscreen model. it was a huge undertaking, i.e., it would have required a lot of work. and we had to be very patient. there were many challenges in implementing the program, but the results were good. the first phase is the 'new' program. a new programme would be introduced in 2020-21. this would allow for the transition to the next phase of care, which is 'care for children at risk of suicide'. This programme was the culmination of a long project. 'Care for Children at Risk of Suicide' is a national, multi-generational initiative designed to provide mental and physical health care for a range of vulnerable people in Australia..\\n\\nThe\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"text_output\";\n",
       "                var nbb_formatted_code = \"text_output\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "674c4e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank you very much for that question, chair.',\n",
       " \"i've got to say 'yes ', in many regards.\",\n",
       " 'so, the key focus of the programme in the early stages was about improving access to specialist child and adolescent mental health services.',\n",
       " 'we developed the windscreen model—or we lifted the windscreen model.',\n",
       " 'it was a huge undertaking, i.e., it would have required a lot of work.',\n",
       " 'and we had to be very patient.',\n",
       " 'there were many challenges in implementing the program, but the results were good.',\n",
       " \"the first phase is the 'new' program.\",\n",
       " \"a new programme would be introduced in 2020-21. this would allow for the transition to the next phase of care, which is 'care for children at risk of suicide'.\",\n",
       " 'This programme was the culmination of a long project.',\n",
       " \"'Care for Children at Risk of Suicide' is a national, multi-generational initiative designed to provide mental and physical health care for a range of vulnerable people in Australia..\",\n",
       " 'The']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"from nltk.tokenize import sent_tokenize\\n\\nsent_tokenize(text_output[0])\";\n",
       "                var nbb_formatted_code = \"from nltk.tokenize import sent_tokenize\\n\\nsent_tokenize(text_output[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(text_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19974353",
   "metadata": {},
   "source": [
    "## Batch Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93bb2c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_formatted_code = \"from db.dbv2 import Table, AugmentedTable, TrainTestTable\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from db.dbv2 import Table, AugmentedTable, TrainTestTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"committee\"\n",
    "\n",
    "table = Table(dataset_type)\n",
    "augmented_table = AugmentedTable(dataset_type)\n",
    "train_test_table = TrainTestTable(dataset_type)\n",
    "\n",
    "min_sent_tokens = 8\n",
    "max_sent_tokens = 64\n",
    "\n",
    "target_sentences_original = table.get_target_sentences()\n",
    "target_sentences = [s[1] for s in target_sentences_original]\n",
    "cleaned_target_sentences = []\n",
    "\n",
    "for s in target_sentences:\n",
    "    if len(word_tokenize(s)) > min_sent_tokens:\n",
    "        shortened_sentence = \" \".join(word_tokenize(s)[:max_sent_tokens])\n",
    "        cleaned_target_sentences.append(shortened_sentence)\n",
    "\n",
    "augmented_segments = Augmentor.augment_gpt2(\n",
    "    cleaned_target_sentences[:2],\n",
    "    fast=True,\n",
    "    # multiply by 5 to account for 5 as a max segment\n",
    "    max_seq_word_length=max_sent_tokens * 5,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
