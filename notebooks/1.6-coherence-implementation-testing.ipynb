{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc7697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Run if working locally\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ee84b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom src.dataset.dataset import RawData\\nfrom src.dataset.wikisection_preprocessing import (\\n    tokenize,\\n    clean_sentence,\\n    preprocess_text_segmentation,\\n    format_data_for_db_insertion,\\n)\\nfrom src.dataset.utils import truncate_by_token\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\\nimport pprint\\n\\nfrom utils.metrics import windowdiff, pk\\n\\nfrom src.bertkeywords.src.similarities import Embedding, Similarities\\nfrom src.bertkeywords.src.keywords import Keywords\\nfrom src.encoders.coherence import Coherence\\nfrom src.dataset.utils import flatten, dedupe_list, truncate_string\";\n",
       "                var nbb_formatted_code = \"import sqlite3\\nfrom sqlite3 import Error\\nimport pickle\\nimport os, sys\\nimport config\\n\\nconfig.root_path = os.path.abspath(os.path.join(os.getcwd(), \\\"..\\\"))\\nsys.path.insert(0, config.root_path)\\n\\nfrom src.dataset.dataset import RawData\\nfrom src.dataset.wikisection_preprocessing import (\\n    tokenize,\\n    clean_sentence,\\n    preprocess_text_segmentation,\\n    format_data_for_db_insertion,\\n)\\nfrom src.dataset.utils import truncate_by_token\\nfrom db.dbv2 import Table, AugmentedTable, TrainTestTable\\nimport pprint\\n\\nfrom utils.metrics import windowdiff, pk\\n\\nfrom src.bertkeywords.src.similarities import Embedding, Similarities\\nfrom src.bertkeywords.src.keywords import Keywords\\nfrom src.encoders.coherence import Coherence\\nfrom src.dataset.utils import flatten, dedupe_list, truncate_string\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pickle\n",
    "import os, sys\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)\n",
    "\n",
    "from src.dataset.dataset import RawData\n",
    "from src.dataset.wikisection_preprocessing import (\n",
    "    tokenize,\n",
    "    clean_sentence,\n",
    "    preprocess_text_segmentation,\n",
    "    format_data_for_db_insertion,\n",
    ")\n",
    "from src.dataset.utils import truncate_by_token\n",
    "from db.dbv2 import Table, AugmentedTable, TrainTestTable\n",
    "import pprint\n",
    "\n",
    "from utils.metrics import windowdiff, pk\n",
    "\n",
    "from src.bertkeywords.src.similarities import Embedding, Similarities\n",
    "from src.bertkeywords.src.keywords import Keywords\n",
    "from src.encoders.coherence import Coherence\n",
    "from src.dataset.utils import flatten, dedupe_list, truncate_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb2458b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"dataset_type = \\\"city\\\"\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_formatted_code = \"dataset_type = \\\"city\\\"\\ntable = Table(dataset_type)\\naugmented_table = AugmentedTable(dataset_type)\\ntrain_test_table = TrainTestTable(dataset_type)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_type = \"city\"\n",
    "table = Table(dataset_type)\n",
    "augmented_table = AugmentedTable(dataset_type)\n",
    "train_test_table = TrainTestTable(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd59c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"data = table.get_all()\\n\\ntext_data = [x[1] for x in data]\\ntext_labels = [x[2] for x in data]\";\n",
       "                var nbb_formatted_code = \"data = table.get_all()\\n\\ntext_data = [x[1] for x in data]\\ntext_labels = [x[2] for x in data]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = table.get_all()\n",
    "\n",
    "text_data = [x[1] for x in data]\n",
    "text_labels = [x[2] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcccad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"all_segments = table.get_all_segments()\\ntext_segments = [[y[1] for y in x] for x in all_segments]\\nsegments_labels = [[1 if i == 0 else 0 for i, y in enumerate(x)] for x in all_segments]\";\n",
       "                var nbb_formatted_code = \"all_segments = table.get_all_segments()\\ntext_segments = [[y[1] for y in x] for x in all_segments]\\nsegments_labels = [[1 if i == 0 else 0 for i, y in enumerate(x)] for x in all_segments]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_segments = table.get_all_segments()\n",
    "text_segments = [[y[1] for y in x] for x in all_segments]\n",
    "segments_labels = [[1 if i == 0 else 0 for i, y in enumerate(x)] for x in all_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295657fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"samples = 5\\nmax_tokens = 400\\n\\nfor i, (segment, labels) in enumerate(\\n    zip(text_segments[:samples], segments_labels[:samples])\\n):\\n    for sentence, label in zip(segment, labels):\\n        # this is the training case. During inference, we will have no idea\\n        # when segments start and when they end.\\n        pass\";\n",
       "                var nbb_formatted_code = \"samples = 5\\nmax_tokens = 400\\n\\nfor i, (segment, labels) in enumerate(\\n    zip(text_segments[:samples], segments_labels[:samples])\\n):\\n    for sentence, label in zip(segment, labels):\\n        # this is the training case. During inference, we will have no idea\\n        # when segments start and when they end.\\n        pass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = 5\n",
    "max_tokens = 400\n",
    "\n",
    "for i, (segment, labels) in enumerate(\n",
    "    zip(text_segments[:samples], segments_labels[:samples])\n",
    "):\n",
    "    for sentence, label in zip(segment, labels):\n",
    "        # this is the training case. During inference, we will have no idea\n",
    "        # when segments start and when they end.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467789d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"text_labels[:25]\";\n",
       "                var nbb_formatted_code = \"text_labels[:25]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_labels[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59e79b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2023-04-16 01:27:22.643016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-16 01:27:23.686457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# initialize the coherence library\\nmax_words_per_step = 4\\ncoherence = Coherence(max_words_per_step=max_words_per_step)\";\n",
       "                var nbb_formatted_code = \"# initialize the coherence library\\nmax_words_per_step = 4\\ncoherence = Coherence(max_words_per_step=max_words_per_step)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the coherence library\n",
    "max_words_per_step = 4\n",
    "coherence = Coherence(max_words_per_step=max_words_per_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "f6870992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 417;\n",
       "                var nbb_unformatted_code = \"def get_weighted_average(weighted_similarities, weights):\\n    return sum(weighted_similarities) / sum(weights)\\n\\n\\n# importance testing\\ndef compare_coherent_words(\\n    coherence_map,\\n    keywords_current,\\n    suppress_errors=False,\\n    same_word_multiplier=3,  # if set to 1, don't amplify the same words found\\n):\\n    word_comparisons = []\\n    weights = []\\n    for i, keywords in enumerate(coherence_map[::-1]):\\n        for word_tuple in keywords:\\n            word = word_tuple[0]\\n            for second_word_tuple in keywords_current:\\n                second_word = second_word_tuple[0]\\n                second_word_importance = second_word_tuple[1]\\n\\n                try:\\n                    word_one_emb = word_tuple[2]\\n                    word_two_emb = second_word_tuple[2]\\n\\n                    if same_word_multiplier > 1:\\n                        flattened_coherence_words_only = [\\n                            element[0]\\n                            for sublist in coherence_map\\n                            for element in sublist\\n                        ]\\n\\n                        num_occurrences = flattened_coherence_words_only.count(\\n                            second_word\\n                        )\\n\\n                        if num_occurrences > 0:\\n                            # amplify words that are found as duplicates in the coherence map\\n                            # if the word shows up 1 time, amplify the weight by 2 times\\n                            weighting_multiplier = flattened_coherence_words_only.count(\\n                                second_word\\n                            ) + (same_word_multiplier - 1)\\n                        else:\\n                            #                             weighting_multiplier = 1\\n                            weighting_multiplier = (\\n                                1 / same_word_multiplier\\n                            )  # reduce the importance of this word\\n\\n                    else:\\n                        weighting_multiplier = 1  # set to 1 in case this is turned off.\\n\\n                    # this weight is a recipricol function that will grow smaller the further the keywords are away\\n                    # we want to put more importance on the current words, so we apply twice as much weight.\\n                    if i == 0:\\n                        weight = (weighting_multiplier * 2) / (i + 1)\\n                    else:\\n                        weight = (weighting_multiplier * 1) / (i + 1)\\n\\n                    # multiply the weighting factor by the importance of the second word\\n                    weight *= second_word_importance\\n\\n                    word_comparisons.append(\\n                        (\\n                            word,\\n                            second_word,\\n                            weight\\n                            * coherence.embedding_lib.get_similarity(\\n                                word_one_emb, word_two_emb\\n                            ),\\n                        )\\n                    )\\n                    weights.append(weight)\\n                except AssertionError as e:\\n                    if not suppress_errors:\\n                        print(e, word, second_word)\\n\\n    return word_comparisons, weights\\n\\n\\n# TODO: add weighted average: https://www.google.com/search?q=weighted+average&rlz=1C5CHFA_enCA1019CA1024&sxsrf=APwXEdcb6dhJ5L_mvWvrWr4AxQcxOFB01g:1681098698316&tbm=isch&source=iu&ictx=1&vet=1&fir=V-LTDKtCElo89M%252C2WVwd1NrPkHFOM%252C_%253BVGk_lj0HALhXQM%252C2WVwd1NrPkHFOM%252C_%253ByzfbB4i3SpPTFM%252C5e7an03wLAdfhM%252C_%253B47HYmoDH6WlThM%252CsRXbJWfpyOLEOM%252C_%253BOsB4jtfzenfuyM%252CHKcmLkpfJ3xWqM%252C_&usg=AI4_-kRmBXgUWAm_nR3vDsLT17TqM5AvSQ&sa=X&ved=2ahUKEwi6hvvVtJ7-AhXJkIkEHe4JCX4Q_h16BAgoEAE#imgrc=V-LTDKtCElo89M\\ndef coherence_tester(\\n    text_data,\\n    text_labels,\\n    max_tokens=256,\\n    max_str_length=30,\\n    prediction_thresh=0.25,\\n    pruning=0,  # remove one sentence worth of keywords\\n    pruning_min=6,  # remove the first sentence in the coherence map once it grows passed 6\\n    dynamic_threshold=False,\\n    threshold_warmup=10,  # number of iterations before using dynamic threshold\\n    last_n_threshold=5,  # will only consider the last n thresholds for dynamic threshold\\n):\\n    coherence_map = []\\n    predictions = []\\n    thresholds = []\\n    for i, (row, label) in enumerate(zip(text_data, text_labels)):\\n        threshold = prediction_thresh\\n        if dynamic_threshold and (i + 1) > threshold_warmup:\\n            last_n_thresholds = thresholds[(0 - last_n_threshold) :]\\n            last_n_thresholds.sort()\\n            mid = len(last_n_thresholds) // 2\\n            threshold = (last_n_thresholds[mid] + last_n_thresholds[~mid]) / 2\\n            print(f\\\"median threshold: {threshold}\\\")\\n        # compare the current sentence to the previous one\\n        if i == 0:\\n            predictions.append((0, 0))\\n        else:\\n            prev_row = text_data[i - 1]\\n\\n            row = truncate_by_token(row, max_tokens)\\n            prev_row = truncate_by_token(prev_row, max_tokens)\\n\\n            cohesion, keywords_prev, keywords_current = coherence.get_coherence(\\n                [row, prev_row], coherence_threshold=0.3\\n            )\\n\\n            # add the keywords to the coherence map\\n            coherence_map.append(cohesion)\\n            if pruning > 0 and len(coherence_map) >= pruning_min:\\n                print(\\\"pruning...\\\", len(coherence_map))\\n                coherence_map = coherence_map[\\n                    pruning:\\n                ]  # remove the pruning amount from the beginning of the list\\n                print(\\\"done pruning...\\\", len(coherence_map))\\n\\n            # truncate the strings for printing\\n            truncated_row = truncate_string(row, max_str_length)\\n            truncated_prev_row = truncate_string(prev_row, max_str_length)\\n            print(\\n                f\\\"Coherence Map: {[[x[0] for x in c] for c in coherence_map]}, KW Curr: {[x[0] for x in keywords_current]}\\\"\\n            )\\n\\n            # compute the word comparisons between the previous (with the coherence map)\\n            # and the current (possibly the first sentence in a new segment)\\n            word_comparisons_with_coherence, weights = compare_coherent_words(\\n                [*coherence_map, keywords_prev], keywords_current\\n            )\\n\\n            similarities_with_coherence = [\\n                comparison[2] for comparison in word_comparisons_with_coherence\\n            ]\\n            avg_similarity_with_coherence = sum(similarities_with_coherence) / (\\n                len(similarities_with_coherence) or 1\\n            )\\n            weighted_avg_similarity_with_coherence = get_weighted_average(\\n                similarities_with_coherence, weights\\n            )\\n            print(f\\\"weighted: {weighted_avg_similarity_with_coherence}\\\")\\n\\n            # if the two sentences are similar, create a cohesive prediction\\n            # otherwise, predict a new segment\\n            if weighted_avg_similarity_with_coherence > threshold:\\n                print(\\n                    f\\\"Label: {label}, Prediction: {0}, logit: {weighted_avg_similarity_with_coherence}\\\"\\n                )\\n                predictions.append((weighted_avg_similarity_with_coherence, 0))\\n            else:\\n                # start of a new segment, empty the map\\n                coherence_map = []\\n                print(\\n                    f\\\"Label: {label}, Prediction: {1}, logit: {weighted_avg_similarity_with_coherence}\\\"\\n                )\\n                predictions.append((weighted_avg_similarity_with_coherence, 1))\\n\\n            thresholds.append(weighted_avg_similarity_with_coherence)\\n            print(\\\"===============================================\\\")\\n\\n    return predictions\";\n",
       "                var nbb_formatted_code = \"def get_weighted_average(weighted_similarities, weights):\\n    return sum(weighted_similarities) / sum(weights)\\n\\n\\n# importance testing\\ndef compare_coherent_words(\\n    coherence_map,\\n    keywords_current,\\n    suppress_errors=False,\\n    same_word_multiplier=3,  # if set to 1, don't amplify the same words found\\n):\\n    word_comparisons = []\\n    weights = []\\n    for i, keywords in enumerate(coherence_map[::-1]):\\n        for word_tuple in keywords:\\n            word = word_tuple[0]\\n            for second_word_tuple in keywords_current:\\n                second_word = second_word_tuple[0]\\n                second_word_importance = second_word_tuple[1]\\n\\n                try:\\n                    word_one_emb = word_tuple[2]\\n                    word_two_emb = second_word_tuple[2]\\n\\n                    if same_word_multiplier > 1:\\n                        flattened_coherence_words_only = [\\n                            element[0]\\n                            for sublist in coherence_map\\n                            for element in sublist\\n                        ]\\n\\n                        num_occurrences = flattened_coherence_words_only.count(\\n                            second_word\\n                        )\\n\\n                        if num_occurrences > 0:\\n                            # amplify words that are found as duplicates in the coherence map\\n                            # if the word shows up 1 time, amplify the weight by 2 times\\n                            weighting_multiplier = flattened_coherence_words_only.count(\\n                                second_word\\n                            ) + (same_word_multiplier - 1)\\n                        else:\\n                            #                             weighting_multiplier = 1\\n                            weighting_multiplier = (\\n                                1 / same_word_multiplier\\n                            )  # reduce the importance of this word\\n\\n                    else:\\n                        weighting_multiplier = 1  # set to 1 in case this is turned off.\\n\\n                    # this weight is a recipricol function that will grow smaller the further the keywords are away\\n                    # we want to put more importance on the current words, so we apply twice as much weight.\\n                    if i == 0:\\n                        weight = (weighting_multiplier * 2) / (i + 1)\\n                    else:\\n                        weight = (weighting_multiplier * 1) / (i + 1)\\n\\n                    # multiply the weighting factor by the importance of the second word\\n                    weight *= second_word_importance\\n\\n                    word_comparisons.append(\\n                        (\\n                            word,\\n                            second_word,\\n                            weight\\n                            * coherence.embedding_lib.get_similarity(\\n                                word_one_emb, word_two_emb\\n                            ),\\n                        )\\n                    )\\n                    weights.append(weight)\\n                except AssertionError as e:\\n                    if not suppress_errors:\\n                        print(e, word, second_word)\\n\\n    return word_comparisons, weights\\n\\n\\n# TODO: add weighted average: https://www.google.com/search?q=weighted+average&rlz=1C5CHFA_enCA1019CA1024&sxsrf=APwXEdcb6dhJ5L_mvWvrWr4AxQcxOFB01g:1681098698316&tbm=isch&source=iu&ictx=1&vet=1&fir=V-LTDKtCElo89M%252C2WVwd1NrPkHFOM%252C_%253BVGk_lj0HALhXQM%252C2WVwd1NrPkHFOM%252C_%253ByzfbB4i3SpPTFM%252C5e7an03wLAdfhM%252C_%253B47HYmoDH6WlThM%252CsRXbJWfpyOLEOM%252C_%253BOsB4jtfzenfuyM%252CHKcmLkpfJ3xWqM%252C_&usg=AI4_-kRmBXgUWAm_nR3vDsLT17TqM5AvSQ&sa=X&ved=2ahUKEwi6hvvVtJ7-AhXJkIkEHe4JCX4Q_h16BAgoEAE#imgrc=V-LTDKtCElo89M\\ndef coherence_tester(\\n    text_data,\\n    text_labels,\\n    max_tokens=256,\\n    max_str_length=30,\\n    prediction_thresh=0.25,\\n    pruning=0,  # remove one sentence worth of keywords\\n    pruning_min=6,  # remove the first sentence in the coherence map once it grows passed 6\\n    dynamic_threshold=False,\\n    threshold_warmup=10,  # number of iterations before using dynamic threshold\\n    last_n_threshold=5,  # will only consider the last n thresholds for dynamic threshold\\n):\\n    coherence_map = []\\n    predictions = []\\n    thresholds = []\\n    for i, (row, label) in enumerate(zip(text_data, text_labels)):\\n        threshold = prediction_thresh\\n        if dynamic_threshold and (i + 1) > threshold_warmup:\\n            last_n_thresholds = thresholds[(0 - last_n_threshold) :]\\n            last_n_thresholds.sort()\\n            mid = len(last_n_thresholds) // 2\\n            threshold = (last_n_thresholds[mid] + last_n_thresholds[~mid]) / 2\\n            print(f\\\"median threshold: {threshold}\\\")\\n        # compare the current sentence to the previous one\\n        if i == 0:\\n            predictions.append((0, 0))\\n        else:\\n            prev_row = text_data[i - 1]\\n\\n            row = truncate_by_token(row, max_tokens)\\n            prev_row = truncate_by_token(prev_row, max_tokens)\\n\\n            cohesion, keywords_prev, keywords_current = coherence.get_coherence(\\n                [row, prev_row], coherence_threshold=0.3\\n            )\\n\\n            # add the keywords to the coherence map\\n            coherence_map.append(cohesion)\\n            if pruning > 0 and len(coherence_map) >= pruning_min:\\n                print(\\\"pruning...\\\", len(coherence_map))\\n                coherence_map = coherence_map[\\n                    pruning:\\n                ]  # remove the pruning amount from the beginning of the list\\n                print(\\\"done pruning...\\\", len(coherence_map))\\n\\n            # truncate the strings for printing\\n            truncated_row = truncate_string(row, max_str_length)\\n            truncated_prev_row = truncate_string(prev_row, max_str_length)\\n            print(\\n                f\\\"Coherence Map: {[[x[0] for x in c] for c in coherence_map]}, KW Curr: {[x[0] for x in keywords_current]}\\\"\\n            )\\n\\n            # compute the word comparisons between the previous (with the coherence map)\\n            # and the current (possibly the first sentence in a new segment)\\n            word_comparisons_with_coherence, weights = compare_coherent_words(\\n                [*coherence_map, keywords_prev], keywords_current\\n            )\\n\\n            similarities_with_coherence = [\\n                comparison[2] for comparison in word_comparisons_with_coherence\\n            ]\\n            avg_similarity_with_coherence = sum(similarities_with_coherence) / (\\n                len(similarities_with_coherence) or 1\\n            )\\n            weighted_avg_similarity_with_coherence = get_weighted_average(\\n                similarities_with_coherence, weights\\n            )\\n            print(f\\\"weighted: {weighted_avg_similarity_with_coherence}\\\")\\n\\n            # if the two sentences are similar, create a cohesive prediction\\n            # otherwise, predict a new segment\\n            if weighted_avg_similarity_with_coherence > threshold:\\n                print(\\n                    f\\\"Label: {label}, Prediction: {0}, logit: {weighted_avg_similarity_with_coherence}\\\"\\n                )\\n                predictions.append((weighted_avg_similarity_with_coherence, 0))\\n            else:\\n                # start of a new segment, empty the map\\n                coherence_map = []\\n                print(\\n                    f\\\"Label: {label}, Prediction: {1}, logit: {weighted_avg_similarity_with_coherence}\\\"\\n                )\\n                predictions.append((weighted_avg_similarity_with_coherence, 1))\\n\\n            thresholds.append(weighted_avg_similarity_with_coherence)\\n            print(\\\"===============================================\\\")\\n\\n    return predictions\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_weighted_average(weighted_similarities, weights):\n",
    "    return sum(weighted_similarities) / sum(weights)\n",
    "\n",
    "\n",
    "# importance testing\n",
    "def compare_coherent_words(\n",
    "    coherence_map,\n",
    "    keywords_current,\n",
    "    suppress_errors=False,\n",
    "    same_word_multiplier=3,  # if set to 1, don't amplify the same words found\n",
    "):\n",
    "    word_comparisons = []\n",
    "    weights = []\n",
    "    for i, keywords in enumerate(coherence_map[::-1]):\n",
    "        for word_tuple in keywords:\n",
    "            word = word_tuple[0]\n",
    "            for second_word_tuple in keywords_current:\n",
    "                second_word = second_word_tuple[0]\n",
    "                second_word_importance = second_word_tuple[1]\n",
    "\n",
    "                try:\n",
    "                    word_one_emb = word_tuple[2]\n",
    "                    word_two_emb = second_word_tuple[2]\n",
    "\n",
    "                    if same_word_multiplier > 1:\n",
    "                        flattened_coherence_words_only = [\n",
    "                            element[0]\n",
    "                            for sublist in coherence_map\n",
    "                            for element in sublist\n",
    "                        ]\n",
    "\n",
    "                        num_occurrences = flattened_coherence_words_only.count(\n",
    "                            second_word\n",
    "                        )\n",
    "\n",
    "                        if num_occurrences > 0:\n",
    "                            # amplify words that are found as duplicates in the coherence map\n",
    "                            # if the word shows up 1 time, amplify the weight by 2 times\n",
    "                            weighting_multiplier = flattened_coherence_words_only.count(\n",
    "                                second_word\n",
    "                            ) + (same_word_multiplier - 1)\n",
    "                        else:\n",
    "                            #                             weighting_multiplier = 1\n",
    "                            weighting_multiplier = (\n",
    "                                1 / same_word_multiplier\n",
    "                            )  # reduce the importance of this word\n",
    "\n",
    "                    else:\n",
    "                        weighting_multiplier = 1  # set to 1 in case this is turned off.\n",
    "\n",
    "                    # this weight is a recipricol function that will grow smaller the further the keywords are away\n",
    "                    # we want to put more importance on the current words, so we apply twice as much weight.\n",
    "                    if i == 0:\n",
    "                        weight = (weighting_multiplier * 2) / (i + 1)\n",
    "                    else:\n",
    "                        weight = (weighting_multiplier * 1) / (i + 1)\n",
    "\n",
    "                    # multiply the weighting factor by the importance of the second word\n",
    "                    weight *= second_word_importance\n",
    "\n",
    "                    word_comparisons.append(\n",
    "                        (\n",
    "                            word,\n",
    "                            second_word,\n",
    "                            weight\n",
    "                            * coherence.embedding_lib.get_similarity(\n",
    "                                word_one_emb, word_two_emb\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                    weights.append(weight)\n",
    "                except AssertionError as e:\n",
    "                    if not suppress_errors:\n",
    "                        print(e, word, second_word)\n",
    "\n",
    "    return word_comparisons, weights\n",
    "\n",
    "\n",
    "# TODO: add weighted average: https://www.google.com/search?q=weighted+average&rlz=1C5CHFA_enCA1019CA1024&sxsrf=APwXEdcb6dhJ5L_mvWvrWr4AxQcxOFB01g:1681098698316&tbm=isch&source=iu&ictx=1&vet=1&fir=V-LTDKtCElo89M%252C2WVwd1NrPkHFOM%252C_%253BVGk_lj0HALhXQM%252C2WVwd1NrPkHFOM%252C_%253ByzfbB4i3SpPTFM%252C5e7an03wLAdfhM%252C_%253B47HYmoDH6WlThM%252CsRXbJWfpyOLEOM%252C_%253BOsB4jtfzenfuyM%252CHKcmLkpfJ3xWqM%252C_&usg=AI4_-kRmBXgUWAm_nR3vDsLT17TqM5AvSQ&sa=X&ved=2ahUKEwi6hvvVtJ7-AhXJkIkEHe4JCX4Q_h16BAgoEAE#imgrc=V-LTDKtCElo89M\n",
    "def coherence_tester(\n",
    "    text_data,\n",
    "    text_labels,\n",
    "    max_tokens=256,\n",
    "    max_str_length=30,\n",
    "    prediction_thresh=0.25,\n",
    "    pruning=0,  # remove one sentence worth of keywords\n",
    "    pruning_min=6,  # remove the first sentence in the coherence map once it grows passed 6\n",
    "    dynamic_threshold=False,\n",
    "    threshold_warmup=10,  # number of iterations before using dynamic threshold\n",
    "    last_n_threshold=5,  # will only consider the last n thresholds for dynamic threshold\n",
    "):\n",
    "    coherence_map = []\n",
    "    predictions = []\n",
    "    thresholds = []\n",
    "    for i, (row, label) in enumerate(zip(text_data, text_labels)):\n",
    "        threshold = prediction_thresh\n",
    "        if dynamic_threshold and (i + 1) > threshold_warmup:\n",
    "            last_n_thresholds = thresholds[(0 - last_n_threshold) :]\n",
    "            last_n_thresholds.sort()\n",
    "            mid = len(last_n_thresholds) // 2\n",
    "            threshold = (last_n_thresholds[mid] + last_n_thresholds[~mid]) / 2\n",
    "            print(f\"median threshold: {threshold}\")\n",
    "        # compare the current sentence to the previous one\n",
    "        if i == 0:\n",
    "            predictions.append((0, 0))\n",
    "        else:\n",
    "            prev_row = text_data[i - 1]\n",
    "\n",
    "            row = truncate_by_token(row, max_tokens)\n",
    "            prev_row = truncate_by_token(prev_row, max_tokens)\n",
    "\n",
    "            cohesion, keywords_prev, keywords_current = coherence.get_coherence(\n",
    "                [row, prev_row], coherence_threshold=0.3\n",
    "            )\n",
    "\n",
    "            # add the keywords to the coherence map\n",
    "            coherence_map.append(cohesion)\n",
    "            if pruning > 0 and len(coherence_map) >= pruning_min:\n",
    "                print(\"pruning...\", len(coherence_map))\n",
    "                coherence_map = coherence_map[\n",
    "                    pruning:\n",
    "                ]  # remove the pruning amount from the beginning of the list\n",
    "                print(\"done pruning...\", len(coherence_map))\n",
    "\n",
    "            # truncate the strings for printing\n",
    "            truncated_row = truncate_string(row, max_str_length)\n",
    "            truncated_prev_row = truncate_string(prev_row, max_str_length)\n",
    "            print(\n",
    "                f\"Coherence Map: {[[x[0] for x in c] for c in coherence_map]}, KW Curr: {[x[0] for x in keywords_current]}\"\n",
    "            )\n",
    "\n",
    "            # compute the word comparisons between the previous (with the coherence map)\n",
    "            # and the current (possibly the first sentence in a new segment)\n",
    "            word_comparisons_with_coherence, weights = compare_coherent_words(\n",
    "                [*coherence_map, keywords_prev], keywords_current\n",
    "            )\n",
    "\n",
    "            similarities_with_coherence = [\n",
    "                comparison[2] for comparison in word_comparisons_with_coherence\n",
    "            ]\n",
    "            avg_similarity_with_coherence = sum(similarities_with_coherence) / (\n",
    "                len(similarities_with_coherence) or 1\n",
    "            )\n",
    "            weighted_avg_similarity_with_coherence = get_weighted_average(\n",
    "                similarities_with_coherence, weights\n",
    "            )\n",
    "            print(f\"weighted: {weighted_avg_similarity_with_coherence}\")\n",
    "\n",
    "            # if the two sentences are similar, create a cohesive prediction\n",
    "            # otherwise, predict a new segment\n",
    "            if weighted_avg_similarity_with_coherence > threshold:\n",
    "                print(\n",
    "                    f\"Label: {label}, Prediction: {0}, logit: {weighted_avg_similarity_with_coherence}\"\n",
    "                )\n",
    "                predictions.append((weighted_avg_similarity_with_coherence, 0))\n",
    "            else:\n",
    "                # start of a new segment, empty the map\n",
    "#                 coherence_map = []\n",
    "                print(\n",
    "                    f\"Label: {label}, Prediction: {1}, logit: {weighted_avg_similarity_with_coherence}\"\n",
    "                )\n",
    "                predictions.append((weighted_avg_similarity_with_coherence, 1))\n",
    "\n",
    "            thresholds.append(weighted_avg_similarity_with_coherence)\n",
    "            print(\"===============================================\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "ca71b4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['donostia', 'sebastian', 'sebastián', 'sebastiane']\n",
      "['pasaia', 'urumea', 'biscay', 'adarra']\n",
      "Got the keywords in 0.2830 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['sebastián', 'biscay']], KW Curr: ['donostia', 'sebastian', 'sebastián', 'sebastiane']\n",
      "weighted: tensor([0.2756])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2756])\n",
      "===============================================\n",
      "['pasaia', 'urumea', 'biscay', 'adarra']\n",
      "['climate', 'temperatures', 'winters', 'sebastián']\n",
      "Got the keywords in 0.2695 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['sebastián', 'biscay'], ['pasaia', 'urumea', 'temperatures', 'winters']], KW Curr: ['pasaia', 'urumea', 'biscay', 'adarra']\n",
      "weighted: tensor([0.2337])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2337])\n",
      "===============================================\n",
      "['climate', 'temperatures', 'winters', 'sebastián']\n",
      "['paleolithic', 'ametzagaña', 'settlers', 'sapiens']\n",
      "Got the keywords in 0.2023 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['paleolithic', 'ametzagaña', 'climate', 'settlers']], KW Curr: ['climate', 'temperatures', 'winters', 'sebastián']\n",
      "weighted: tensor([0.3490])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3490])\n",
      "===============================================\n",
      "['paleolithic', 'ametzagaña', 'settlers', 'sapiens']\n",
      "['sebastián', 'san', 'basque', 'varduli']\n",
      "Got the keywords in 0.1647 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['paleolithic', 'ametzagaña', 'climate', 'settlers'], ['paleolithic', 'san', 'basque', 'sapiens']], KW Curr: ['paleolithic', 'ametzagaña', 'settlers', 'sapiens']\n",
      "weighted: tensor([0.2993])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2993])\n",
      "===============================================\n",
      "['sebastián', 'san', 'basque', 'varduli']\n",
      "['navarre', 'fuero', 'monastery', 'sebastián']\n",
      "Got the keywords in 0.2744 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['paleolithic', 'ametzagaña', 'climate', 'settlers'], ['paleolithic', 'san', 'basque', 'sapiens'], []], KW Curr: ['sebastián', 'san', 'basque', 'varduli']\n",
      "weighted: tensor([0.1844])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.1844])\n",
      "===============================================\n",
      "['navarre', 'fuero', 'monastery', 'sebastián']\n",
      "['donostia', 'navarre', 'spain', 'hondarribia']\n",
      "Got the keywords in 0.4172 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero']], KW Curr: ['navarre', 'fuero', 'monastery', 'sebastián']\n",
      "weighted: tensor([0.3494])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3494])\n",
      "===============================================\n",
      "['donostia', 'navarre', 'spain', 'hondarribia']\n",
      "['gipuzkoa', 'tolosa', 'construction', '1833']\n",
      "Got the keywords in 0.4483 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain']], KW Curr: ['donostia', 'navarre', 'spain', 'hondarribia']\n",
      "weighted: tensor([0.4572])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4572])\n",
      "===============================================\n",
      "['gipuzkoa', 'tolosa', 'construction', '1833']\n",
      "['cortazar', 'donostia', 'zurriola', 'town']\n",
      "Got the keywords in 0.4034 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa']], KW Curr: ['gipuzkoa', 'tolosa', 'construction', '1833']\n",
      "weighted: tensor([0.5532])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5532])\n",
      "===============================================\n",
      "['cortazar', 'donostia', 'zurriola', 'town']\n",
      "['koxkeroak', 'vieja', 'joxemaritarrak', 'parte']\n",
      "Got the keywords in 0.3602 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak']], KW Curr: ['cortazar', 'donostia', 'zurriola', 'town']\n",
      "weighted: tensor([0.6303])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.6303])\n",
      "===============================================\n",
      "['koxkeroak', 'vieja', 'joxemaritarrak', 'parte']\n",
      "['miramar', 'león', 'el', 'antiguo']\n",
      "Got the keywords in 0.2883 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león']], KW Curr: ['koxkeroak', 'vieja', 'joxemaritarrak', 'parte']\n",
      "weighted: tensor([0.4422])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4422])\n",
      "===============================================\n",
      "['miramar', 'león', 'el', 'antiguo']\n",
      "['amara', 'euskotren', 'marshes', 'urumea']\n",
      "Got the keywords in 0.2064 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar']], KW Curr: ['miramar', 'león', 'el', 'antiguo']\n",
      "weighted: tensor([0.3245])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3245])\n",
      "===============================================\n",
      "['amara', 'euskotren', 'marshes', 'urumea']\n",
      "['amara', 'district', 'city', 'madrid']\n",
      "Got the keywords in 0.2101 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid']], KW Curr: ['amara', 'euskotren', 'marshes', 'urumea']\n",
      "weighted: tensor([0.2946])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2946])\n",
      "===============================================\n",
      "['amara', 'district', 'city', 'madrid']\n",
      "['district', 'area', 'gros', 'built']\n",
      "Got the keywords in 0.2542 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built']], KW Curr: ['amara', 'district', 'city', 'madrid']\n",
      "weighted: tensor([0.2760])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2760])\n",
      "===============================================\n",
      "['district', 'area', 'gros', 'built']\n",
      "['palace', 'residence', 'aiete', 'franco']\n",
      "Got the keywords in 0.2177 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area']], KW Curr: ['district', 'area', 'gros', 'built']\n",
      "weighted: tensor([0.4008])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4008])\n",
      "===============================================\n",
      "['palace', 'residence', 'aiete', 'franco']\n",
      "['egia', 'donostia', 'urumea', 'anoeta']\n",
      "Got the keywords in 0.2753 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta']], KW Curr: ['palace', 'residence', 'aiete', 'franco']\n",
      "weighted: tensor([0.3921])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3921])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['egia', 'donostia', 'urumea', 'anoeta']\n",
      "['intxaurrondo', 'walnut', 'basque', 'situated']\n",
      "Got the keywords in 0.2918 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut']], KW Curr: ['egia', 'donostia', 'urumea', 'anoeta']\n",
      "weighted: tensor([0.4195])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4195])\n",
      "===============================================\n",
      "['intxaurrondo', 'walnut', 'basque', 'situated']\n",
      "['altza', 'basque', 'sebastián', 'san']\n",
      "Got the keywords in 0.2652 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut'], ['intxaurrondo', 'altza', 'basque', 'sebastián']], KW Curr: ['intxaurrondo', 'walnut', 'basque', 'situated']\n",
      "weighted: tensor([0.4402])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4402])\n",
      "===============================================\n",
      "['altza', 'basque', 'sebastián', 'san']\n",
      "['ibaeta', 'cervezas', 'el', 'buildings']\n",
      "Got the keywords in 0.2451 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut'], ['intxaurrondo', 'altza', 'basque', 'sebastián'], ['ibaeta', 'basque', 'buildings', 'san']], KW Curr: ['altza', 'basque', 'sebastián', 'san']\n",
      "weighted: tensor([0.3509])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3509])\n",
      "===============================================\n",
      "['ibaeta', 'cervezas', 'el', 'buildings']\n",
      "['ciudad', 'hernani', 'astigarraga', 'district']\n",
      "Got the keywords in 0.2531 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut'], ['intxaurrondo', 'altza', 'basque', 'sebastián'], ['ibaeta', 'basque', 'buildings', 'san'], ['ibaeta', 'ciudad', 'cervezas', 'hernani']], KW Curr: ['ibaeta', 'cervezas', 'el', 'buildings']\n",
      "weighted: tensor([0.3776])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3776])\n",
      "===============================================\n",
      "['ciudad', 'hernani', 'astigarraga', 'district']\n",
      "['urumea', 'district', 'donostia', 'river']\n",
      "Got the keywords in 0.1708 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut'], ['intxaurrondo', 'altza', 'basque', 'sebastián'], ['ibaeta', 'basque', 'buildings', 'san'], ['ibaeta', 'ciudad', 'cervezas', 'hernani'], ['ciudad', 'astigarraga', 'urumea', 'river']], KW Curr: ['ciudad', 'hernani', 'astigarraga', 'district']\n",
      "weighted: tensor([0.3227])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3227])\n",
      "===============================================\n",
      "['urumea', 'district', 'donostia', 'river']\n",
      "['astigarraga', 'loiola', 'martutene', 'municipality']\n",
      "Got the keywords in 0.2023 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['navarre', 'donostia', 'navarre', 'fuero'], ['gipuzkoa', 'donostia', 'navarre', 'spain'], ['cortazar', 'gipuzkoa', 'donostia', 'tolosa'], ['cortazar', 'koxkeroak', 'vieja', 'joxemaritarrak'], ['koxkeroak', 'vieja', 'miramar', 'león'], ['euskotren', 'miramar'], ['amara', 'madrid'], ['amara', 'district', 'city', 'built'], ['palace', 'district', 'residence', 'area'], ['egia', 'donostia', 'palace', 'anoeta'], ['egia', 'intxaurrondo', 'donostia', 'walnut'], ['intxaurrondo', 'altza', 'basque', 'sebastián'], ['ibaeta', 'basque', 'buildings', 'san'], ['ibaeta', 'ciudad', 'cervezas', 'hernani'], ['ciudad', 'astigarraga', 'urumea', 'river'], ['astigarraga', 'district', 'river', 'municipality']], KW Curr: ['urumea', 'district', 'donostia', 'river']\n",
      "weighted: tensor([0.2378])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2378])\n",
      "===============================================\n",
      "['astigarraga', 'loiola', 'martutene', 'municipality']\n",
      "['ulia', 'donostia', 'pasaia', 'gardens']\n",
      "Got the keywords in 0.2630 seconds\n",
      "Got the embeddings and comparisons in 0.0009 seconds\n",
      "Coherence Map: [[]], KW Curr: ['astigarraga', 'loiola', 'martutene', 'municipality']\n",
      "weighted: tensor([0.1914])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.1914])\n",
      "===============================================\n",
      "['ulia', 'donostia', 'pasaia', 'gardens']\n",
      "['exclave', 'zubieta', 'donostia', 'village']\n",
      "Got the keywords in 0.2368 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['ulia', 'exclave']], KW Curr: ['ulia', 'donostia', 'pasaia', 'gardens']\n",
      "weighted: tensor([0.3102])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3102])\n",
      "===============================================\n",
      "['exclave', 'zubieta', 'donostia', 'village']\n",
      "['festivals', 'wrocław', 'sebastián', 'festival']\n",
      "Got the keywords in 0.3336 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals']], KW Curr: ['exclave', 'zubieta', 'donostia', 'village']\n",
      "weighted: tensor([0.3893])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3893])\n",
      "===============================================\n",
      "['festivals', 'wrocław', 'sebastián', 'festival']\n",
      "['festival', 'tamborrada', 'celebrations', 'feast']\n",
      "Got the keywords in 0.4504 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals']], KW Curr: ['festivals', 'wrocław', 'sebastián', 'festival']\n",
      "weighted: tensor([0.4343])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4343])\n",
      "===============================================\n",
      "['festival', 'tamborrada', 'celebrations', 'feast']\n",
      "['festival', 'fireworks', 'semana', 'grande']\n",
      "Got the keywords in 0.2811 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana']], KW Curr: ['festival', 'tamborrada', 'celebrations', 'feast']\n",
      "weighted: tensor([0.4352])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4352])\n",
      "===============================================\n",
      "['festival', 'fireworks', 'semana', 'grande']\n",
      "['festival', 'biscay', 'rowing', 'basque']\n",
      "Got the keywords in 0.2827 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande']], KW Curr: ['festival', 'fireworks', 'semana', 'grande']\n",
      "weighted: tensor([0.3506])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3506])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['festival', 'biscay', 'rowing', 'basque']\n",
      "['agatha', 'saint', 'carnival', 'eve']\n",
      "Got the keywords in 0.2731 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival']], KW Curr: ['festival', 'biscay', 'rowing', 'basque']\n",
      "weighted: tensor([0.2798])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2798])\n",
      "===============================================\n",
      "['agatha', 'saint', 'carnival', 'eve']\n",
      "['festival', 'gypsy', 'romani', 'carnival']\n",
      "Got the keywords in 0.2211 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival'], ['festival', 'agatha', 'gypsy', 'saint']], KW Curr: ['agatha', 'saint', 'carnival', 'eve']\n",
      "weighted: tensor([0.2851])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2851])\n",
      "===============================================\n",
      "['festival', 'gypsy', 'romani', 'carnival']\n",
      "['festival', 'gipuzkoa', 'chorizo', 'konstituzio']\n",
      "Got the keywords in 0.2451 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival'], ['festival', 'agatha', 'gypsy', 'saint'], ['festival', 'festival', 'romani', 'chorizo']], KW Curr: ['festival', 'gypsy', 'romani', 'carnival']\n",
      "weighted: tensor([0.3501])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3501])\n",
      "===============================================\n",
      "['festival', 'gipuzkoa', 'chorizo', 'konstituzio']\n",
      "['christmas', 'basque', 'villages', 'streets']\n",
      "Got the keywords in 0.2174 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival'], ['festival', 'agatha', 'gypsy', 'saint'], ['festival', 'festival', 'romani', 'chorizo'], ['festival', 'gipuzkoa', 'christmas', 'streets']], KW Curr: ['festival', 'gipuzkoa', 'chorizo', 'konstituzio']\n",
      "weighted: tensor([0.2872])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2872])\n",
      "===============================================\n",
      "['christmas', 'basque', 'villages', 'streets']\n",
      "['tourism', 'sebastián', 'destinations', 'spain']\n",
      "Got the keywords in 0.1457 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival'], ['festival', 'agatha', 'gypsy', 'saint'], ['festival', 'festival', 'romani', 'chorizo'], ['festival', 'gipuzkoa', 'christmas', 'streets'], ['tourism', 'spain', 'basque', 'streets']], KW Curr: ['christmas', 'basque', 'villages', 'streets']\n",
      "weighted: tensor([0.2755])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2755])\n",
      "===============================================\n",
      "['tourism', 'sebastián', 'destinations', 'spain']\n",
      "['donostia', 'cuisine', 'restaurants', 'culinary']\n",
      "Got the keywords in 0.2078 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['ulia', 'exclave'], ['exclave', 'festivals'], ['festival', 'tamborrada', 'celebrations', 'festivals'], ['festival', 'festival', 'tamborrada', 'semana'], ['festival', 'festival', 'biscay', 'grande'], ['biscay', 'rowing', 'saint', 'carnival'], ['festival', 'agatha', 'gypsy', 'saint'], ['festival', 'festival', 'romani', 'chorizo'], ['festival', 'gipuzkoa', 'christmas', 'streets'], ['tourism', 'spain', 'basque', 'streets'], []], KW Curr: ['tourism', 'sebastián', 'destinations', 'spain']\n",
      "weighted: tensor([0.2178])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2178])\n",
      "===============================================\n",
      "['donostia', 'cuisine', 'restaurants', 'culinary']\n",
      "['universidad', 'donostia', 'university', 'universities']\n",
      "Got the keywords in 0.3104 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad']], KW Curr: ['donostia', 'cuisine', 'restaurants', 'culinary']\n",
      "weighted: tensor([0.2926])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2926])\n",
      "===============================================\n",
      "['universidad', 'donostia', 'university', 'universities']\n",
      "['sociedad', 'liga', 'anoeta', 'stadium']\n",
      "Got the keywords in 0.3409 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university']], KW Curr: ['universidad', 'donostia', 'university', 'universities']\n",
      "weighted: tensor([0.3685])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3685])\n",
      "===============================================\n",
      "['sociedad', 'liga', 'anoeta', 'stadium']\n",
      "['hospers', 'sioux', 'railroad', 'founded']\n",
      "Got the keywords in 0.1952 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers']], KW Curr: ['sociedad', 'liga', 'anoeta', 'stadium']\n",
      "weighted: tensor([0.3483])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3483])\n",
      "===============================================\n",
      "['hospers', 'sioux', 'railroad', 'founded']\n",
      "['hospers', 'located', 'area', 'city']\n",
      "Got the keywords in 0.1132 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located']], KW Curr: ['hospers', 'sioux', 'railroad', 'founded']\n",
      "weighted: tensor([0.3368])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3368])\n",
      "===============================================\n",
      "['hospers', 'located', 'area', 'city']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1978 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households']], KW Curr: ['hospers', 'located', 'area', 'city']\n",
      "weighted: tensor([0.3205])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3205])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', '280']\n",
      "Got the keywords in 0.3290 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.5334])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5334])\n",
      "===============================================\n",
      "['population', 'census', 'households', '280']\n",
      "['hospers', 'school', 'moc', 'students']\n",
      "Got the keywords in 0.2156 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280']], KW Curr: ['population', 'census', 'households', '280']\n",
      "weighted: tensor([0.4027])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4027])\n",
      "===============================================\n",
      "['hospers', 'school', 'moc', 'students']\n",
      "['izyum', 'izium', 'ukraine', 'tatars']\n",
      "Got the keywords in 0.2067 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc']], KW Curr: ['hospers', 'school', 'moc', 'students']\n",
      "weighted: tensor([0.3009])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3009])\n",
      "===============================================\n",
      "['izyum', 'izium', 'ukraine', 'tatars']\n",
      "['izium', '1943', 'bridgehead', '1942']\n",
      "Got the keywords in 0.1963 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc'], ['izium', 'izium', 'bridgehead', 'ukraine']], KW Curr: ['izyum', 'izium', 'ukraine', 'tatars']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted: tensor([0.3032])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3032])\n",
      "===============================================\n",
      "['izium', '1943', 'bridgehead', '1942']\n",
      "['sloviansk', 'ukraine', 'izium', 'russia']\n",
      "Got the keywords in 0.2837 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc'], ['izium', 'izium', 'bridgehead', 'ukraine'], ['sloviansk', 'ukraine', 'izium', 'izium']], KW Curr: ['izium', '1943', 'bridgehead', '1942']\n",
      "weighted: tensor([0.4422])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4422])\n",
      "===============================================\n",
      "['sloviansk', 'ukraine', 'izium', 'russia']\n",
      "['lennon', 'square', 'soviet', 'decommunization']\n",
      "Got the keywords in 0.2523 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc'], ['izium', 'izium', 'bridgehead', 'ukraine'], ['sloviansk', 'ukraine', 'izium', 'izium'], ['sloviansk', 'ukraine', 'lennon', 'decommunization']], KW Curr: ['sloviansk', 'ukraine', 'izium', 'russia']\n",
      "weighted: tensor([0.4159])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4159])\n",
      "===============================================\n",
      "['lennon', 'square', 'soviet', 'decommunization']\n",
      "['köppen', 'climate', 'warm', 'dfb']\n",
      "Got the keywords in 0.0851 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc'], ['izium', 'izium', 'bridgehead', 'ukraine'], ['sloviansk', 'ukraine', 'izium', 'izium'], ['sloviansk', 'ukraine', 'lennon', 'decommunization'], ['köppen', 'soviet']], KW Curr: ['lennon', 'square', 'soviet', 'decommunization']\n",
      "weighted: tensor([0.2605])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2605])\n",
      "===============================================\n",
      "['köppen', 'climate', 'warm', 'dfb']\n",
      "['wallingford', 'area', 'located', 'city']\n",
      "Got the keywords in 0.1115 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['donostia', 'universidad'], ['sociedad', 'universidad', 'liga', 'university'], ['sociedad', 'hospers'], ['hospers', 'located'], ['hospers', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'hospers', 'census', '280'], ['izium', 'moc'], ['izium', 'izium', 'bridgehead', 'ukraine'], ['sloviansk', 'ukraine', 'izium', 'izium'], ['sloviansk', 'ukraine', 'lennon', 'decommunization'], ['köppen', 'soviet'], []], KW Curr: ['köppen', 'climate', 'warm', 'dfb']\n",
      "weighted: tensor([0.2123])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.2123])\n",
      "===============================================\n",
      "['wallingford', 'area', 'located', 'city']\n",
      "['census', 'population', 'households', 'household']\n",
      "Got the keywords in 0.1384 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households']], KW Curr: ['wallingford', 'area', 'located', 'city']\n",
      "weighted: tensor([0.2773])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2773])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'household']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.2496 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population']], KW Curr: ['census', 'population', 'households', 'household']\n",
      "weighted: tensor([0.5813])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5813])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['banya', 'gora', 'resort', 'valley']\n",
      "Got the keywords in 0.2569 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], []], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.2557])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2557])\n",
      "===============================================\n",
      "['banya', 'gora', 'resort', 'valley']\n",
      "['hydrotherapy', 'hydrothermal', 'village', 'ancient']\n",
      "Got the keywords in 0.1679 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora']], KW Curr: ['banya', 'gora', 'resort', 'valley']\n",
      "weighted: tensor([0.2647])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2647])\n",
      "===============================================\n",
      "['hydrotherapy', 'hydrothermal', 'village', 'ancient']\n",
      "['boris', 'palace', 'banya', 'bagarov']\n",
      "Got the keywords in 0.1314 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris']], KW Curr: ['hydrotherapy', 'hydrothermal', 'village', 'ancient']\n",
      "weighted: tensor([0.2741])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2741])\n",
      "===============================================\n",
      "['boris', 'palace', 'banya', 'bagarov']\n",
      "['harvard', 'railroad', '1871', 'massachusetts']\n",
      "Got the keywords in 0.1369 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris']], KW Curr: ['boris', 'palace', 'banya', 'bagarov']\n",
      "weighted: tensor([0.3041])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3041])\n",
      "===============================================\n",
      "['harvard', 'railroad', '1871', 'massachusetts']\n",
      "['harvard', 'area', 'located', '096554']\n",
      "Got the keywords in 0.1006 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554']], KW Curr: ['harvard', 'railroad', '1871', 'massachusetts']\n",
      "weighted: tensor([0.2735])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2735])\n",
      "===============================================\n",
      "['harvard', 'area', 'located', '096554']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1798 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households']], KW Curr: ['harvard', 'area', 'located', '096554']\n",
      "weighted: tensor([0.3256])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3256])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.2685 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.4741])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4741])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['population', 'census', 'households', 'families']\n",
      "['suva', 'fiji', 'polynesia', 'islands']\n",
      "Got the keywords in 0.3807 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3657])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3657])\n",
      "===============================================\n",
      "['suva', 'fiji', 'polynesia', 'islands']\n",
      "['suva', 'fiji', 'pacific', 'viti']\n",
      "Got the keywords in 0.3665 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji']], KW Curr: ['suva', 'fiji', 'polynesia', 'islands']\n",
      "weighted: tensor([0.4252])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4252])\n",
      "===============================================\n",
      "['suva', 'fiji', 'pacific', 'viti']\n",
      "['suva', 'central', 'wards', 'area']\n",
      "Got the keywords in 0.2972 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti']], KW Curr: ['suva', 'fiji', 'pacific', 'viti']\n",
      "weighted: tensor([0.3110])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3110])\n",
      "===============================================\n",
      "['suva', 'central', 'wards', 'area']\n",
      "['areas', 'muanikau', 'zones', 'tamavua']\n",
      "Got the keywords in 0.1481 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti'], ['suva', 'central', 'areas', 'muanikau']], KW Curr: ['suva', 'central', 'wards', 'area']\n",
      "weighted: tensor([0.3970])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3970])\n",
      "===============================================\n",
      "['areas', 'muanikau', 'zones', 'tamavua']\n",
      "['suva', 'areas', 'rewa', 'corridor']\n",
      "Got the keywords in 0.2050 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti'], ['suva', 'central', 'areas', 'muanikau'], ['areas', 'muanikau', 'rewa', 'corridor']], KW Curr: ['areas', 'muanikau', 'zones', 'tamavua']\n",
      "weighted: tensor([0.5121])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5121])\n",
      "===============================================\n",
      "['suva', 'areas', 'rewa', 'corridor']\n",
      "['suva', 'climate', 'weather', 'rainfall']\n",
      "Got the keywords in 0.2615 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti'], ['suva', 'central', 'areas', 'muanikau'], ['areas', 'muanikau', 'rewa', 'corridor'], ['suva', 'suva']], KW Curr: ['suva', 'areas', 'rewa', 'corridor']\n",
      "weighted: tensor([0.3369])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3369])\n",
      "===============================================\n",
      "['suva', 'climate', 'weather', 'rainfall']\n",
      "['suva', 'fijian', 'fijians', 'fiji']\n",
      "Got the keywords in 0.2808 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti'], ['suva', 'central', 'areas', 'muanikau'], ['areas', 'muanikau', 'rewa', 'corridor'], ['suva', 'suva'], []], KW Curr: ['suva', 'climate', 'weather', 'rainfall']\n",
      "weighted: tensor([0.2833])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2833])\n",
      "===============================================\n",
      "['suva', 'fijian', 'fijians', 'fiji']\n",
      "['suva', 'fiji', 'councillors', 'municipal']\n",
      "Got the keywords in 0.2436 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['wallingford', 'census', 'population', 'households'], ['census', 'census', 'population', 'population'], [], ['hydrotherapy', 'banya', 'ancient', 'gora'], ['hydrotherapy', 'boris'], ['harvard', 'boris'], ['harvard', '096554'], ['harvard', 'census', 'population', 'households'], ['population', 'census', 'census', 'population'], ['suva', 'census', 'fiji', 'polynesia'], ['suva', 'suva', 'fiji', 'fiji'], ['central', 'area', 'pacific', 'viti'], ['suva', 'central', 'areas', 'muanikau'], ['areas', 'muanikau', 'rewa', 'corridor'], ['suva', 'suva'], [], ['fijian', 'municipal']], KW Curr: ['suva', 'fijian', 'fijians', 'fiji']\n",
      "weighted: tensor([0.2047])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2047])\n",
      "===============================================\n",
      "['suva', 'fiji', 'councillors', 'municipal']\n",
      "['fiji', 'fijian', 'suva', 'buildings']\n",
      "Got the keywords in 0.3048 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva']], KW Curr: ['suva', 'fiji', 'councillors', 'municipal']\n",
      "weighted: tensor([0.4500])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4500])\n",
      "===============================================\n",
      "['fiji', 'fijian', 'suva', 'buildings']\n",
      "['suva', 'fiji', 'fijians', 'pacific']\n",
      "Got the keywords in 0.3962 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva'], []], KW Curr: ['fiji', 'fijian', 'suva', 'buildings']\n",
      "weighted: tensor([0.2743])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2743])\n",
      "===============================================\n",
      "['suva', 'fiji', 'fijians', 'pacific']\n",
      "['suva', 'fiji', 'oceania', 'pacific']\n",
      "Got the keywords in 0.3825 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva'], [], ['suva', 'fiji']], KW Curr: ['suva', 'fiji', 'fijians', 'pacific']\n",
      "weighted: tensor([0.2557])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2557])\n",
      "===============================================\n",
      "['suva', 'fiji', 'oceania', 'pacific']\n",
      "['suva', 'oceania', 'regional', 'infrastructure']\n",
      "Got the keywords in 0.2636 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva'], [], ['suva', 'fiji'], ['suva', 'suva', 'pacific', 'infrastructure']], KW Curr: ['suva', 'fiji', 'oceania', 'pacific']\n",
      "weighted: tensor([0.3506])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3506])\n",
      "===============================================\n",
      "['suva', 'oceania', 'regional', 'infrastructure']\n",
      "['suva', 'seats', 'seating', 'venues']\n",
      "Got the keywords in 0.1496 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva'], [], ['suva', 'fiji'], ['suva', 'suva', 'pacific', 'infrastructure'], []], KW Curr: ['suva', 'oceania', 'regional', 'infrastructure']\n",
      "weighted: tensor([0.2844])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2844])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suva', 'seats', 'seating', 'venues']\n",
      "['suva', 'fiji', 'gardens', 'garden']\n",
      "Got the keywords in 0.1976 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'fiji', 'fijian', 'suva'], [], ['suva', 'fiji'], ['suva', 'suva', 'pacific', 'infrastructure'], [], []], KW Curr: ['suva', 'seats', 'seating', 'venues']\n",
      "weighted: tensor([0.1885])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.1885])\n",
      "===============================================\n",
      "['suva', 'fiji', 'gardens', 'garden']\n",
      "['suva', 'concerts', 'performances', 'singers']\n",
      "Got the keywords in 0.2432 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji']], KW Curr: ['suva', 'fiji', 'gardens', 'garden']\n",
      "weighted: tensor([0.3086])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3086])\n",
      "===============================================\n",
      "['suva', 'concerts', 'performances', 'singers']\n",
      "['suva', 'fijian', 'fijians', 'fiji']\n",
      "Got the keywords in 0.2314 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts']], KW Curr: ['suva', 'concerts', 'performances', 'singers']\n",
      "weighted: tensor([0.3285])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3285])\n",
      "===============================================\n",
      "['suva', 'fijian', 'fijians', 'fiji']\n",
      "['festivals', 'festival', 'suva', 'carnival']\n",
      "Got the keywords in 0.1883 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva']], KW Curr: ['suva', 'fijian', 'fijians', 'fiji']\n",
      "weighted: tensor([0.2582])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2582])\n",
      "===============================================\n",
      "['festivals', 'festival', 'suva', 'carnival']\n",
      "['suva', 'nightlife', 'nightclubs', 'lounges']\n",
      "Got the keywords in 0.1974 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife']], KW Curr: ['festivals', 'festival', 'suva', 'carnival']\n",
      "weighted: tensor([0.3389])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3389])\n",
      "===============================================\n",
      "['suva', 'nightlife', 'nightclubs', 'lounges']\n",
      "['suva', 'theatres', 'laucala', 'cinema']\n",
      "Got the keywords in 0.2060 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs']], KW Curr: ['suva', 'nightlife', 'nightclubs', 'lounges']\n",
      "weighted: tensor([0.3258])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3258])\n",
      "===============================================\n",
      "['suva', 'theatres', 'laucala', 'cinema']\n",
      "['suva', 'fiji', 'pacific', 'stadium']\n",
      "Got the keywords in 0.2045 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema']], KW Curr: ['suva', 'theatres', 'laucala', 'cinema']\n",
      "weighted: tensor([0.2536])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2536])\n",
      "===============================================\n",
      "['suva', 'fiji', 'pacific', 'stadium']\n",
      "['suva', 'fiji', 'stations', 'broadcasters']\n",
      "Got the keywords in 0.2337 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema'], ['suva', 'suva']], KW Curr: ['suva', 'fiji', 'pacific', 'stadium']\n",
      "weighted: tensor([0.3195])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3195])\n",
      "===============================================\n",
      "['suva', 'fiji', 'stations', 'broadcasters']\n",
      "['suva', 'shopping', 'areas', 'stores']\n",
      "Got the keywords in 0.4000 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema'], ['suva', 'suva'], ['suva', 'suva']], KW Curr: ['suva', 'fiji', 'stations', 'broadcasters']\n",
      "weighted: tensor([0.3747])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3747])\n",
      "===============================================\n",
      "['suva', 'shopping', 'areas', 'stores']\n",
      "['auckland', 'suva', 'fiji', 'airport']\n",
      "Got the keywords in 0.4221 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema'], ['suva', 'suva'], ['suva', 'suva'], ['suva', 'auckland', 'suva', 'shopping']], KW Curr: ['suva', 'shopping', 'areas', 'stores']\n",
      "weighted: tensor([0.4534])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4534])\n",
      "===============================================\n",
      "['auckland', 'suva', 'fiji', 'airport']\n",
      "['suva', 'fiji', 'actress', 'australian']\n",
      "Got the keywords in 0.3628 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema'], ['suva', 'suva'], ['suva', 'suva'], ['suva', 'auckland', 'suva', 'shopping'], []], KW Curr: ['auckland', 'suva', 'fiji', 'airport']\n",
      "weighted: tensor([0.3096])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3096])\n",
      "===============================================\n",
      "['suva', 'fiji', 'actress', 'australian']\n",
      "['osaka', 'kashiwara', 'prefecture', 'fujidera']\n",
      "Got the keywords in 0.2704 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['suva', 'suva', 'concerts', 'fiji'], ['suva', 'suva', 'fijian', 'concerts'], ['fijian', 'suva'], ['suva', 'suva', 'carnival', 'nightlife'], ['suva', 'suva', 'nightlife', 'nightclubs'], ['fiji', 'theatres', 'pacific', 'cinema'], ['suva', 'suva'], ['suva', 'suva'], ['suva', 'auckland', 'suva', 'shopping'], [], ['australian', 'fujidera']], KW Curr: ['suva', 'fiji', 'actress', 'australian']\n",
      "weighted: tensor([0.2164])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.2164])\n",
      "===============================================\n",
      "['osaka', 'kashiwara', 'prefecture', 'fujidera']\n",
      "['kashiwara', 'kawachi', 'kokubu', 'kansai']\n",
      "Got the keywords in 0.1720 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [[]], KW Curr: ['osaka', 'kashiwara', 'prefecture', 'fujidera']\n",
      "weighted: tensor([0.2025])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2025])\n",
      "===============================================\n",
      "['kashiwara', 'kawachi', 'kokubu', 'kansai']\n",
      "['havana', 'area', 'located', 'city']\n",
      "Got the keywords in 0.1444 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['kashiwara', 'kawachi', 'area', 'city']], KW Curr: ['kashiwara', 'kawachi', 'kokubu', 'kansai']\n",
      "weighted: tensor([0.3508])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3508])\n",
      "===============================================\n",
      "['havana', 'area', 'located', 'city']\n",
      "['greenville', 'havana', 'marvinville', 'station']\n",
      "Got the keywords in 0.1503 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['kashiwara', 'kawachi', 'area', 'city'], ['havana', 'greenville', 'havana', 'city']], KW Curr: ['havana', 'area', 'located', 'city']\n",
      "weighted: tensor([0.2377])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2377])\n",
      "===============================================\n",
      "['greenville', 'havana', 'marvinville', 'station']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.2033 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census']], KW Curr: ['greenville', 'havana', 'marvinville', 'station']\n",
      "weighted: tensor([0.3794])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3794])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['alvarado', 'mexico', 'city', 'office']\n",
      "Got the keywords in 0.1826 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3647])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3647])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alvarado', 'mexico', 'city', 'office']\n",
      "['area', 'census', 'land', 'city']\n",
      "Got the keywords in 0.0909 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office']], KW Curr: ['alvarado', 'mexico', 'city', 'office']\n",
      "weighted: tensor([0.2909])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2909])\n",
      "===============================================\n",
      "['area', 'census', 'land', 'city']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1647 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city']], KW Curr: ['area', 'census', 'land', 'city']\n",
      "weighted: tensor([0.2769])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2769])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'household']\n",
      "Got the keywords in 0.2545 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.4890])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4890])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'household']\n",
      "['hanska', 'incorporated', 'village', '1890']\n",
      "Got the keywords in 0.1937 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households']], KW Curr: ['population', 'census', 'households', 'household']\n",
      "weighted: tensor([0.4015])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4015])\n",
      "===============================================\n",
      "['hanska', 'incorporated', 'village', '1890']\n",
      "['area', 'census', 'land', 'city']\n",
      "Got the keywords in 0.0862 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city']], KW Curr: ['hanska', 'incorporated', 'village', '1890']\n",
      "weighted: tensor([0.3392])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3392])\n",
      "===============================================\n",
      "['area', 'census', 'land', 'city']\n",
      "['census', 'population', 'households', 'household']\n",
      "Got the keywords in 0.1595 seconds\n",
      "Got the embeddings and comparisons in 0.0007 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city']], KW Curr: ['area', 'census', 'land', 'city']\n",
      "weighted: tensor([0.2854])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2854])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'household']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.2660 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population']], KW Curr: ['census', 'population', 'households', 'household']\n",
      "weighted: tensor([0.5920])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5920])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['washta', 'sioux', 'located', 'area']\n",
      "Got the keywords in 0.2126 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.4799])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4799])\n",
      "===============================================\n",
      "['washta', 'sioux', 'located', 'area']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1874 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households']], KW Curr: ['washta', 'sioux', 'located', 'area']\n",
      "weighted: tensor([0.5025])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5025])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', '282']\n",
      "Got the keywords in 0.2597 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.5326])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5326])\n",
      "===============================================\n",
      "['population', 'census', 'households', '282']\n",
      "['prairie', 'reed', 'ada', 'daggs']\n",
      "Got the keywords in 0.3304 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada']], KW Curr: ['population', 'census', 'households', '282']\n",
      "weighted: tensor([0.3952])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3952])\n",
      "===============================================\n",
      "['prairie', 'reed', 'ada', 'daggs']\n",
      "['ada', 'park', 'camp', 'bebee']\n",
      "Got the keywords in 0.2725 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], []], KW Curr: ['prairie', 'reed', 'ada', 'daggs']\n",
      "weighted: tensor([0.2924])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2924])\n",
      "===============================================\n",
      "['ada', 'park', 'camp', 'bebee']\n",
      "['ada', 'oklahoma', 'tulsa', 'texas']\n",
      "Got the keywords in 0.1524 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp']], KW Curr: ['ada', 'park', 'camp', 'bebee']\n",
      "weighted: tensor([0.3245])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3245])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'oklahoma', 'tulsa', 'texas']\n",
      "['ada', 'census', 'population', 'households']\n",
      "Got the keywords in 0.2298 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada']], KW Curr: ['ada', 'oklahoma', 'tulsa', 'texas']\n",
      "weighted: tensor([0.3950])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3950])\n",
      "===============================================\n",
      "['ada', 'census', 'population', 'households']\n",
      "['ada', 'headquartered', 'headquarters', 'companies']\n",
      "Got the keywords in 0.4269 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered']], KW Curr: ['ada', 'census', 'population', 'households']\n",
      "weighted: tensor([0.4657])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4657])\n",
      "===============================================\n",
      "['ada', 'headquartered', 'headquarters', 'companies']\n",
      "['ecu', 'university', 'central', 'accredited']\n",
      "Got the keywords in 0.2851 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central']], KW Curr: ['ada', 'headquartered', 'headquarters', 'companies']\n",
      "weighted: tensor([0.4552])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4552])\n",
      "===============================================\n",
      "['ecu', 'university', 'central', 'accredited']\n",
      "['ada', 'schools', 'school', 'glenwood']\n",
      "Got the keywords in 0.1544 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school']], KW Curr: ['ecu', 'university', 'central', 'accredited']\n",
      "weighted: tensor([0.3355])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3355])\n",
      "===============================================\n",
      "['ada', 'schools', 'school', 'glenwood']\n",
      "['pontotoc', 'located', 'tech', 'area']\n",
      "Got the keywords in 0.1367 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located']], KW Curr: ['ada', 'schools', 'school', 'glenwood']\n",
      "weighted: tensor([0.3387])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3387])\n",
      "===============================================\n",
      "['pontotoc', 'located', 'tech', 'area']\n",
      "['ada', 'oklahoma', 'convicted', 'prosecutor']\n",
      "Got the keywords in 0.2090 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor']], KW Curr: ['pontotoc', 'located', 'tech', 'area']\n",
      "weighted: tensor([0.3490])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3490])\n",
      "===============================================\n",
      "['ada', 'oklahoma', 'convicted', 'prosecutor']\n",
      "['comodoro', 'jorge', 'tehuelche', 'rivadavia']\n",
      "Got the keywords in 0.4006 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge']], KW Curr: ['ada', 'oklahoma', 'convicted', 'prosecutor']\n",
      "weighted: tensor([0.3836])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3836])\n",
      "===============================================\n",
      "['comodoro', 'jorge', 'tehuelche', 'rivadavia']\n",
      "['afrikaners', 'afrikaner', 'settlers', 'argentina']\n",
      "Got the keywords in 0.5278 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers']], KW Curr: ['comodoro', 'jorge', 'tehuelche', 'rivadavia']\n",
      "weighted: tensor([0.4932])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4932])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afrikaners', 'afrikaner', 'settlers', 'argentina']\n",
      "['comodoro', 'rivadavia', 'climate', 'arid']\n",
      "Got the keywords in 0.3638 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers'], ['afrikaners', 'comodoro']], KW Curr: ['afrikaners', 'afrikaner', 'settlers', 'argentina']\n",
      "weighted: tensor([0.3712])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3712])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'climate', 'arid']\n",
      "['comodoro', 'rivadavia', 'population', 'argentina']\n",
      "Got the keywords in 0.2031 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers'], ['afrikaners', 'comodoro'], ['comodoro', 'rivadavia', 'comodoro', 'rivadavia']], KW Curr: ['comodoro', 'rivadavia', 'climate', 'arid']\n",
      "weighted: tensor([0.4065])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4065])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'population', 'argentina']\n",
      "['comodoro', 'rivadavia', 'colorado', 'cerro']\n",
      "Got the keywords in 0.3643 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers'], ['afrikaners', 'comodoro'], ['comodoro', 'rivadavia', 'comodoro', 'rivadavia'], ['comodoro', 'comodoro', 'rivadavia', 'rivadavia']], KW Curr: ['comodoro', 'rivadavia', 'population', 'argentina']\n",
      "weighted: tensor([0.4824])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4824])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'colorado', 'cerro']\n",
      "['industrial', 'industry', 'factories', 'activities']\n",
      "Got the keywords in 0.3008 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers'], ['afrikaners', 'comodoro'], ['comodoro', 'rivadavia', 'comodoro', 'rivadavia'], ['comodoro', 'comodoro', 'rivadavia', 'rivadavia'], []], KW Curr: ['comodoro', 'rivadavia', 'colorado', 'cerro']\n",
      "weighted: tensor([0.2585])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2585])\n",
      "===============================================\n",
      "['industrial', 'industry', 'factories', 'activities']\n",
      "['oil', 'started', 'petrolíferos', 'industry']\n",
      "Got the keywords in 0.2929 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['greenville', 'havana', 'population', 'census'], ['alvarado', 'population'], ['census', 'office'], ['census', 'city'], ['census', 'population', 'population', 'census'], ['hanska', 'population', 'census', 'households'], ['hanska', 'city'], ['population', 'city'], ['population', 'census', 'census', 'population'], ['washta', 'population', 'census', 'households'], ['washta', 'census', 'population', 'households'], ['census', 'population', 'population', 'households'], ['population', 'prairie', 'reed', 'ada'], [], ['tulsa', 'ada', 'texas', 'camp'], ['ada', 'ada'], ['ada', 'ada', 'census', 'headquartered'], ['ecu', 'ada', 'university', 'central'], ['ecu', 'school'], ['pontotoc', 'ada', 'schools', 'located'], ['pontotoc', 'prosecutor'], ['ada', 'comodoro', 'oklahoma', 'jorge'], ['afrikaners', 'afrikaner', 'comodoro', 'settlers'], ['afrikaners', 'comodoro'], ['comodoro', 'rivadavia', 'comodoro', 'rivadavia'], ['comodoro', 'comodoro', 'rivadavia', 'rivadavia'], [], []], KW Curr: ['industrial', 'industry', 'factories', 'activities']\n",
      "weighted: tensor([0.1976])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.1976])\n",
      "===============================================\n",
      "['oil', 'started', 'petrolíferos', 'industry']\n",
      "['comodoro', 'rivadavia', 'argentina', 'jorge']\n",
      "Got the keywords in 0.2794 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos']], KW Curr: ['oil', 'started', 'petrolíferos', 'industry']\n",
      "weighted: tensor([0.3628])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3628])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'argentina', 'jorge']\n",
      "['argentine', 'comodoro', 'rivadavia', 'longitude']\n",
      "Got the keywords in 0.1478 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine']], KW Curr: ['comodoro', 'rivadavia', 'argentina', 'jorge']\n",
      "weighted: tensor([0.3733])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3733])\n",
      "===============================================\n",
      "['argentine', 'comodoro', 'rivadavia', 'longitude']\n",
      "['comodoro', 'rivadavia', 'port', 'ships']\n",
      "Got the keywords in 0.1544 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia']], KW Curr: ['argentine', 'comodoro', 'rivadavia', 'longitude']\n",
      "weighted: tensor([0.5553])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5553])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'port', 'ships']\n",
      "['shipyard', 'pier', 'port', 'punta']\n",
      "Got the keywords in 0.2525 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta']], KW Curr: ['comodoro', 'rivadavia', 'port', 'ships']\n",
      "weighted: tensor([0.4228])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4228])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shipyard', 'pier', 'port', 'punta']\n",
      "['concrete', 'portland', 'production', 'petroquimica']\n",
      "Got the keywords in 0.2864 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port']], KW Curr: ['shipyard', 'pier', 'port', 'punta']\n",
      "weighted: tensor([0.4953])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4953])\n",
      "===============================================\n",
      "['concrete', 'portland', 'production', 'petroquimica']\n",
      "['rivadavia', 'comodoro', 'wind', 'generators']\n",
      "Got the keywords in 0.1420 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland']], KW Curr: ['concrete', 'portland', 'production', 'petroquimica']\n",
      "weighted: tensor([0.4011])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4011])\n",
      "===============================================\n",
      "['rivadavia', 'comodoro', 'wind', 'generators']\n",
      "['comodoro', 'rivadavia', 'atlético', 'argentine']\n",
      "Got the keywords in 0.1996 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia']], KW Curr: ['rivadavia', 'comodoro', 'wind', 'generators']\n",
      "weighted: tensor([0.3471])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3471])\n",
      "===============================================\n",
      "['comodoro', 'rivadavia', 'atlético', 'argentine']\n",
      "['zolotonosha', 'strunkovka', 'ukraine', 'magdeburg']\n",
      "Got the keywords in 0.2671 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha']], KW Curr: ['comodoro', 'rivadavia', 'atlético', 'argentine']\n",
      "weighted: tensor([0.2911])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2911])\n",
      "===============================================\n",
      "['zolotonosha', 'strunkovka', 'ukraine', 'magdeburg']\n",
      "['chattanooga', 'nashville', 'founded', 'new']\n",
      "Got the keywords in 0.1702 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka']], KW Curr: ['zolotonosha', 'strunkovka', 'ukraine', 'magdeburg']\n",
      "weighted: tensor([0.3324])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3324])\n",
      "===============================================\n",
      "['chattanooga', 'nashville', 'founded', 'new']\n",
      "['hohenwald', 'located', 'area', '5479']\n",
      "Got the keywords in 0.1109 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479']], KW Curr: ['chattanooga', 'nashville', 'founded', 'new']\n",
      "weighted: tensor([0.3611])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3611])\n",
      "===============================================\n",
      "['hohenwald', 'located', 'area', '5479']\n",
      "['population', 'census', 'households', '332']\n",
      "Got the keywords in 0.1931 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households']], KW Curr: ['hohenwald', 'located', 'area', '5479']\n",
      "weighted: tensor([0.4437])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4437])\n",
      "===============================================\n",
      "['population', 'census', 'households', '332']\n",
      "['bay', 'springs', 'area', 'km²']\n",
      "Got the keywords in 0.2242 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households']], KW Curr: ['population', 'census', 'households', '332']\n",
      "weighted: tensor([0.4003])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4003])\n",
      "===============================================\n",
      "['bay', 'springs', 'area', 'km²']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.2204 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households']], KW Curr: ['bay', 'springs', 'area', 'km²']\n",
      "weighted: tensor([0.4724])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4724])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['springs', 'bay', 'company', 'manufacturing']\n",
      "Got the keywords in 0.3294 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.4610])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4610])\n",
      "===============================================\n",
      "['springs', 'bay', 'company', 'manufacturing']\n",
      "['bay', 'school', 'academy', 'springs']\n",
      "Got the keywords in 0.2089 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy']], KW Curr: ['springs', 'bay', 'company', 'manufacturing']\n",
      "weighted: tensor([0.3524])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3524])\n",
      "===============================================\n",
      "['bay', 'school', 'academy', 'springs']\n",
      "['humid', 'subtropical', 'climate', 'summers']\n",
      "Got the keywords in 0.0897 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school']], KW Curr: ['bay', 'school', 'academy', 'springs']\n",
      "weighted: tensor([0.3231])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3231])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['humid', 'subtropical', 'climate', 'summers']\n",
      "['delphi', 'erie', 'courthouse', 'county']\n",
      "Got the keywords in 0.2032 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie']], KW Curr: ['humid', 'subtropical', 'climate', 'summers']\n",
      "weighted: tensor([0.2880])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2880])\n",
      "===============================================\n",
      "['delphi', 'erie', 'courthouse', 'county']\n",
      "['delphi', 'census', 'area', 'located']\n",
      "Got the keywords in 0.1814 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie'], ['delphi', 'delphi', 'erie', 'census']], KW Curr: ['delphi', 'erie', 'courthouse', 'county']\n",
      "weighted: tensor([0.3552])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3552])\n",
      "===============================================\n",
      "['delphi', 'census', 'area', 'located']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1729 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie'], ['delphi', 'delphi', 'erie', 'census'], ['delphi', 'census', 'population', 'located']], KW Curr: ['delphi', 'census', 'area', 'located']\n",
      "weighted: tensor([0.3358])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3358])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.2731 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie'], ['delphi', 'delphi', 'erie', 'census'], ['delphi', 'census', 'population', 'located'], ['census', 'population', 'census', 'households']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.5313])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5313])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['delphi', 'schools', 'school', 'community']\n",
      "Got the keywords in 0.2173 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie'], ['delphi', 'delphi', 'erie', 'census'], ['delphi', 'census', 'population', 'located'], ['census', 'population', 'census', 'households'], ['census', 'community']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3039])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3039])\n",
      "===============================================\n",
      "['delphi', 'schools', 'school', 'community']\n",
      "['winter', 'spring', 'weather', 'iran']\n",
      "Got the keywords in 0.2167 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['comodoro', 'jorge', 'started', 'petrolíferos'], ['comodoro', 'argentine'], ['argentine', 'comodoro', 'comodoro', 'rivadavia'], ['pier', 'port', 'comodoro', 'punta'], ['shipyard', 'pier', 'concrete', 'port'], ['concrete', 'rivadavia', 'comodoro', 'portland'], ['comodoro', 'rivadavia'], ['comodoro', 'zolotonosha'], ['chattanooga', 'zolotonosha', 'nashville', 'strunkovka'], ['hohenwald', 'chattanooga', 'nashville', '5479'], ['hohenwald', 'population', 'census', 'households'], ['population', 'census', 'bay', 'households'], ['census', 'population', 'bay', 'households'], ['census', 'population', 'springs', 'bay'], ['springs', 'academy'], ['humid', 'climate', 'bay', 'school'], ['delphi', 'humid', 'subtropical', 'erie'], ['delphi', 'delphi', 'erie', 'census'], ['delphi', 'census', 'population', 'located'], ['census', 'population', 'census', 'households'], ['census', 'community'], ['winter', 'community']], KW Curr: ['delphi', 'schools', 'school', 'community']\n",
      "weighted: tensor([0.2462])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.2462])\n",
      "===============================================\n",
      "['winter', 'spring', 'weather', 'iran']\n",
      "['اچمی', 'dialect', 'larestani', 'ajami']\n",
      "Got the keywords in 0.2094 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [[]], KW Curr: ['winter', 'spring', 'weather', 'iran']\n",
      "weighted: tensor([0.1673])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.1673])\n",
      "===============================================\n",
      "['اچمی', 'dialect', 'larestani', 'ajami']\n",
      "['helix', 'oregon', 'oxford', 'named']\n",
      "Got the keywords in 0.1165 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon']], KW Curr: ['اچمی', 'dialect', 'larestani', 'ajami']\n",
      "weighted: tensor([0.3115])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3115])\n",
      "===============================================\n",
      "['helix', 'oregon', 'oxford', 'named']\n",
      "['area', 'census', 'land', 'city']\n",
      "Got the keywords in 0.1108 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city']], KW Curr: ['helix', 'oregon', 'oxford', 'named']\n",
      "weighted: tensor([0.2840])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2840])\n",
      "===============================================\n",
      "['area', 'census', 'land', 'city']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1687 seconds\n",
      "Got the embeddings and comparisons in 0.0009 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city']], KW Curr: ['area', 'census', 'land', 'city']\n",
      "weighted: tensor([0.2713])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2713])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census', 'population', 'households', 'families']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.2525 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.5981])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5981])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['helix', 'farm', 'farming', 'stateline']\n",
      "Got the keywords in 0.2095 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population'], []], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.2753])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2753])\n",
      "===============================================\n",
      "['helix', 'farm', 'farming', 'stateline']\n",
      "['wheatstock', 'festival', 'rodeo', 'memorial']\n",
      "Got the keywords in 0.1246 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population'], [], ['rodeo', 'farming']], KW Curr: ['helix', 'farm', 'farming', 'stateline']\n",
      "weighted: tensor([0.3054])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3054])\n",
      "===============================================\n",
      "['wheatstock', 'festival', 'rodeo', 'memorial']\n",
      "['são', 'paulo', 'altitude', 'located']\n",
      "Got the keywords in 0.1013 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population'], [], ['rodeo', 'farming'], ['altitude', 'rodeo', 'located', 'memorial']], KW Curr: ['wheatstock', 'festival', 'rodeo', 'memorial']\n",
      "weighted: tensor([0.3310])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3310])\n",
      "===============================================\n",
      "['são', 'paulo', 'altitude', 'located']\n",
      "['economy', 'agricultural', 'soybeans', 'cultivation']\n",
      "Got the keywords in 0.0904 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population'], [], ['rodeo', 'farming'], ['altitude', 'rodeo', 'located', 'memorial'], ['altitude', 'soybeans']], KW Curr: ['são', 'paulo', 'altitude', 'located']\n",
      "weighted: tensor([0.2751])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2751])\n",
      "===============================================\n",
      "['economy', 'agricultural', 'soybeans', 'cultivation']\n",
      "['ituverava', 'carmo', 'franca', 'guarani']\n",
      "Got the keywords in 0.1241 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['dialect', 'larestani', 'ajami', 'oregon'], ['area', 'helix', 'land', 'city'], ['population', 'city'], ['census', 'census', 'population', 'population'], [], ['rodeo', 'farming'], ['altitude', 'rodeo', 'located', 'memorial'], ['altitude', 'soybeans'], []], KW Curr: ['economy', 'agricultural', 'soybeans', 'cultivation']\n",
      "weighted: tensor([0.2200])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2200])\n",
      "===============================================\n",
      "['ituverava', 'carmo', 'franca', 'guarani']\n",
      "['shkodër', 'shkodra', 'skodra', 'şkodra']\n",
      "Got the keywords in 0.2375 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani']], KW Curr: ['ituverava', 'carmo', 'franca', 'guarani']\n",
      "weighted: tensor([0.3888])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3888])\n",
      "===============================================\n",
      "['shkodër', 'shkodra', 'skodra', 'şkodra']\n",
      "['shkodër', 'albania', 'kir', 'adriatic']\n",
      "Got the keywords in 0.3350 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër']], KW Curr: ['shkodër', 'shkodra', 'skodra', 'şkodra']\n",
      "weighted: tensor([0.4720])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4720])\n",
      "===============================================\n",
      "['shkodër', 'albania', 'kir', 'adriatic']\n",
      "['shkodër', 'climate', 'humid', 'temperature']\n",
      "Got the keywords in 0.2495 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir']], KW Curr: ['shkodër', 'albania', 'kir', 'adriatic']\n",
      "weighted: tensor([0.3520])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3520])\n",
      "===============================================\n",
      "['shkodër', 'climate', 'humid', 'temperature']\n",
      "['shkodër', 'earliest', 'serbs', 'scodra']\n",
      "Got the keywords in 0.2891 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs']], KW Curr: ['shkodër', 'climate', 'humid', 'temperature']\n",
      "weighted: tensor([0.2504])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2504])\n",
      "===============================================\n",
      "['shkodër', 'earliest', 'serbs', 'scodra']\n",
      "['shkodër', 'ottomans', 'sanjak', 'siege']\n",
      "Got the keywords in 0.4396 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest']], KW Curr: ['shkodër', 'earliest', 'serbs', 'scodra']\n",
      "weighted: tensor([0.4263])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4263])\n",
      "===============================================\n",
      "['shkodër', 'ottomans', 'sanjak', 'siege']\n",
      "['shkodër', 'prizren', 'albania', 'league']\n",
      "Got the keywords in 0.4113 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans']], KW Curr: ['shkodër', 'ottomans', 'sanjak', 'siege']\n",
      "weighted: tensor([0.3652])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3652])\n",
      "===============================================\n",
      "['shkodër', 'prizren', 'albania', 'league']\n",
      "['shkodër', 'albania', 'albanians', 'population']\n",
      "Got the keywords in 0.3653 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania']], KW Curr: ['shkodër', 'prizren', 'albania', 'league']\n",
      "weighted: tensor([0.4406])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4406])\n",
      "===============================================\n",
      "['shkodër', 'albania', 'albanians', 'population']\n",
      "['shkodër', 'municipality', 'municipalities', 'municipal']\n",
      "Got the keywords in 0.2759 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities']], KW Curr: ['shkodër', 'albania', 'albanians', 'population']\n",
      "weighted: tensor([0.4322])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4322])\n",
      "===============================================\n",
      "['shkodër', 'municipality', 'municipalities', 'municipal']\n",
      "['shkodër', 'shkodra', 'industries', 'industry']\n",
      "Got the keywords in 0.2314 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities']], KW Curr: ['shkodër', 'municipality', 'municipalities', 'municipal']\n",
      "weighted: tensor([0.2604])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2604])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shkodër', 'shkodra', 'industries', 'industry']\n",
      "['albania', 'tirana', 'shkodra', 'albanian']\n",
      "Got the keywords in 0.2611 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'albania', 'tirana']], KW Curr: ['shkodër', 'shkodra', 'industries', 'industry']\n",
      "weighted: tensor([0.4068])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4068])\n",
      "===============================================\n",
      "['albania', 'tirana', 'shkodra', 'albanian']\n",
      "['shkodër', 'shkodra', 'albania', 'castle']\n",
      "Got the keywords in 0.3260 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'albania', 'tirana'], ['shkodër', 'albania', 'tirana', 'albanian']], KW Curr: ['albania', 'tirana', 'shkodra', 'albanian']\n",
      "weighted: tensor([0.3201])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3201])\n",
      "===============================================\n",
      "['shkodër', 'shkodra', 'albania', 'castle']\n",
      "['music', 'percussion', 'bosnia', 'instruments']\n",
      "Got the keywords in 0.3466 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'albania', 'tirana'], ['shkodër', 'albania', 'tirana', 'albanian'], ['music', 'instruments', 'albania', 'castle']], KW Curr: ['shkodër', 'shkodra', 'albania', 'castle']\n",
      "weighted: tensor([0.2776])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2776])\n",
      "===============================================\n",
      "['music', 'percussion', 'bosnia', 'instruments']\n",
      "['rozafati', 'rozafa', 'shkodër', 'gurakuqi']\n",
      "Got the keywords in 0.5276 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'albania', 'tirana'], ['shkodër', 'albania', 'tirana', 'albanian'], ['music', 'instruments', 'albania', 'castle'], ['music', 'instruments', 'rozafati', 'gurakuqi']], KW Curr: ['music', 'percussion', 'bosnia', 'instruments']\n",
      "weighted: tensor([0.3528])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3528])\n",
      "===============================================\n",
      "['rozafati', 'rozafa', 'shkodër', 'gurakuqi']\n",
      "['shkodër', 'born', 'residents', 'personalities']\n",
      "Got the keywords in 0.3338 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['shkodër', 'ituverava', 'shkodra', 'guarani'], ['shkodër', 'shkodër'], ['shkodër', 'humid', 'temperature', 'kir'], ['shkodër', 'humid', 'temperature', 'serbs'], ['shkodër', 'shkodër', 'ottomans', 'earliest'], ['shkodër', 'shkodër', 'prizren', 'ottomans'], ['shkodër', 'shkodër', 'prizren', 'albania'], ['shkodër', 'shkodër', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'municipality', 'municipalities'], ['shkodër', 'shkodra', 'albania', 'tirana'], ['shkodër', 'albania', 'tirana', 'albanian'], ['music', 'instruments', 'albania', 'castle'], ['music', 'instruments', 'rozafati', 'gurakuqi'], ['shkodër', 'rozafati', 'rozafa', 'born']], KW Curr: ['rozafati', 'rozafa', 'shkodër', 'gurakuqi']\n",
      "weighted: tensor([0.2123])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2123])\n",
      "===============================================\n",
      "['shkodër', 'born', 'residents', 'personalities']\n",
      "['karamay', 'killed', 'death', 'teachers']\n",
      "Got the keywords in 0.2187 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['killed', 'born', 'residents', 'teachers']], KW Curr: ['shkodër', 'born', 'residents', 'personalities']\n",
      "weighted: tensor([0.2799])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2799])\n",
      "===============================================\n",
      "['karamay', 'killed', 'death', 'teachers']\n",
      "['dushanzi', 'karamay', 'tacheng', 'district']\n",
      "Got the keywords in 0.2427 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['killed', 'born', 'residents', 'teachers'], []], KW Curr: ['karamay', 'killed', 'death', 'teachers']\n",
      "weighted: tensor([0.2421])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2421])\n",
      "===============================================\n",
      "['dushanzi', 'karamay', 'tacheng', 'district']\n",
      "['karamay', 'baiyang', 'fengcheng', 'huangyangquan']\n",
      "Got the keywords in 0.2790 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [[]], KW Curr: ['dushanzi', 'karamay', 'tacheng', 'district']\n",
      "weighted: tensor([0.2135])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2135])\n",
      "===============================================\n",
      "['karamay', 'baiyang', 'fengcheng', 'huangyangquan']\n",
      "['karamay', 'climate', 'temperature', 'winters']\n",
      "Got the keywords in 0.3473 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature']], KW Curr: ['karamay', 'baiyang', 'fengcheng', 'huangyangquan']\n",
      "weighted: tensor([0.4299])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4299])\n",
      "===============================================\n",
      "['karamay', 'climate', 'temperature', 'winters']\n",
      "['karamay', 'population', 'census', 'inhabitants']\n",
      "Got the keywords in 0.2676 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate']], KW Curr: ['karamay', 'climate', 'temperature', 'winters']\n",
      "weighted: tensor([0.4433])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4433])\n",
      "===============================================\n",
      "['karamay', 'population', 'census', 'inhabitants']\n",
      "['gdp', 'oil', 'china', 'billion']\n",
      "Got the keywords in 0.1979 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census']], KW Curr: ['karamay', 'population', 'census', 'inhabitants']\n",
      "weighted: tensor([0.4656])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4656])\n",
      "===============================================\n",
      "['gdp', 'oil', 'china', 'billion']\n",
      "['kensett', 'railroad', '1871', '1872']\n",
      "Got the keywords in 0.1430 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil']], KW Curr: ['gdp', 'oil', 'china', 'billion']\n",
      "weighted: tensor([0.4398])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4398])\n",
      "===============================================\n",
      "['kensett', 'railroad', '1871', '1872']\n",
      "['kensett', 'area', '208560', 'located']\n",
      "Got the keywords in 0.0916 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area']], KW Curr: ['kensett', 'railroad', '1871', '1872']\n",
      "weighted: tensor([0.3499])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3499])\n",
      "===============================================\n",
      "['kensett', 'area', '208560', 'located']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.1777 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households']], KW Curr: ['kensett', 'area', '208560', 'located']\n",
      "weighted: tensor([0.3368])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3368])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'household']\n",
      "Got the keywords in 0.3725 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.4620])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4620])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'household']\n",
      "['warren', 'railroad', 'county', 'line']\n",
      "Got the keywords in 0.3885 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households']], KW Curr: ['population', 'census', 'households', 'household']\n",
      "weighted: tensor([0.4304])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4304])\n",
      "===============================================\n",
      "['warren', 'railroad', 'county', 'line']\n",
      "['warren', 'burlington', 'river', 'area']\n",
      "Got the keywords in 0.4126 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington']], KW Curr: ['warren', 'railroad', 'county', 'line']\n",
      "weighted: tensor([0.5748])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5748])\n",
      "===============================================\n",
      "['warren', 'burlington', 'river', 'area']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.3162 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington'], ['census', 'population', 'households', 'warren']], KW Curr: ['warren', 'burlington', 'river', 'area']\n",
      "weighted: tensor([0.4300])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4300])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.3248 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington'], ['census', 'population', 'households', 'warren'], ['census', 'population', 'census', 'population']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.4805])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4805])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['lutheran', 'churches', 'church', 'evangelical']\n",
      "Got the keywords in 0.2545 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington'], ['census', 'population', 'households', 'warren'], ['census', 'population', 'census', 'population'], ['churches', 'census']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3447])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3447])\n",
      "===============================================\n",
      "['lutheran', 'churches', 'church', 'evangelical']\n",
      "['agribusiness', 'warren', 'agriculture', 'farming']\n",
      "Got the keywords in 0.1858 seconds\n",
      "Got the embeddings and comparisons in 0.0008 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington'], ['census', 'population', 'households', 'warren'], ['census', 'population', 'census', 'population'], ['churches', 'census'], ['churches', 'church', 'warren', 'farming']], KW Curr: ['lutheran', 'churches', 'church', 'evangelical']\n",
      "weighted: tensor([0.3768])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3768])\n",
      "===============================================\n",
      "['agribusiness', 'warren', 'agriculture', 'farming']\n",
      "['warren', 'classrooms', 'county', 'school']\n",
      "Got the keywords in 0.2835 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['karamay', 'karamay', 'climate', 'temperature'], ['karamay', 'karamay', 'population', 'climate'], ['karamay', 'population', 'gdp', 'census'], ['kensett', 'gdp', 'railroad', 'oil'], ['railroad', 'area'], ['kensett', 'census', 'population', 'households'], ['census', 'population', 'population', 'census'], ['population', 'census', 'warren', 'households'], ['warren', 'warren', 'railroad', 'burlington'], ['census', 'population', 'households', 'warren'], ['census', 'population', 'census', 'population'], ['churches', 'census'], ['churches', 'church', 'warren', 'farming'], ['agriculture', 'classrooms']], KW Curr: ['agribusiness', 'warren', 'agriculture', 'farming']\n",
      "weighted: tensor([0.2297])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2297])\n",
      "===============================================\n",
      "['warren', 'classrooms', 'county', 'school']\n",
      "['warren', 'minnesota', 'justice', 'activist']\n",
      "Got the keywords in 0.2900 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['warren', 'justice', 'classrooms', 'county']], KW Curr: ['warren', 'classrooms', 'county', 'school']\n",
      "weighted: tensor([0.2461])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2461])\n",
      "===============================================\n",
      "['warren', 'minnesota', 'justice', 'activist']\n",
      "['scottsburg', 'scottsville', 'fort', 'jones']\n",
      "Got the keywords in 0.3689 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['scottsville', 'justice']], KW Curr: ['warren', 'minnesota', 'justice', 'activist']\n",
      "weighted: tensor([0.3107])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3107])\n",
      "===============================================\n",
      "['scottsburg', 'scottsville', 'fort', 'jones']\n",
      "['jones', 'fort', 'stationed', 'fitzgerald']\n",
      "Got the keywords in 0.4581 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort']], KW Curr: ['scottsburg', 'scottsville', 'fort', 'jones']\n",
      "weighted: tensor([0.6485])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.6485])\n",
      "===============================================\n",
      "['jones', 'fort', 'stationed', 'fitzgerald']\n",
      "['fort', 'jones', 'located', 'area']\n",
      "Got the keywords in 0.2260 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort']], KW Curr: ['jones', 'fort', 'stationed', 'fitzgerald']\n",
      "weighted: tensor([0.4358])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4358])\n",
      "===============================================\n",
      "['fort', 'jones', 'located', 'area']\n",
      "['climate', 'temperatures', 'warm', 'summers']\n",
      "Got the keywords in 0.1219 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort'], ['climate', 'fort', 'jones', 'summers']], KW Curr: ['fort', 'jones', 'located', 'area']\n",
      "weighted: tensor([0.4107])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4107])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['climate', 'temperatures', 'warm', 'summers']\n",
      "['jones', 'population', 'fort', 'census']\n",
      "Got the keywords in 0.2696 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort'], ['climate', 'fort', 'jones', 'summers'], ['climate', 'jones', 'population', 'summers']], KW Curr: ['climate', 'temperatures', 'warm', 'summers']\n",
      "weighted: tensor([0.4789])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4789])\n",
      "===============================================\n",
      "['jones', 'population', 'fort', 'census']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.3717 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort'], ['climate', 'fort', 'jones', 'summers'], ['climate', 'jones', 'population', 'summers'], ['population', 'census', 'jones', 'population']], KW Curr: ['jones', 'population', 'fort', 'census']\n",
      "weighted: tensor([0.4642])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4642])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['jones', 'fort', 'federally', 'state']\n",
      "Got the keywords in 0.2421 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort'], ['climate', 'fort', 'jones', 'summers'], ['climate', 'jones', 'population', 'summers'], ['population', 'census', 'jones', 'population'], ['jones', 'households']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3041])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3041])\n",
      "===============================================\n",
      "['jones', 'fort', 'federally', 'state']\n",
      "['kłodzko', 'poland', 'glatz', 'wrocław']\n",
      "Got the keywords in 0.2860 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['scottsville', 'justice'], ['scottsburg', 'scottsville', 'jones', 'fort'], ['fort', 'jones', 'jones', 'fort'], ['climate', 'fort', 'jones', 'summers'], ['climate', 'jones', 'population', 'summers'], ['population', 'census', 'jones', 'population'], ['jones', 'households'], ['jones', 'wrocław']], KW Curr: ['jones', 'fort', 'federally', 'state']\n",
      "weighted: tensor([0.2092])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.2092])\n",
      "===============================================\n",
      "['kłodzko', 'poland', 'glatz', 'wrocław']\n",
      "['bono', 'jonesboro', 'craighead', 'ridge']\n",
      "Got the keywords in 0.2714 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono']], KW Curr: ['kłodzko', 'poland', 'glatz', 'wrocław']\n",
      "weighted: tensor([0.3316])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3316])\n",
      "===============================================\n",
      "['bono', 'jonesboro', 'craighead', 'ridge']\n",
      "['population', 'census', 'households', '512']\n",
      "Got the keywords in 0.2795 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono'], ['population', 'bono', 'households', 'jonesboro']], KW Curr: ['bono', 'jonesboro', 'craighead', 'ridge']\n",
      "weighted: tensor([0.4023])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4023])\n",
      "===============================================\n",
      "['population', 'census', 'households', '512']\n",
      "['westside', 'district', 'school', 'bono']\n",
      "Got the keywords in 0.2089 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono'], ['population', 'bono', 'households', 'jonesboro'], ['population', 'westside']], KW Curr: ['population', 'census', 'households', '512']\n",
      "weighted: tensor([0.3470])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3470])\n",
      "===============================================\n",
      "['westside', 'district', 'school', 'bono']\n",
      "['climate', 'köppen', 'subtropical', 'precipitation']\n",
      "Got the keywords in 0.1198 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono'], ['population', 'bono', 'households', 'jonesboro'], ['population', 'westside'], ['climate', 'subtropical', 'school', 'bono']], KW Curr: ['westside', 'district', 'school', 'bono']\n",
      "weighted: tensor([0.2655])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2655])\n",
      "===============================================\n",
      "['climate', 'köppen', 'subtropical', 'precipitation']\n",
      "['köppen', 'savanna', 'climate', 'tropical']\n",
      "Got the keywords in 0.0949 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono'], ['population', 'bono', 'households', 'jonesboro'], ['population', 'westside'], ['climate', 'subtropical', 'school', 'bono'], ['savanna', 'climate', 'tropical', 'köppen']], KW Curr: ['climate', 'köppen', 'subtropical', 'precipitation']\n",
      "weighted: tensor([0.3061])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3061])\n",
      "===============================================\n",
      "['köppen', 'savanna', 'climate', 'tropical']\n",
      "['settlers', 'settlements', 'pioneers', 'brunswick']\n",
      "Got the keywords in 0.1823 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['kłodzko', 'poland', 'wrocław', 'bono'], ['population', 'bono', 'households', 'jonesboro'], ['population', 'westside'], ['climate', 'subtropical', 'school', 'bono'], ['savanna', 'climate', 'tropical', 'köppen'], []], KW Curr: ['köppen', 'savanna', 'climate', 'tropical']\n",
      "weighted: tensor([0.2323])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.2323])\n",
      "===============================================\n",
      "['settlers', 'settlements', 'pioneers', 'brunswick']\n",
      "['fairbanks', 'isle', 'aroostook', 'presque']\n",
      "Got the keywords in 0.3133 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers']], KW Curr: ['settlers', 'settlements', 'pioneers', 'brunswick']\n",
      "weighted: tensor([0.6914])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.6914])\n",
      "===============================================\n",
      "['fairbanks', 'isle', 'aroostook', 'presque']\n",
      "['industry', 'isle', 'presque', 'factory']\n",
      "Got the keywords in 0.1982 seconds\n",
      "Got the embeddings and comparisons in 0.0002 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle']], KW Curr: ['fairbanks', 'isle', 'aroostook', 'presque']\n",
      "weighted: tensor([0.4330])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4330])\n",
      "===============================================\n",
      "['industry', 'isle', 'presque', 'factory']\n",
      "['maine', 'agriculture', 'potatoes', 'agricultural']\n",
      "Got the keywords in 0.1345 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory']], KW Curr: ['industry', 'isle', 'presque', 'factory']\n",
      "weighted: tensor([0.3810])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3810])\n",
      "===============================================\n",
      "['maine', 'agriculture', 'potatoes', 'agricultural']\n",
      "['railway', 'brunswick', 'bangor', 'railroad']\n",
      "Got the keywords in 0.1442 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture']], KW Curr: ['maine', 'agriculture', 'potatoes', 'agricultural']\n",
      "weighted: tensor([0.5124])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5124])\n",
      "===============================================\n",
      "['railway', 'brunswick', 'bangor', 'railroad']\n",
      "['airport', 'isle', 'presque', 'planes']\n",
      "Got the keywords in 0.1787 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle']], KW Curr: ['railway', 'brunswick', 'bangor', 'railroad']\n",
      "weighted: tensor([0.5439])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5439])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airport', 'isle', 'presque', 'planes']\n",
      "['maine', 'college', 'aroostook', 'school']\n",
      "Got the keywords in 0.2196 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook']], KW Curr: ['airport', 'isle', 'presque', 'planes']\n",
      "weighted: tensor([0.6173])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.6173])\n",
      "===============================================\n",
      "['maine', 'college', 'aroostook', 'school']\n",
      "['hospital', 'isle', 'nurses', 'presque']\n",
      "Got the keywords in 0.2893 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college']], KW Curr: ['maine', 'college', 'aroostook', 'school']\n",
      "weighted: tensor([0.6621])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.6621])\n",
      "===============================================\n",
      "['hospital', 'isle', 'nurses', 'presque']\n",
      "['balloon', 'isle', 'eagle', 'maine']\n",
      "Got the keywords in 0.2872 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle']], KW Curr: ['hospital', 'isle', 'nurses', 'presque']\n",
      "weighted: tensor([0.5217])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5217])\n",
      "===============================================\n",
      "['balloon', 'isle', 'eagle', 'maine']\n",
      "['isle', 'presque', 'located', '002166']\n",
      "Got the keywords in 0.2545 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle']], KW Curr: ['balloon', 'isle', 'eagle', 'maine']\n",
      "weighted: tensor([0.3516])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3516])\n",
      "===============================================\n",
      "['isle', 'presque', 'located', '002166']\n",
      "['census', 'population', 'households', 'families']\n",
      "Got the keywords in 0.3480 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population']], KW Curr: ['isle', 'presque', 'located', '002166']\n",
      "weighted: tensor([0.4119])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4119])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'families']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.3945 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population'], ['population', 'census', 'population', 'households']], KW Curr: ['census', 'population', 'households', 'families']\n",
      "weighted: tensor([0.5297])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5297])\n",
      "===============================================\n",
      "['population', 'census', 'households', 'families']\n",
      "['isle', 'presque', 'maine', 'aroostook']\n",
      "Got the keywords in 0.3431 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population'], ['population', 'census', 'population', 'households'], ['population', 'isle']], KW Curr: ['population', 'census', 'households', 'families']\n",
      "weighted: tensor([0.3311])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3311])\n",
      "===============================================\n",
      "['isle', 'presque', 'maine', 'aroostook']\n",
      "['isle', 'nbc', 'presque', 'wvii']\n",
      "Got the keywords in 0.2251 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population'], ['population', 'census', 'population', 'households'], ['population', 'isle'], ['isle', 'isle']], KW Curr: ['isle', 'presque', 'maine', 'aroostook']\n",
      "weighted: tensor([0.2967])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2967])\n",
      "===============================================\n",
      "['isle', 'nbc', 'presque', 'wvii']\n",
      "['stations', 'wupi', 'presque', 'radio']\n",
      "Got the keywords in 0.1843 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population'], ['population', 'census', 'population', 'households'], ['population', 'isle'], ['isle', 'isle'], ['isle', 'nbc', 'stations', 'presque']], KW Curr: ['isle', 'nbc', 'presque', 'wvii']\n",
      "weighted: tensor([0.3529])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3529])\n",
      "===============================================\n",
      "['stations', 'wupi', 'presque', 'radio']\n",
      "['aroostook', 'houlton', 'bangor', 'newspapers']\n",
      "Got the keywords in 0.1684 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['settlers', 'settlements', 'fairbanks', 'pioneers'], ['industry', 'fairbanks', 'presque', 'isle'], ['industry', 'maine', 'potatoes', 'factory'], ['railway', 'maine', 'brunswick', 'agriculture'], ['airport', 'railway', 'brunswick', 'isle'], ['airport', 'maine', 'college', 'aroostook'], ['hospital', 'maine', 'isle', 'college'], ['hospital', 'balloon', 'isle', 'isle'], ['isle', 'presque', 'balloon', 'isle'], ['isle', 'census', 'presque', 'population'], ['population', 'census', 'population', 'households'], ['population', 'isle'], ['isle', 'isle'], ['isle', 'nbc', 'stations', 'presque'], []], KW Curr: ['stations', 'wupi', 'presque', 'radio']\n",
      "weighted: tensor([0.2237])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2237])\n",
      "===============================================\n",
      "['aroostook', 'houlton', 'bangor', 'newspapers']\n",
      "['island', 'sky', '1953', 'film']\n",
      "Got the keywords in 0.1343 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['houlton', 'film']], KW Curr: ['aroostook', 'houlton', 'bangor', 'newspapers']\n",
      "weighted: tensor([0.2746])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2746])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['island', 'sky', '1953', 'film']\n",
      "['المنامة', 'manãma', 'arabic', 'al']\n",
      "Got the keywords in 0.1128 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['houlton', 'film'], ['sky', 'al']], KW Curr: ['island', 'sky', '1953', 'film']\n",
      "weighted: tensor([0.2595])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2595])\n",
      "===============================================\n",
      "['المنامة', 'manãma', 'arabic', 'al']\n",
      "['bahrain', 'mesopotamia', 'urbanisation', 'rural']\n",
      "Got the keywords in 0.2837 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['houlton', 'film'], ['sky', 'al'], []], KW Curr: ['المنامة', 'manãma', 'arabic', 'al']\n",
      "weighted: tensor([0.2294])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2294])\n",
      "===============================================\n",
      "['bahrain', 'mesopotamia', 'urbanisation', 'rural']\n",
      "['bahrain', 'manama', 'bahraini', 'persia']\n",
      "Got the keywords in 0.4862 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini']], KW Curr: ['bahrain', 'mesopotamia', 'urbanisation', 'rural']\n",
      "weighted: tensor([0.4811])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4811])\n",
      "===============================================\n",
      "['bahrain', 'manama', 'bahraini', 'persia']\n",
      "['bahrain', 'manama', '1914', 'mesopotamian']\n",
      "Got the keywords in 0.4308 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia']], KW Curr: ['bahrain', 'manama', 'bahraini', 'persia']\n",
      "weighted: tensor([0.3581])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3581])\n",
      "===============================================\n",
      "['bahrain', 'manama', '1914', 'mesopotamian']\n",
      "['manama', 'manamah', 'bahrain', 'governorates']\n",
      "Got the keywords in 0.3231 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama']], KW Curr: ['bahrain', 'manama', '1914', 'mesopotamian']\n",
      "weighted: tensor([0.3610])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3610])\n",
      "===============================================\n",
      "['manama', 'manamah', 'bahrain', 'governorates']\n",
      "['manama', 'bahraini', 'economy', 'industries']\n",
      "Got the keywords in 0.3312 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini']], KW Curr: ['manama', 'manamah', 'bahrain', 'governorates']\n",
      "weighted: tensor([0.4121])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4121])\n",
      "===============================================\n",
      "['manama', 'bahraini', 'economy', 'industries']\n",
      "['manama', 'persians', 'bahraini', 'gulf']\n",
      "Got the keywords in 0.3549 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians']], KW Curr: ['manama', 'bahraini', 'economy', 'industries']\n",
      "weighted: tensor([0.5077])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.5077])\n",
      "===============================================\n",
      "['manama', 'persians', 'bahraini', 'gulf']\n",
      "['manama', 'roads', 'road', 'traffic']\n",
      "Got the keywords in 0.3827 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road']], KW Curr: ['manama', 'persians', 'bahraini', 'gulf']\n",
      "weighted: tensor([0.3836])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3836])\n",
      "===============================================\n",
      "['manama', 'roads', 'road', 'traffic']\n",
      "['manama', 'buses', 'bus', 'bahrain']\n",
      "Got the keywords in 0.2783 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus']], KW Curr: ['manama', 'roads', 'road', 'traffic']\n",
      "weighted: tensor([0.4567])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4567])\n",
      "===============================================\n",
      "['manama', 'buses', 'bus', 'bahrain']\n",
      "['bahrain', 'airport', 'arabia', 'saudi']\n",
      "Got the keywords in 0.1556 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus'], ['manama', 'bus', 'arabia', 'saudi']], KW Curr: ['manama', 'buses', 'bus', 'bahrain']\n",
      "weighted: tensor([0.3222])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3222])\n",
      "===============================================\n",
      "['bahrain', 'airport', 'arabia', 'saudi']\n",
      "['bahrain', 'bahraini', 'qur', 'quranic']\n",
      "Got the keywords in 0.2841 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus'], ['manama', 'bus', 'arabia', 'saudi'], ['bahrain', 'bahrain', 'quranic', 'arabia']], KW Curr: ['bahrain', 'airport', 'arabia', 'saudi']\n",
      "weighted: tensor([0.2937])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2937])\n",
      "===============================================\n",
      "['bahrain', 'bahraini', 'qur', 'quranic']\n",
      "['bahrain', 'peninsula', 'arid', 'located']\n",
      "Got the keywords in 0.2574 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus'], ['manama', 'bus', 'arabia', 'saudi'], ['bahrain', 'bahrain', 'quranic', 'arabia'], []], KW Curr: ['bahrain', 'bahraini', 'qur', 'quranic']\n",
      "weighted: tensor([0.3024])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3024])\n",
      "===============================================\n",
      "['bahrain', 'peninsula', 'arid', 'located']\n",
      "['manama', 'bahrain', 'climate', 'temperatures']\n",
      "Got the keywords in 0.1122 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus'], ['manama', 'bus', 'arabia', 'saudi'], ['bahrain', 'bahrain', 'quranic', 'arabia'], [], ['bahrain', 'manama', 'temperatures', 'peninsula']], KW Curr: ['bahrain', 'peninsula', 'arid', 'located']\n",
      "weighted: tensor([0.4007])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4007])\n",
      "===============================================\n",
      "['manama', 'bahrain', 'climate', 'temperatures']\n",
      "['manama', 'bahrain', 'bahraini', 'popular']\n",
      "Got the keywords in 0.1775 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['bahrain', 'bahrain', 'manama', 'bahraini'], ['bahrain', 'manama', 'bahraini', 'persia'], ['manama', 'manamah', 'bahrain', 'manama'], ['manama', 'manama', 'manamah', 'bahraini'], ['manama', 'manama', 'bahraini', 'persians'], ['manama', 'manama', 'roads', 'road'], ['manama', 'manama', 'buses', 'bus'], ['manama', 'bus', 'arabia', 'saudi'], ['bahrain', 'bahrain', 'quranic', 'arabia'], [], ['bahrain', 'manama', 'temperatures', 'peninsula'], ['manama', 'bahrain', 'bahrain', 'climate']], KW Curr: ['manama', 'bahrain', 'climate', 'temperatures']\n",
      "weighted: tensor([0.2440])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2440])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manama', 'bahrain', 'bahraini', 'popular']\n",
      "['vila', 'archaeological', 'joão', 'conde']\n",
      "Got the keywords in 0.3717 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular']], KW Curr: ['manama', 'bahrain', 'bahraini', 'popular']\n",
      "weighted: tensor([0.3823])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3823])\n",
      "===============================================\n",
      "['vila', 'archaeological', 'joão', 'conde']\n",
      "['vila', 'porto', 'conde', 'portugal']\n",
      "Got the keywords in 0.4699 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde']], KW Curr: ['vila', 'archaeological', 'joão', 'conde']\n",
      "weighted: tensor([0.3843])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3843])\n",
      "===============================================\n",
      "['vila', 'porto', 'conde', 'portugal']\n",
      "['azurara', 'vila', 'árvore', 'municipality']\n",
      "Got the keywords in 0.2502 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality']], KW Curr: ['vila', 'porto', 'conde', 'portugal']\n",
      "weighted: tensor([0.2772])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2772])\n",
      "===============================================\n",
      "['azurara', 'vila', 'árvore', 'municipality']\n",
      "['vila', 'resorts', 'tourist', 'environment']\n",
      "Got the keywords in 0.1829 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist']], KW Curr: ['azurara', 'vila', 'árvore', 'municipality']\n",
      "weighted: tensor([0.3067])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3067])\n",
      "===============================================\n",
      "['vila', 'resorts', 'tourist', 'environment']\n",
      "['vila', 'conde', 'norte', 'porto']\n",
      "Got the keywords in 0.3001 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist']], KW Curr: ['vila', 'resorts', 'tourist', 'environment']\n",
      "weighted: tensor([0.2829])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2829])\n",
      "===============================================\n",
      "['vila', 'conde', 'norte', 'porto']\n",
      "['são', 'vairão', 'beaches', 'junqueira']\n",
      "Got the keywords in 0.2510 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto']], KW Curr: ['vila', 'conde', 'norte', 'porto']\n",
      "weighted: tensor([0.2935])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2935])\n",
      "===============================================\n",
      "['são', 'vairão', 'beaches', 'junqueira']\n",
      "['vila', 'são', 'joão', 'festivals']\n",
      "Got the keywords in 0.1860 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão']], KW Curr: ['são', 'vairão', 'beaches', 'junqueira']\n",
      "weighted: tensor([0.3327])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3327])\n",
      "===============================================\n",
      "['vila', 'são', 'joão', 'festivals']\n",
      "['móng', 'vietnam', 'cash', 'border']\n",
      "Got the keywords in 0.2526 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão'], ['são', 'vietnam']], KW Curr: ['vila', 'são', 'joão', 'festivals']\n",
      "weighted: tensor([0.2679])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.2679])\n",
      "===============================================\n",
      "['móng', 'vietnam', 'cash', 'border']\n",
      "['hanoi', 'đầu', 'vietnamese', 'móng']\n",
      "Got the keywords in 0.2983 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão'], ['são', 'vietnam'], ['đầu', 'móng', 'vietnamese', 'móng']], KW Curr: ['móng', 'vietnam', 'cash', 'border']\n",
      "weighted: tensor([0.3096])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3096])\n",
      "===============================================\n",
      "['hanoi', 'đầu', 'vietnamese', 'móng']\n",
      "['cantonese', 'mong', 'mandarin', 'cai']\n",
      "Got the keywords in 0.2287 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão'], ['são', 'vietnam'], ['đầu', 'móng', 'vietnamese', 'móng'], ['hanoi', 'đầu', 'cantonese', 'mandarin']], KW Curr: ['hanoi', 'đầu', 'vietnamese', 'móng']\n",
      "weighted: tensor([0.2615])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2615])\n",
      "===============================================\n",
      "['cantonese', 'mong', 'mandarin', 'cai']\n",
      "['township', 'communes', 'hải', 'đông']\n",
      "Got the keywords in 0.1684 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão'], ['são', 'vietnam'], ['đầu', 'móng', 'vietnamese', 'móng'], ['hanoi', 'đầu', 'cantonese', 'mandarin'], []], KW Curr: ['cantonese', 'mong', 'mandarin', 'cai']\n",
      "weighted: tensor([0.2521])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2521])\n",
      "===============================================\n",
      "['township', 'communes', 'hải', 'đông']\n",
      "['westfield', 'quakers', 'quaker', 'founded']\n",
      "Got the keywords in 0.3395 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['manama', 'vila', 'archaeological', 'popular'], ['vila', 'vila', 'porto', 'conde'], ['conde', 'municipality'], ['resorts', 'vila', 'árvore', 'tourist'], ['vila', 'vila', 'conde', 'tourist'], ['são', 'conde', 'beaches', 'porto'], ['são', 'vairão', 'são', 'joão'], ['são', 'vietnam'], ['đầu', 'móng', 'vietnamese', 'móng'], ['hanoi', 'đầu', 'cantonese', 'mandarin'], [], []], KW Curr: ['township', 'communes', 'hải', 'đông']\n",
      "weighted: tensor([0.1703])\n",
      "Label: 1, Prediction: 1, logit: tensor([0.1703])\n",
      "===============================================\n",
      "['westfield', 'quakers', 'quaker', 'founded']\n",
      "['westfield', 'income', 'poverty', 'median']\n",
      "Got the keywords in 0.3051 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['westfield', 'westfield', 'quakers', 'quaker']], KW Curr: ['westfield', 'quakers', 'quaker', 'founded']\n",
      "weighted: tensor([0.4235])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4235])\n",
      "===============================================\n",
      "['westfield', 'income', 'poverty', 'median']\n",
      "['census', 'population', 'households', 'residents']\n",
      "Got the keywords in 0.2292 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['westfield', 'westfield', 'quakers', 'quaker'], ['census', 'westfield', 'population', 'households']], KW Curr: ['westfield', 'income', 'poverty', 'median']\n",
      "weighted: tensor([0.3865])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3865])\n",
      "===============================================\n",
      "['census', 'population', 'households', 'residents']\n",
      "['westfield', 'noblesville', 'newspaper', 'news']\n",
      "Got the keywords in 0.1907 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['westfield', 'westfield', 'quakers', 'quaker'], ['census', 'westfield', 'population', 'households'], []], KW Curr: ['census', 'population', 'households', 'residents']\n",
      "weighted: tensor([0.2774])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2774])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['westfield', 'noblesville', 'newspaper', 'news']\n",
      "['park', 'grand', 'softball', 'fieldhouse']\n",
      "Got the keywords in 0.2137 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['westfield', 'westfield', 'quakers', 'quaker'], ['census', 'westfield', 'population', 'households'], [], []], KW Curr: ['westfield', 'noblesville', 'newspaper', 'news']\n",
      "weighted: tensor([0.2081])\n",
      "Label: 0, Prediction: 1, logit: tensor([0.2081])\n",
      "===============================================\n",
      "['park', 'grand', 'softball', 'fieldhouse']\n",
      "['westfield', 'indianapolis', 'noblesville', 'indiana']\n",
      "Got the keywords in 0.2877 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis']], KW Curr: ['park', 'grand', 'softball', 'fieldhouse']\n",
      "weighted: tensor([0.3549])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3549])\n",
      "===============================================\n",
      "['westfield', 'indianapolis', 'noblesville', 'indiana']\n",
      "['rustica', 'alemanni', 'palaeolithic', 'auderiensium']\n",
      "Got the keywords in 0.2567 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni']], KW Curr: ['westfield', 'indianapolis', 'noblesville', 'indiana']\n",
      "weighted: tensor([0.3843])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3843])\n",
      "===============================================\n",
      "['rustica', 'alemanni', 'palaeolithic', 'auderiensium']\n",
      "['umstadt', 'umstaedter', 'town', 'franks']\n",
      "Got the keywords in 0.2931 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium']], KW Curr: ['rustica', 'alemanni', 'palaeolithic', 'auderiensium']\n",
      "weighted: tensor([0.3344])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3344])\n",
      "===============================================\n",
      "['umstadt', 'umstaedter', 'town', 'franks']\n",
      "['umstadt', 'castles', 'konrad', 'castle']\n",
      "Got the keywords in 0.2767 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter']], KW Curr: ['umstadt', 'umstaedter', 'town', 'franks']\n",
      "weighted: tensor([0.4176])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4176])\n",
      "===============================================\n",
      "['umstadt', 'castles', 'konrad', 'castle']\n",
      "['hesse', 'langstadt', 'kleestadt', 'town']\n",
      "Got the keywords in 0.2609 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt']], KW Curr: ['umstadt', 'castles', 'konrad', 'castle']\n",
      "weighted: tensor([0.4757])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.4757])\n",
      "===============================================\n",
      "['hesse', 'langstadt', 'kleestadt', 'town']\n",
      "['umstadt', 'wenigumstadt', 'darmstadt', 'dieburg']\n",
      "Got the keywords in 0.2501 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt']], KW Curr: ['hesse', 'langstadt', 'kleestadt', 'town']\n",
      "weighted: tensor([0.3628])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3628])\n",
      "===============================================\n",
      "['umstadt', 'wenigumstadt', 'darmstadt', 'dieburg']\n",
      "['winzerfest', 'festival', 'september', 'wine']\n",
      "Got the keywords in 0.1604 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], []], KW Curr: ['umstadt', 'wenigumstadt', 'darmstadt', 'dieburg']\n",
      "weighted: tensor([0.2917])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2917])\n",
      "===============================================\n",
      "['winzerfest', 'festival', 'september', 'wine']\n",
      "['umstadt', 'schools', 'hospital', 'students']\n",
      "Got the keywords in 0.0842 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september']], KW Curr: ['winzerfest', 'festival', 'september', 'wine']\n",
      "weighted: tensor([0.2557])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2557])\n",
      "===============================================\n",
      "['umstadt', 'schools', 'hospital', 'students']\n",
      "['comănești', 'ghica', 'neolithic', 'vermești']\n",
      "Got the keywords in 0.1536 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic']], KW Curr: ['umstadt', 'schools', 'hospital', 'students']\n",
      "weighted: tensor([0.3460])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.3460])\n",
      "===============================================\n",
      "['comănești', 'ghica', 'neolithic', 'vermești']\n",
      "['unemployed', 'industry', 'unemployment', 'town']\n",
      "Got the keywords in 0.2330 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic'], ['unemployed', 'industry', 'unemployment', 'ghica']], KW Curr: ['comănești', 'ghica', 'neolithic', 'vermești']\n",
      "weighted: tensor([0.3624])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3624])\n",
      "===============================================\n",
      "['unemployed', 'industry', 'unemployment', 'town']\n",
      "['picayune', 'murals', 'orleans', 'newspaper']\n",
      "Got the keywords in 0.2441 seconds\n",
      "Got the embeddings and comparisons in 0.0004 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic'], ['unemployed', 'industry', 'unemployment', 'ghica'], ['picayune', 'unemployed', 'industry', 'unemployment']], KW Curr: ['unemployed', 'industry', 'unemployment', 'town']\n",
      "weighted: tensor([0.4096])\n",
      "Label: 1, Prediction: 0, logit: tensor([0.4096])\n",
      "===============================================\n",
      "['picayune', 'murals', 'orleans', 'newspaper']\n",
      "['katrina', 'picayune', 'hurricane', 'orleans']\n",
      "Got the keywords in 0.2053 seconds\n",
      "Got the embeddings and comparisons in 0.0006 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic'], ['unemployed', 'industry', 'unemployment', 'ghica'], ['picayune', 'unemployed', 'industry', 'unemployment'], []], KW Curr: ['picayune', 'murals', 'orleans', 'newspaper']\n",
      "weighted: tensor([0.2540])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.2540])\n",
      "===============================================\n",
      "['katrina', 'picayune', 'hurricane', 'orleans']\n",
      "['area', 'census', 'land', 'city']\n",
      "Got the keywords in 0.1522 seconds\n",
      "Got the embeddings and comparisons in 0.0003 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic'], ['unemployed', 'industry', 'unemployment', 'ghica'], ['picayune', 'unemployed', 'industry', 'unemployment'], [], ['katrina', 'census', 'orleans', 'land']], KW Curr: ['katrina', 'picayune', 'hurricane', 'orleans']\n",
      "weighted: tensor([0.3231])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3231])\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['area', 'census', 'land', 'city']\n",
      "['population', 'census', 'households', 'families']\n",
      "Got the keywords in 0.1896 seconds\n",
      "Got the embeddings and comparisons in 0.0005 seconds\n",
      "Coherence Map: [['park', 'westfield', 'grand', 'indianapolis'], ['westfield', 'rustica', 'indianapolis', 'alemanni'], ['umstadt', 'rustica', 'palaeolithic', 'auderiensium'], ['umstadt', 'umstadt', 'castles', 'umstaedter'], ['umstadt', 'hesse', 'langstadt', 'kleestadt'], ['umstadt', 'wenigumstadt', 'hesse', 'langstadt'], [], ['umstadt', 'september'], ['umstadt', 'neolithic'], ['unemployed', 'industry', 'unemployment', 'ghica'], ['picayune', 'unemployed', 'industry', 'unemployment'], [], ['katrina', 'census', 'orleans', 'land'], ['population', 'area']], KW Curr: ['area', 'census', 'land', 'city']\n",
      "weighted: tensor([0.3320])\n",
      "Label: 0, Prediction: 0, logit: tensor([0.3320])\n",
      "===============================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 418;\n",
       "                var nbb_unformatted_code = \"start = 0\\nnum_samples = 250\\nmax_tokens = 256  # want to keep this under 512\\nmax_str_length = 30\\n\\ntrue_labels = text_labels[start : start + num_samples]\\n\\npredictions = coherence_tester(\\n    text_data[start : start + num_samples],\\n    true_labels,\\n    max_tokens=max_tokens,\\n    max_str_length=max_str_length,\\n)\";\n",
       "                var nbb_formatted_code = \"start = 0\\nnum_samples = 250\\nmax_tokens = 256  # want to keep this under 512\\nmax_str_length = 30\\n\\ntrue_labels = text_labels[start : start + num_samples]\\n\\npredictions = coherence_tester(\\n    text_data[start : start + num_samples],\\n    true_labels,\\n    max_tokens=max_tokens,\\n    max_str_length=max_str_length,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "num_samples = 250\n",
    "max_tokens = 256  # want to keep this under 512\n",
    "max_str_length = 30\n",
    "\n",
    "true_labels = text_labels[start : start + num_samples]\n",
    "\n",
    "predictions = coherence_tester(\n",
    "    text_data[start : start + num_samples],\n",
    "    true_labels,\n",
    "    max_tokens=max_tokens,\n",
    "    max_str_length=max_str_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d3a93727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 419;\n",
       "                var nbb_unformatted_code = \"print([x[1] for x in predictions])\\nprint(true_labels)\";\n",
       "                var nbb_formatted_code = \"print([x[1] for x in predictions])\\nprint(true_labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print([x[1] for x in predictions])\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "61e7863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 420;\n",
       "                var nbb_unformatted_code = \"pred_string = \\\"\\\".join(str([x[1] for x in predictions]))\\ntrue_string = \\\"\\\".join(str(true_labels))\";\n",
       "                var nbb_formatted_code = \"pred_string = \\\"\\\".join(str([x[1] for x in predictions]))\\ntrue_string = \\\"\\\".join(str(true_labels))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_string = \"\".join(str([x[1] for x in predictions]))\n",
    "true_string = \"\".join(str(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "19af16ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 421;\n",
       "                var nbb_unformatted_code = \"avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\";\n",
       "                var nbb_formatted_code = \"avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "db43c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6\n",
      "wd = 0.32483221476510066\n",
      "pk = 0.3087248322147651\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 422;\n",
       "                var nbb_unformatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_formatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "print(f\"k = {avg_k}\")\n",
    "print(f\"wd = {wd_score}\")\n",
    "print(f\"pk = {pk_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb16194",
   "metadata": {},
   "source": [
    "## Prediction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "f36e88ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 423;\n",
       "                var nbb_unformatted_code = \"pred_thresholds = [0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\";\n",
       "                var nbb_formatted_code = \"pred_thresholds = [0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_thresholds = [0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "af208503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 424;\n",
       "                var nbb_unformatted_code = \"pred_thresh = 0.26\";\n",
       "                var nbb_formatted_code = \"pred_thresh = 0.26\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_thresh = 0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e9cebcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_thresh = 0.23\n",
      "k = 6\n",
      "wd = 0.3221476510067114\n",
      "pk = 0.31409395973154364\n",
      "===========================================\n",
      "pred_thresh = 0.24\n",
      "k = 6\n",
      "wd = 0.3302013422818792\n",
      "pk = 0.3181208053691275\n",
      "===========================================\n",
      "pred_thresh = 0.25\n",
      "k = 6\n",
      "wd = 0.3221476510067114\n",
      "pk = 0.30604026845637583\n",
      "===========================================\n",
      "pred_thresh = 0.26\n",
      "k = 6\n",
      "wd = 0.35838926174496644\n",
      "pk = 0.33422818791946307\n",
      "===========================================\n",
      "pred_thresh = 0.27\n",
      "k = 6\n",
      "wd = 0.3785234899328859\n",
      "pk = 0.34630872483221475\n",
      "===========================================\n",
      "pred_thresh = 0.28\n",
      "k = 6\n",
      "wd = 0.46174496644295304\n",
      "pk = 0.41073825503355704\n",
      "===========================================\n",
      "pred_thresh = 0.29\n",
      "k = 6\n",
      "wd = 0.4818791946308725\n",
      "pk = 0.43087248322147653\n",
      "===========================================\n",
      "pred_thresh = 0.3\n",
      "k = 6\n",
      "wd = 0.5100671140939598\n",
      "pk = 0.45503355704697984\n",
      "===========================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 425;\n",
       "                var nbb_unformatted_code = \"for pred_thresh in pred_thresholds:\\n    modified_predictions = [\\n        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\\n    ]\\n\\n    pred_string = \\\"\\\".join(str(modified_predictions))\\n    true_string = \\\"\\\".join(str(true_labels))\\n\\n    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\\n\\n    wd_score = windowdiff(pred_string, true_string, avg_k)\\n    pk_score = pk(pred_string, true_string, avg_k)\\n\\n    print(f\\\"pred_thresh = {pred_thresh}\\\")\\n    print(f\\\"k = {avg_k}\\\")\\n    print(f\\\"wd = {wd_score}\\\")\\n    print(f\\\"pk = {pk_score}\\\")\\n    print(\\\"===========================================\\\")\";\n",
       "                var nbb_formatted_code = \"for pred_thresh in pred_thresholds:\\n    modified_predictions = [\\n        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\\n    ]\\n\\n    pred_string = \\\"\\\".join(str(modified_predictions))\\n    true_string = \\\"\\\".join(str(true_labels))\\n\\n    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\\n\\n    wd_score = windowdiff(pred_string, true_string, avg_k)\\n    pk_score = pk(pred_string, true_string, avg_k)\\n\\n    print(f\\\"pred_thresh = {pred_thresh}\\\")\\n    print(f\\\"k = {avg_k}\\\")\\n    print(f\\\"wd = {wd_score}\\\")\\n    print(f\\\"pk = {pk_score}\\\")\\n    print(\\\"===========================================\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pred_thresh in pred_thresholds:\n",
    "    modified_predictions = [\n",
    "        1 if x < pred_thresh else 0 for x in [x[0] for x in predictions]\n",
    "    ]\n",
    "\n",
    "    pred_string = \"\".join(str(modified_predictions))\n",
    "    true_string = \"\".join(str(true_labels))\n",
    "\n",
    "    avg_k = len(true_labels) // (true_labels.count(1) + 1)  # get avg segment size\n",
    "\n",
    "    wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "    pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "    print(f\"pred_thresh = {pred_thresh}\")\n",
    "    print(f\"k = {avg_k}\")\n",
    "    print(f\"wd = {wd_score}\")\n",
    "    print(f\"pk = {pk_score}\")\n",
    "    print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6a2f65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 389;\n",
       "                var nbb_unformatted_code = \"print(pred_string)\\nprint(true_string)\";\n",
       "                var nbb_formatted_code = \"print(pred_string)\\nprint(true_string)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred_string)\n",
    "print(true_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b9dbb752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6\n",
      "wd = 0.4684563758389262\n",
      "pk = 0.4214765100671141\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 375;\n",
       "                var nbb_unformatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_formatted_code = \"wd_score = windowdiff(pred_string, true_string, avg_k)\\npk_score = pk(pred_string, true_string, avg_k)\\n\\nprint(f\\\"k = {avg_k}\\\")\\nprint(f\\\"wd = {wd_score}\\\")\\nprint(f\\\"pk = {pk_score}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd_score = windowdiff(pred_string, true_string, avg_k)\n",
    "pk_score = pk(pred_string, true_string, avg_k)\n",
    "\n",
    "print(f\"k = {avg_k}\")\n",
    "print(f\"wd = {wd_score}\")\n",
    "print(f\"pk = {pk_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34585627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462a8434",
   "metadata": {},
   "source": [
    "## KeyBERT Embedding Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d15e7648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 172;\n",
       "                var nbb_unformatted_code = \"curr = 230\\nprev = curr - 1\";\n",
       "                var nbb_formatted_code = \"curr = 230\\nprev = curr - 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curr = 230\n",
    "prev = curr - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the keywords and embeddings library\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "similarities_lib = Similarities(\"bert-base-uncased\")\n",
    "keywords_lib = Keywords(similarities_lib.model, similarities_lib.tokenizer)\n",
    "embedding_lib = Embedding(similarities_lib.model, similarities_lib.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8c6434ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the keywords in 0.6567 seconds\n",
      "Got the embeddings and comparisons in 0.0007 seconds\n",
      "['cantonese', 'languages', 'vietnamese', 'communes']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"cohesion = coherence.get_coherence(\\n    [text_data[curr], text_data[prev]], coherence_threshold=0.25\\n)\\nprint([k[0] for k in cohesion])\";\n",
       "                var nbb_formatted_code = \"cohesion = coherence.get_coherence(\\n    [text_data[curr], text_data[prev]], coherence_threshold=0.25\\n)\\nprint([k[0] for k in cohesion])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cohesion = coherence.get_coherence(\n",
    "    [text_data[curr], text_data[prev]], coherence_threshold=0.25\n",
    ")\n",
    "print([k[0] for k in cohesion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "357c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"# get the keywords for the current sentences\\nkeywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\\nkeywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\\n\\n# compute the word comparisons between the previous (with the coherence map)\\n# and the current (possibly the first sentence in a new segment)\\nword_comparisons_with_coherence, weights = compare_coherent_words(\\n    [keywords_prev], keywords_current\\n)\";\n",
       "                var nbb_formatted_code = \"# get the keywords for the current sentences\\nkeywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\\nkeywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\\n\\n# compute the word comparisons between the previous (with the coherence map)\\n# and the current (possibly the first sentence in a new segment)\\nword_comparisons_with_coherence, weights = compare_coherent_words(\\n    [keywords_prev], keywords_current\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the keywords for the current sentences\n",
    "keywords_current = keywords_lib.get_keywords_with_kb_embeddings(text_data[curr])\n",
    "keywords_prev = keywords_lib.get_keywords_with_kb_embeddings(text_data[prev])\n",
    "\n",
    "# compute the word comparisons between the previous (with the coherence map)\n",
    "# and the current (possibly the first sentence in a new segment)\n",
    "word_comparisons_with_coherence, weights = compare_coherent_words(\n",
    "    [keywords_prev], keywords_current\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dd52c9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('township', 0.2304),\n",
       "  ('communes', 0.1857),\n",
       "  ('hải', 0.1399),\n",
       "  ('wards', 0.1397),\n",
       "  ('đông', 0.1224)],\n",
       " [('cantonese', 0.5038),\n",
       "  ('mandarin', 0.464),\n",
       "  ('languages', 0.3483),\n",
       "  ('language', 0.343),\n",
       "  ('vietnamese', 0.3184)])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 207;\n",
       "                var nbb_unformatted_code = \"[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]\";\n",
       "                var nbb_formatted_code = \"[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[(x[0], x[1]) for x in keywords_current], [(x[0], x[1]) for x in keywords_prev]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f953",
   "metadata": {},
   "source": [
    "# KeyBERT Embedding Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "559ab602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 679;\n",
       "                var nbb_unformatted_code = \"docs = [\\n        \\\"Hi my name is Devarsh\\\",\\n        \\\"Devarsh likes to play Basketball.\\\",\\n    \\\"I love to watch Cricket.\\\",\\n        \\\"I am a strong programmer. And my name is Devarsh\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"docs = [\\n    \\\"Hi my name is Devarsh\\\",\\n    \\\"Devarsh likes to play Basketball.\\\",\\n    \\\"I love to watch Cricket.\\\",\\n    \\\"I am a strong programmer. And my name is Devarsh\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = [\n",
    "    \"Hi my name is Devarsh\",\n",
    "    \"Devarsh likes to play Basketball.\",\n",
    "    \"I love to watch Cricket.\",\n",
    "    \"I am a strong programmer. And my name is Devarsh\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "00458200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 680;\n",
       "                var nbb_unformatted_code = \"from keybert import KeyBERT\\n\\nkw_model = KeyBERT()\\ndoc_embeddings, word_embeddings = kw_model.extract_embeddings(\\n    docs, min_df=1, stop_words=\\\"english\\\"\\n)\\nkeywords = kw_model.extract_keywords(\\n    docs,\\n    min_df=1,\\n    stop_words=\\\"english\\\",\\n    doc_embeddings=doc_embeddings,\\n    word_embeddings=word_embeddings,\\n)\";\n",
       "                var nbb_formatted_code = \"from keybert import KeyBERT\\n\\nkw_model = KeyBERT()\\ndoc_embeddings, word_embeddings = kw_model.extract_embeddings(\\n    docs, min_df=1, stop_words=\\\"english\\\"\\n)\\nkeywords = kw_model.extract_keywords(\\n    docs,\\n    min_df=1,\\n    stop_words=\\\"english\\\",\\n    doc_embeddings=doc_embeddings,\\n    word_embeddings=word_embeddings,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "doc_embeddings, word_embeddings = kw_model.extract_embeddings(\n",
    "    docs, min_df=1, stop_words=\"english\"\n",
    ")\n",
    "keywords = kw_model.extract_keywords(\n",
    "    docs,\n",
    "    min_df=1,\n",
    "    stop_words=\"english\",\n",
    "    doc_embeddings=doc_embeddings,\n",
    "    word_embeddings=word_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "7d30bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 681;\n",
       "                var nbb_unformatted_code = \"len(doc_embeddings)\";\n",
       "                var nbb_formatted_code = \"len(doc_embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "018ee52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 682;\n",
       "                var nbb_unformatted_code = \"len(word_embeddings)\";\n",
       "                var nbb_formatted_code = \"len(word_embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "80cbdc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('devarsh', 0.6267), ('hi', 0.5216)],\n",
       " [('devarsh', 0.6549),\n",
       "  ('basketball', 0.5558),\n",
       "  ('play', 0.3787),\n",
       "  ('likes', 0.2284)],\n",
       " [('cricket', 0.7118), ('watch', 0.3656), ('love', 0.307)],\n",
       " [('programmer', 0.5942), ('devarsh', 0.5528), ('strong', 0.3452)]]"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 683;\n",
       "                var nbb_unformatted_code = \"keywords\";\n",
       "                var nbb_formatted_code = \"keywords\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "fd1ac50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 701;\n",
       "                var nbb_unformatted_code = \"kw_model = KeyBERT()\\nimport torch\\n\\n\\ndef get_keywords_with_embeddings_test(\\n    data,\\n) -> list[tuple[str, float, torch.Tensor]]:\\n    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\\n\\n    keywords = kw_model.extract_keywords(\\n        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\\n    )\\n\\n    keywords_with_embeddings = []\\n    count = 0\\n    print(len(word_embeddings))\\n    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\\n        for j, words in enumerate(kw):\\n            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\\n            count += 1\\n\\n    return keywords_with_embeddings\";\n",
       "                var nbb_formatted_code = \"kw_model = KeyBERT()\\nimport torch\\n\\n\\ndef get_keywords_with_embeddings_test(\\n    data,\\n) -> list[tuple[str, float, torch.Tensor]]:\\n    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\\n\\n    keywords = kw_model.extract_keywords(\\n        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\\n    )\\n\\n    keywords_with_embeddings = []\\n    count = 0\\n    print(len(word_embeddings))\\n    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\\n        for j, words in enumerate(kw):\\n            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\\n            count += 1\\n\\n    return keywords_with_embeddings\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_keywords_with_embeddings_test(\n",
    "    data,\n",
    ") -> list[tuple[str, float, torch.Tensor]]:\n",
    "    doc_embeddings, word_embeddings = kw_model.extract_embeddings(data)\n",
    "\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        data, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings\n",
    "    )\n",
    "\n",
    "    keywords_with_embeddings = []\n",
    "    count = 0\n",
    "    print(len(word_embeddings))\n",
    "    for i, (kw, we) in enumerate(zip(keywords, word_embeddings)):\n",
    "        for j, words in enumerate(kw):\n",
    "            keywords_with_embeddings.append((words[0], words[1], torch.tensor(we)))\n",
    "            count += 1\n",
    "\n",
    "    return keywords_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "d1bbf3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 702;\n",
       "                var nbb_unformatted_code = \"embeddings = get_keywords_with_embeddings_test(docs)\";\n",
       "                var nbb_formatted_code = \"embeddings = get_keywords_with_embeddings_test(docs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = get_keywords_with_embeddings_test(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "f1ea7b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 703;\n",
       "                var nbb_unformatted_code = \"len(embeddings)\";\n",
       "                var nbb_formatted_code = \"len(embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883ef15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
