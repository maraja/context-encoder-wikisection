{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3b816077"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"],"id":"3b816077"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74078,"status":"ok","timestamp":1671198314707,"user":{"displayName":"Amit Maraj","userId":"16669611174731103480"},"user_tz":300},"id":"vUECyENeltWJ","outputId":"faaacedb-25d9-49d9-8ab1-6af0b5e62b06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.3.3\n","  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (3.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.3) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.3.3) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.3) (2022.12.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.3) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.3) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.3) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b49ef89f4bc81407d08440decce38548916a4210a6baadf0a8c71a999a42c9b6\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting stop_words\n","  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n","Building wheels for collected packages: stop-words\n","  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=b55858a91c0d21427c91786a533ef2b591f285306cd0030fef5a27af2407ddcb\n","  Stored in directory: /root/.cache/pip/wheels/eb/03/0d/3bd31c983789aeb0b4d5e2ca48590288d9db1586cf5f225062\n","Successfully built stop-words\n","Installing collected packages: stop-words\n","Successfully installed stop-words-2018.7.23\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting symspellpy\n","  Downloading symspellpy-6.7.7-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.0 MB/s \n","\u001b[?25hCollecting editdistpy>=0.1.3\n","  Downloading editdistpy-0.1.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 89.8 MB/s \n","\u001b[?25hInstalling collected packages: editdistpy, symspellpy\n","Successfully installed editdistpy-0.1.3 symspellpy-6.7.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting language_detector\n","  Downloading language-detector-5.0.2.tar.gz (6.6 kB)\n","Building wheels for collected packages: language-detector\n","  Building wheel for language-detector (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for language-detector: filename=language_detector-5.0.2-py3-none-any.whl size=7052 sha256=f96513825bc7027b7da5bd8846ff5f5584583bc4d7d583f79cb35cc0749d25d4\n","  Stored in directory: /root/.cache/pip/wheels/fb/aa/7c/23b0859aab6e5fef62c9e1db0eb2b7efa8ccf7f001d87bcbd3\n","Successfully built language-detector\n","Installing collected packages: language-detector\n","Successfully installed language-detector-5.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cached_property\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Installing collected packages: cached-property\n","Successfully installed cached-property-1.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.8 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting config\n","  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n","Installing collected packages: config\n","Successfully installed config-0.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting umap\n","  Downloading umap-0.1.1.tar.gz (3.2 kB)\n","Building wheels for collected packages: umap\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3565 sha256=32d6300c11c40dfb313a2a2a6afa5af76176bdb4fe47bb0ce0b146cf725baf47\n","  Stored in directory: /root/.cache/pip/wheels/d4/13/91/2e752dc8dab5df027854bd33d2b65e1dc5cdc107fd1133990f\n","Successfully built umap\n","Installing collected packages: umap\n","Successfully installed umap-0.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentence-transformers==0.4.1\n","  Downloading sentence-transformers-0.4.1.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (4.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (4.64.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (1.13.0+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (1.7.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (3.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence-transformers==0.4.1) (0.1.97)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->sentence-transformers==0.4.1) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.8.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2022.6.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (0.0.53)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers==0.4.1) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers==0.4.1) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers==0.4.1) (3.1.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1-py3-none-any.whl size=103051 sha256=d68910b1b3c86a2901ccc083f6ce641954cc7ccd81736bfc5df9c352c8d646ea\n","  Stored in directory: /root/.cache/pip/wheels/45/53/a3/113ad62d54c14d565127100ca511a104b5c33dc9534bf5cae4\n","Successfully built sentence-transformers\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-0.4.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# run this cell if running remotely\n","\n","!pip install transformers==4.3.3\n","!pip install stop_words\n","!pip install symspellpy\n","!pip install language_detector\n","!pip install cached_property\n","!pip install sentencepiece\n","!pip install config\n","!pip install umap\n","!pip install sentence-transformers==0.4.1\n","!pip install nltk\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import tensorflow, sentence_transformers, transformers\n","tensorflow.__version__, sentence_transformers.__version__, transformers.__version__\n","\n","root_path = \"/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2\"\n","import sys, os\n","import config\n","\n","config.root_path = os.path.abspath(root_path)\n","sys.path.insert(0, config.root_path)"],"id":"vUECyENeltWJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzgNkHqtuw_A"},"outputs":[],"source":["# run this cell if working locally\n","import sys, os\n","import config\n","\n","config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n","sys.path.insert(0, config.root_path)"],"id":"nzgNkHqtuw_A"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1671198315170,"user":{"displayName":"Amit Maraj","userId":"16669611174731103480"},"user_tz":300},"id":"wu2Ocq82xjTf","outputId":"dae5f835-6255-48eb-a587-2020c043e7ea"},"outputs":[{"data":{"text/plain":["['/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2',\n"," '/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python38.zip',\n"," '/usr/lib/python3.8',\n"," '/usr/lib/python3.8/lib-dynload',\n"," '',\n"," '/usr/local/lib/python3.8/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.8/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["root_path = \"/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2\"\n","\n","config.root_path = os.path.abspath(root_path)\n","sys.path.insert(0, config.root_path)\n","sys.path"],"id":"wu2Ocq82xjTf"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["64f52ec6de434164b38c327f425b22e8","b7b38673d41340fdba947a93dabfd462","7a4609be765e477aa11173d453913202","07b12d60394d431b9c390ea33fac9b95","2fbdf462973945cf97ed90aa97c7dc58","791b866925dc44e4a5ce2bda758c3cc5","063f42fcf5be4c1cbf0c58735c5f6547","af5c39705db44dc9a1e70c00da9a0214","3c0a0038c5224e34a8275d4b8ad486c1","f65cc3c23dfa4e61b6e98448b11e185b","0c85d606b3e04c798f86a2549b73ecc0","6c0a6f56522a424aa6b76efd1cf9673c","748372025b8e4e40995a11f3d4fe40d0","f9416200cdd148f99d85db7a1f9a924e","474e3be2f0824e3db3ed84d161e41771","f97a92256cb54c85a1add4270889f252","07cf81cdc75f4f3baaa11e2078bad98f","b72719882c61485990b424540684ce5a","3189d22c5c5d4456b4568774b3a805bd","a96102b5a6224d08adc0f5dc0f800baf","a772e0e95cce48f8a03a5ac9f2de9e8e","28a130b6976546cbaf442038ea116691","ce50e82623cf4f55a0102541c75d23ae","be89ad3989ea4511b62d031a64895141","be66c8351228415d8b5a506ae8d07136","c7a825793e9445caba328cb4f9c18645","596f7d3d232a407383b39de2b4eaa6d2","e142f2288c7a44f99dd60da44730c8d5","52be9ecbb5fa4a5086a013b0fe063ebb","dd1d905665b64be894a724acd5dfde0a","90996a2e531544b393d5a7d2f71dd263","16d7077da7474bbf8c77ee89ac497d73","0c9c9343f404423a9accefc76095897d","db9c0a3196a248bcbbcf660504208943","143da96a82e942d8bc71fd2ffcf3f932","e1c5e52d61484539ad717f2f3c678edb","a622def7ec154d53ba2abb47ed121b3a","47d5fdc1e91c4cacb9eb18286c1eb9fd","e225c13f0cb74f52b577429bb8174975","19fbab42035644168a21a311d9446c61","848e599fb9e24f9885de88896a2e81ed","2339ed21727143a4a9860943fd16f09a","6df96f85350f42b4b6fd07834b066888","e78fc6999a0e451b9b821e0578706540","0bfc01cb904146f5a7cd75a61ffc7308","8007597bed154694bad355f9396b6b9b","2a53722769264511982b74ee29f1980b","505389d0441e4f05957f4a963c08b944","c92356df80674b08b26d95ef20847f93","153aaea32fe94f72a2a07fd7b4fbc917","285e5a42e8bf4693b20827d4d28a4c2e","6735e487855c4353bf57f1522e70137c","c62da119e31c4641954b56b25c79c772","5439db8c87a9440fba82cca152906c71","e95d12714fe340aa9bc9baf37b58e217","53e39268ece84fdb8e5fcbef654a841e","8b32f32f34454d05854c315a99e0bad2","7bef114e682a4983b0387da7db41ec9b","ad2637bb7fca4b1cb8525a152c07b99a","a6a1b9c4d7ca4f19bbf5dcd961ab6462","5ff162962ec743eaab11146a1ab0a42e","7699ea43dc554d47b22a23ba9edaddd9","667e166d08c345b0948549b8e9541f1d","5556915b5f244cb9afd08872d008fffd","ef70f9a76ab74eeb8d6700ed3f9b7e4d","c40417881a9a4969b0a40154726f80e4"]},"executionInfo":{"elapsed":23179,"status":"ok","timestamp":1671198338347,"user":{"displayName":"Amit Maraj","userId":"16669611174731103480"},"user_tz":300},"id":"811f4ff7","outputId":"91adbb6d-36b0-499d-81da-4b026f6d3bef"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64f52ec6de434164b38c327f425b22e8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/630 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c0a6f56522a424aa6b76efd1cf9673c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce50e82623cf4f55a0102541c75d23ae","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db9c0a3196a248bcbbcf660504208943","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bfc01cb904146f5a7cd75a61ffc7308","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53e39268ece84fdb8e5fcbef654a841e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/409 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import tensorflow as tf\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","from src.encoders.context_encoder_ldabert_2 import ContextEncoderSimple\n","from src.dataset.ldabert_2 import LDABERT2Dataset\n","\n","from tensorflow.python import keras\n","import toml\n","import json\n","import pandas as pd\n","import numpy as np\n","from utils.experiments import get_experiments_json, get_experiments, save_results"],"id":"811f4ff7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"26986a31"},"outputs":[],"source":[],"id":"26986a31"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5a5de02f"},"outputs":[],"source":[],"id":"5a5de02f"},{"cell_type":"markdown","metadata":{"id":"66caca4d"},"source":["## Experiment"],"id":"66caca4d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1671198338610,"user":{"displayName":"Amit Maraj","userId":"16669611174731103480"},"user_tz":300},"id":"gTJTmy-X1gyN","outputId":"d4b34c47-3b89-4bb6-d5c6-f4f7cc5c7f97"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-fa2faa0c-1f74-475b-89b7-83bf1f6f5dfb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bert_type</th>\n","      <th>dataset_type</th>\n","      <th>final_dropout</th>\n","      <th>dense_neurons</th>\n","      <th>max_sentence_length</th>\n","      <th>gamma</th>\n","      <th>pct_data</th>\n","      <th>augment_pct</th>\n","      <th>bert_trainable</th>\n","      <th>epochs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ldabert</td>\n","      <td>clinical</td>\n","      <td>0.5</td>\n","      <td>128</td>\n","      <td>128</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ldabert</td>\n","      <td>wiki</td>\n","      <td>0.5</td>\n","      <td>128</td>\n","      <td>128</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ldabert</td>\n","      <td>fiction</td>\n","      <td>0.5</td>\n","      <td>128</td>\n","      <td>128</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa2faa0c-1f74-475b-89b7-83bf1f6f5dfb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fa2faa0c-1f74-475b-89b7-83bf1f6f5dfb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fa2faa0c-1f74-475b-89b7-83bf1f6f5dfb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  bert_type dataset_type  final_dropout  dense_neurons  max_sentence_length  \\\n","0   ldabert     clinical            0.5            128                  128   \n","1   ldabert         wiki            0.5            128                  128   \n","2   ldabert      fiction            0.5            128                  128   \n","\n","   gamma  pct_data  augment_pct  bert_trainable  epochs  \n","0     15         1            1            True      50  \n","1     15         1            1            True      50  \n","2     15         1            1            True      50  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["experiments_config = get_experiments_json('ldabert2_simple_finetune_test')\n","experiments_config_df = pd.DataFrame.from_dict(experiments_config)\n","experiments_config_df"],"id":"gTJTmy-X1gyN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-JZ0fAd1oBO"},"outputs":[],"source":["experiments_config_df.to_csv(r'../models/experiment.csv', header=None, index=None, sep=' ', mode='a')"],"id":"p-JZ0fAd1oBO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtQh12191ome"},"outputs":[],"source":["def get_random_hash(k):\n","  import random, string\n","  x = ''.join(random.choices(string.ascii_letters + string.digits, k=k))\n","  return x"],"id":"rtQh12191ome"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJXQb_X7ymh1"},"outputs":[],"source":[],"id":"iJXQb_X7ymh1"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8659ace","executionInfo":{"status":"ok","timestamp":1671275684894,"user_tz":300,"elapsed":49160004,"user":{"displayName":"Amit Maraj","userId":"16669611174731103480"}},"outputId":"dba32efe-9639-45ef-e24c-87eb20cfcf70"},"outputs":[{"output_type":"stream","name":"stdout","text":["params: {'bert_type': 'ldabert', 'dataset_type': 'fiction', 'final_dropout': 0.5, 'dense_neurons': 128, 'max_sentence_length': 128, 'gamma': 15, 'pct_data': 1, 'augment_pct': 1, 'bert_trainable': True, 'epochs': 50}\n","initializing model...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["initializing dataset...\n","processing dataset...\n","artificial segments True\n","artificial segments True\n","something went wrong [Errno 2] No such file or directory: '/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/data/lda_bert_2/generated_vectors/train/fiction/1_1_as-True_msl-300.pkl'\n","root path /content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2\n","Preprocessing raw texts ...\n","sentences length 64277\n","Preprocessing raw texts. Done!\n","lda sentences length 64277\n","Getting vector representations for LDA ...\n","Getting vector representations for LDA. Done!\n","saving vectors... 64277 64277 64277\n","initializing testing dataset...\n","processing testing dataset...\n","artificial segments False\n","class weight {0: 0.5279945456636383, 1: 9.43031103286385}\n","/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/models/LDABERT2/simple/fiction-64277-1-pct-1-aug_C5EvF/finetune/checkpoint.ckpt\n","compiling the model...\n","No checkpoint available.\n","starting the finetune training process...\n","Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["4018/4018 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7599"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4018/4018 [==============================] - 876s 209ms/step - loss: 0.5422 - accuracy: 0.7599 - val_loss: 0.5538 - val_accuracy: 0.7622\n","Epoch 2/5\n","4018/4018 [==============================] - 836s 208ms/step - loss: 0.5180 - accuracy: 0.7642 - val_loss: 0.5309 - val_accuracy: 0.7655\n","Epoch 3/5\n","4018/4018 [==============================] - 836s 208ms/step - loss: 0.5073 - accuracy: 0.7668 - val_loss: 0.5701 - val_accuracy: 0.7663\n","Epoch 4/5\n","4018/4018 [==============================] - 833s 207ms/step - loss: 0.4963 - accuracy: 0.7666 - val_loss: 0.5952 - val_accuracy: 0.7660\n","Epoch 5/5\n","4018/4018 [==============================] - 833s 207ms/step - loss: 0.4926 - accuracy: 0.7654 - val_loss: 0.6611 - val_accuracy: 0.7645\n","saving results...\n","initializing model...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["initializing dataset...\n","processing dataset...\n","artificial segments True\n","artificial segments True\n","initializing testing dataset...\n","processing testing dataset...\n","artificial segments False\n","class weight {0: 0.5279945456636383, 1: 9.43031103286385}\n","/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/models/LDABERT2/simple/fiction-64277-1-pct-1-aug_C5EvF/finetune/checkpoint.ckpt\n","compiling the model...\n","model loaded.\n","starting the frozen training process...\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["4018/4018 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.7682"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4018/4018 [==============================] - 880s 210ms/step - loss: 0.4984 - accuracy: 0.7682 - val_loss: 0.6372 - val_accuracy: 0.7657\n","Epoch 2/50\n","4018/4018 [==============================] - 836s 208ms/step - loss: 0.4942 - accuracy: 0.7618 - val_loss: 0.5445 - val_accuracy: 0.7640\n","Epoch 3/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4838 - accuracy: 0.7635 - val_loss: 0.5025 - val_accuracy: 0.7663\n","Epoch 4/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4794 - accuracy: 0.7678 - val_loss: 0.5665 - val_accuracy: 0.7681\n","Epoch 5/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4736 - accuracy: 0.7686 - val_loss: 0.4068 - val_accuracy: 0.7703\n","Epoch 6/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4714 - accuracy: 0.7722 - val_loss: 0.5619 - val_accuracy: 0.7723\n","Epoch 7/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4699 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7733\n","Epoch 8/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4624 - accuracy: 0.7739 - val_loss: 0.5901 - val_accuracy: 0.7738\n","Epoch 9/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4594 - accuracy: 0.7734 - val_loss: 0.5228 - val_accuracy: 0.7739\n","Epoch 10/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4569 - accuracy: 0.7744 - val_loss: 0.4895 - val_accuracy: 0.7749\n","Epoch 11/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4577 - accuracy: 0.7753 - val_loss: 0.4134 - val_accuracy: 0.7763\n","Epoch 12/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4553 - accuracy: 0.7771 - val_loss: 0.5395 - val_accuracy: 0.7773\n","Epoch 13/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4518 - accuracy: 0.7775 - val_loss: 0.5609 - val_accuracy: 0.7775\n","Epoch 14/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4493 - accuracy: 0.7777 - val_loss: 0.6022 - val_accuracy: 0.7776\n","Epoch 15/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4511 - accuracy: 0.7775 - val_loss: 0.5094 - val_accuracy: 0.7777\n","Epoch 16/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4499 - accuracy: 0.7780 - val_loss: 0.5864 - val_accuracy: 0.7779\n","Epoch 17/50\n","4018/4018 [==============================] - 842s 209ms/step - loss: 0.4490 - accuracy: 0.7780 - val_loss: 0.5173 - val_accuracy: 0.7781\n","Epoch 18/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4460 - accuracy: 0.7783 - val_loss: 0.4493 - val_accuracy: 0.7787\n","Epoch 19/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4486 - accuracy: 0.7792 - val_loss: 0.4302 - val_accuracy: 0.7796\n","Epoch 20/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4466 - accuracy: 0.7801 - val_loss: 0.3850 - val_accuracy: 0.7806\n","Epoch 21/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4453 - accuracy: 0.7811 - val_loss: 0.6917 - val_accuracy: 0.7808\n","Epoch 22/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4382 - accuracy: 0.7806 - val_loss: 0.4284 - val_accuracy: 0.7810\n","Epoch 23/50\n","4018/4018 [==============================] - 845s 210ms/step - loss: 0.4428 - accuracy: 0.7814 - val_loss: 0.5033 - val_accuracy: 0.7816\n","Epoch 24/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4430 - accuracy: 0.7818 - val_loss: 0.4326 - val_accuracy: 0.7821\n","Epoch 25/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4397 - accuracy: 0.7825 - val_loss: 0.5296 - val_accuracy: 0.7826\n","Epoch 26/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4408 - accuracy: 0.7827 - val_loss: 0.6123 - val_accuracy: 0.7827\n","Epoch 27/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4393 - accuracy: 0.7826 - val_loss: 0.5212 - val_accuracy: 0.7827\n","Epoch 28/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4390 - accuracy: 0.7828 - val_loss: 0.5027 - val_accuracy: 0.7830\n","Epoch 29/50\n","4018/4018 [==============================] - 843s 210ms/step - loss: 0.4396 - accuracy: 0.7832 - val_loss: 0.5950 - val_accuracy: 0.7832\n","Epoch 30/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4405 - accuracy: 0.7831 - val_loss: 0.3799 - val_accuracy: 0.7835\n","Epoch 31/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4372 - accuracy: 0.7838 - val_loss: 0.4418 - val_accuracy: 0.7840\n","Epoch 32/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4349 - accuracy: 0.7843 - val_loss: 0.5596 - val_accuracy: 0.7843\n","Epoch 33/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4357 - accuracy: 0.7844 - val_loss: 0.4643 - val_accuracy: 0.7846\n","Epoch 34/50\n","4018/4018 [==============================] - 844s 210ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7848\n","Epoch 35/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4361 - accuracy: 0.7849 - val_loss: 0.3517 - val_accuracy: 0.7853\n","Epoch 36/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4377 - accuracy: 0.7856 - val_loss: 0.4340 - val_accuracy: 0.7858\n","Epoch 37/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4345 - accuracy: 0.7861 - val_loss: 0.4348 - val_accuracy: 0.7862\n","Epoch 38/50\n","4018/4018 [==============================] - 841s 209ms/step - loss: 0.4306 - accuracy: 0.7863 - val_loss: 0.4806 - val_accuracy: 0.7865\n","Epoch 39/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4306 - accuracy: 0.7866 - val_loss: 0.5161 - val_accuracy: 0.7867\n","Epoch 40/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4308 - accuracy: 0.7868 - val_loss: 0.5298 - val_accuracy: 0.7868\n","Epoch 41/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4279 - accuracy: 0.7869 - val_loss: 0.4253 - val_accuracy: 0.7871\n","Epoch 42/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4355 - accuracy: 0.7873 - val_loss: 0.4205 - val_accuracy: 0.7875\n","Epoch 43/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4310 - accuracy: 0.7877 - val_loss: 0.4112 - val_accuracy: 0.7878\n","Epoch 44/50\n","4018/4018 [==============================] - 839s 209ms/step - loss: 0.4294 - accuracy: 0.7880 - val_loss: 0.4701 - val_accuracy: 0.7882\n","Epoch 45/50\n","4018/4018 [==============================] - 843s 210ms/step - loss: 0.4272 - accuracy: 0.7884 - val_loss: 0.3837 - val_accuracy: 0.7886\n","Epoch 46/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4339 - accuracy: 0.7889 - val_loss: 0.4550 - val_accuracy: 0.7889\n","Epoch 47/50\n","4018/4018 [==============================] - 840s 209ms/step - loss: 0.4294 - accuracy: 0.7891 - val_loss: 0.5717 - val_accuracy: 0.7891\n","Epoch 48/50\n","4018/4018 [==============================] - 842s 210ms/step - loss: 0.4273 - accuracy: 0.7890 - val_loss: 0.4183 - val_accuracy: 0.7892\n","Epoch 49/50\n","4018/4018 [==============================] - 839s 209ms/step - loss: 0.4265 - accuracy: 0.7894 - val_loss: 0.5307 - val_accuracy: 0.7895\n","Epoch 50/50\n","4018/4018 [==============================] - 839s 209ms/step - loss: 0.4232 - accuracy: 0.7896 - val_loss: 0.5012 - val_accuracy: 0.7896\n","saving results...\n"]}],"source":["# all\n","for experiment in experiments_config[2:3]:\n","    dataset_type = experiment['dataset_type']\n","    final_dropout = experiment['final_dropout']\n","    dense_neurons = experiment['dense_neurons']\n","    pct_data = experiment['pct_data']\n","    augment_pct = experiment['augment_pct']\n","    gamma = experiment['gamma']\n","    max_sentence_length = experiment['max_sentence_length']\n","    bert_trainable = experiment['bert_trainable']\n","    epochs = experiment['epochs']\n","    BATCH_SIZE = 16\n","    finetuning_epochs = 5 # finetune the system for 5 epochs before training with the frozen finetuned BERT weights\n","    print(\"params:\", experiment)\n","    random_hash = get_random_hash(5)\n","    experiment['epochs'] = epochs\n","\n","    for step in [\"finetune\",\"frozen\"]:\n","        # init model\n","        print(\"initializing model...\")\n","        model = ContextEncoderSimple(final_dropout=final_dropout,\n","                                dense_neurons=dense_neurons,\n","                              gamma=gamma,\n","                              max_sentence_length=max_sentence_length,\n","                               bert_trainable=bert_trainable)\n","\n","        # print(\"number of params: \", sum([np.prod(keras.get_value(w).shape) for w in model.trainable_weights]))\n","\n","        # init dataset\n","        print(\"initializing dataset...\")\n","        dataset = LDABERT2Dataset(dataset_type=dataset_type,\n","                                pct_data=pct_data,\n","                              max_seq_length=max_sentence_length,\n","                                max_segment_length=300,\n","                                augment_pct=augment_pct,\n","                                split=\"train\",\n","                            artificial_segments=True)\n","\n","        # process dataset\n","        print(\"processing dataset...\")\n","        sentences, tokenized_sentences, labels = dataset.process()\n","\n","\n","        vectors_filename = '{}_{}_as-{}_msl-{}.pkl'.format(dataset.pct_data, dataset.augment_pct, dataset.artificial_segments, dataset.max_segment_length)\n","\n","        saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.get_saved_vectors(\"train\", dataset.dataset_type, vectors_filename)\n","\n","        if len(saved_vectors) == 0:\n","            saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.create_vectors(\"train\", dataset.dataset_type, vectors_filename)\n","\n","        left_input, mid_input, right_input = dataset.format_sentences_tri_input_plus(saved_tokenized_sentences)\n","        lda_left_input, lda_mid_input, lda_right_input = dataset.format_sentences_tri_input(saved_vectors)\n","\n","        # init testing dataset\n","        print(\"initializing testing dataset...\")\n","        testing_dataset = LDABERT2Dataset(dataset_type=dataset_type,\n","                                pct_data=0.25,\n","                              max_seq_length=512,\n","                                max_segment_length=300,\n","                                augment_pct=0,\n","                                split=\"test\",\n","                            artificial_segments=False)\n","\n","        # process testing dataset\n","        print(\"processing testing dataset...\")\n","        testing_sentences, testing_tokenized_sentences, testing_labels = testing_dataset.process()\n","\n","        vectors_filename = '{}_{}_testing_data.pkl'.format(testing_dataset.pct_data, testing_dataset.augment_pct)\n","\n","        testing_saved_vectors, testing_saved_labels, testing_saved_sentences, testing_saved_tokenized_sentences = testing_dataset.get_saved_vectors(\"test\", testing_dataset.dataset_type, vectors_filename)\n","\n","        if len(testing_saved_vectors) == 0:\n","            testing_saved_vectors, testing_saved_labels, testing_saved_sentences, testing_saved_tokenized_sentences = testing_dataset.create_vectors(\"test\", testing_dataset.dataset_type, vectors_filename)\n","\n","        testing_left_input, testing_mid_input, testing_right_input = testing_dataset.format_sentences_tri_input_plus(testing_saved_tokenized_sentences)\n","        testing_lda_left_input, testing_lda_mid_input, testing_lda_right_input = testing_dataset.format_sentences_tri_input(testing_saved_vectors)\n","\n","        # get class weight\n","        neg, pos = np.bincount(labels.flatten())\n","        initial_bias = np.log([pos/neg])\n","\n","        total=len(labels)\n","        weight_for_0 = (1 / neg)*(total)/2.0\n","        weight_for_1 = (1 / pos)*(total)/2.0\n","\n","        class_weight = {0: weight_for_0, 1: weight_for_1}\n","        print(\"class weight\", class_weight)\n","\n","        # create checkpoint path\n","        checkpoint_filepath = '{}/models/LDABERT2/simple/{}-{}-{}-pct-{}-aug_{}/finetune/checkpoint.ckpt'.format(\n","                                config.root_path,\n","                                dataset.dataset_type,\n","                                len(saved_sentences),\n","                                dataset.pct_data,\n","                                dataset.augment_pct,\n","                                random_hash)\n","\n","        if step == \"frozen\":\n","            # create checkpoint path\n","            checkpoint_filepath = '{}/models/LDABERT2/simple/{}-{}-{}-pct-{}-aug_{}/finetune/checkpoint.ckpt'.format(\n","                                    config.root_path,\n","                                    dataset.dataset_type,\n","                                    len(saved_sentences),\n","                                    dataset.pct_data,\n","                                    dataset.augment_pct,\n","                                    random_hash)\n","\n","    #     # continue training\n","    #     checkpoint_filepath = '{}/models/LDABERT2/simple/clinical-16122-1-pct-1-aug_288O6/finetune/checkpoint.ckpt'.format(config.root_path)\n","\n","        print(checkpoint_filepath)\n","\n","        # get callbacks ready.\n","        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=checkpoint_filepath,\n","            save_weights_only=True,\n","            monitor='val_accuracy',\n","            save_best_only=True,\n","            mode=\"auto\",\n","            save_freq=\"epoch\")\n","\n","        early_stopping = tf.keras.callbacks.EarlyStopping(\n","            monitor='val_accuracy',\n","            verbose=1,\n","            patience=10,\n","            mode='max',\n","            restore_best_weights=True)\n","\n","        callbacks = [\n","        #     early_stopping,\n","            model_checkpoint_callback\n","        ]\n","\n","        # compiling model\n","        print(\"compiling the model...\")\n","        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","                      loss=tf.keras.losses.BinaryCrossentropy(),\n","                      metrics=[\n","                          keras.metrics.BinaryAccuracy(name='accuracy')\n","                      ])\n","\n","        try:\n","            model.load_weights(checkpoint_filepath)\n","            print(\"model loaded.\")\n","        except:\n","            print(\"No checkpoint available.\")\n","\n","        print(f\"starting the {step} training process...\")\n","        history = model.fit([\n","                                left_input, mid_input, right_input,\n","                                lda_left_input, lda_mid_input, lda_right_input\n","                            ],\n","                            tf.convert_to_tensor(saved_labels),\n","                            validation_data=([\n","                                testing_left_input, testing_mid_input, testing_right_input,\n","                                testing_lda_left_input, testing_lda_mid_input, testing_lda_right_input\n","                            ], tf.convert_to_tensor(testing_saved_labels)),\n","                            epochs=finetuning_epochs if step == \"finetune\" else epochs,\n","                            # validation_split=0.25,\n","                            batch_size=BATCH_SIZE,\n","                            verbose=1,\n","                            class_weight=class_weight,\n","                            callbacks=callbacks)\n","\n","        # assigning history to experiment object for saving.\n","        experiment[\"history\"] = history.history\n","        experiment[\"hash\"] = random_hash\n","\n","        print(\"saving results...\")\n","        save_results(experiment)"],"id":"a8659ace"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyRFxeEbxcmw"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"id":"fyRFxeEbxcmw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sVFESlTpQ18"},"outputs":[],"source":[],"id":"2sVFESlTpQ18"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"063f42fcf5be4c1cbf0c58735c5f6547":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07b12d60394d431b9c390ea33fac9b95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f65cc3c23dfa4e61b6e98448b11e185b","placeholder":"​","style":"IPY_MODEL_0c85d606b3e04c798f86a2549b73ecc0","value":" 630/630 [00:00&lt;00:00, 43.0kB/s]"}},"07cf81cdc75f4f3baaa11e2078bad98f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bfc01cb904146f5a7cd75a61ffc7308":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8007597bed154694bad355f9396b6b9b","IPY_MODEL_2a53722769264511982b74ee29f1980b","IPY_MODEL_505389d0441e4f05957f4a963c08b944"],"layout":"IPY_MODEL_c92356df80674b08b26d95ef20847f93"}},"0c85d606b3e04c798f86a2549b73ecc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c9c9343f404423a9accefc76095897d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143da96a82e942d8bc71fd2ffcf3f932":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e225c13f0cb74f52b577429bb8174975","placeholder":"​","style":"IPY_MODEL_19fbab42035644168a21a311d9446c61","value":"Downloading: 100%"}},"153aaea32fe94f72a2a07fd7b4fbc917":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16d7077da7474bbf8c77ee89ac497d73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19fbab42035644168a21a311d9446c61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2339ed21727143a4a9860943fd16f09a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"285e5a42e8bf4693b20827d4d28a4c2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28a130b6976546cbaf442038ea116691":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a53722769264511982b74ee29f1980b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6735e487855c4353bf57f1522e70137c","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c62da119e31c4641954b56b25c79c772","value":112}},"2fbdf462973945cf97ed90aa97c7dc58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3189d22c5c5d4456b4568774b3a805bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0a0038c5224e34a8275d4b8ad486c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"474e3be2f0824e3db3ed84d161e41771":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a772e0e95cce48f8a03a5ac9f2de9e8e","placeholder":"​","style":"IPY_MODEL_28a130b6976546cbaf442038ea116691","value":" 232k/232k [00:00&lt;00:00, 1.79MB/s]"}},"47d5fdc1e91c4cacb9eb18286c1eb9fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505389d0441e4f05957f4a963c08b944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5439db8c87a9440fba82cca152906c71","placeholder":"​","style":"IPY_MODEL_e95d12714fe340aa9bc9baf37b58e217","value":" 112/112 [00:00&lt;00:00, 7.21kB/s]"}},"52be9ecbb5fa4a5086a013b0fe063ebb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53e39268ece84fdb8e5fcbef654a841e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b32f32f34454d05854c315a99e0bad2","IPY_MODEL_7bef114e682a4983b0387da7db41ec9b","IPY_MODEL_ad2637bb7fca4b1cb8525a152c07b99a"],"layout":"IPY_MODEL_a6a1b9c4d7ca4f19bbf5dcd961ab6462"}},"5439db8c87a9440fba82cca152906c71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5556915b5f244cb9afd08872d008fffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"596f7d3d232a407383b39de2b4eaa6d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff162962ec743eaab11146a1ab0a42e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64f52ec6de434164b38c327f425b22e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7b38673d41340fdba947a93dabfd462","IPY_MODEL_7a4609be765e477aa11173d453913202","IPY_MODEL_07b12d60394d431b9c390ea33fac9b95"],"layout":"IPY_MODEL_2fbdf462973945cf97ed90aa97c7dc58"}},"667e166d08c345b0948549b8e9541f1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6735e487855c4353bf57f1522e70137c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0a6f56522a424aa6b76efd1cf9673c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_748372025b8e4e40995a11f3d4fe40d0","IPY_MODEL_f9416200cdd148f99d85db7a1f9a924e","IPY_MODEL_474e3be2f0824e3db3ed84d161e41771"],"layout":"IPY_MODEL_f97a92256cb54c85a1add4270889f252"}},"6df96f85350f42b4b6fd07834b066888":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748372025b8e4e40995a11f3d4fe40d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07cf81cdc75f4f3baaa11e2078bad98f","placeholder":"​","style":"IPY_MODEL_b72719882c61485990b424540684ce5a","value":"Downloading: 100%"}},"7699ea43dc554d47b22a23ba9edaddd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"791b866925dc44e4a5ce2bda758c3cc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4609be765e477aa11173d453913202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af5c39705db44dc9a1e70c00da9a0214","max":630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c0a0038c5224e34a8275d4b8ad486c1","value":630}},"7bef114e682a4983b0387da7db41ec9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_667e166d08c345b0948549b8e9541f1d","max":409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5556915b5f244cb9afd08872d008fffd","value":409}},"8007597bed154694bad355f9396b6b9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_153aaea32fe94f72a2a07fd7b4fbc917","placeholder":"​","style":"IPY_MODEL_285e5a42e8bf4693b20827d4d28a4c2e","value":"Downloading: 100%"}},"848e599fb9e24f9885de88896a2e81ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b32f32f34454d05854c315a99e0bad2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ff162962ec743eaab11146a1ab0a42e","placeholder":"​","style":"IPY_MODEL_7699ea43dc554d47b22a23ba9edaddd9","value":"Downloading: 100%"}},"90996a2e531544b393d5a7d2f71dd263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a622def7ec154d53ba2abb47ed121b3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df96f85350f42b4b6fd07834b066888","placeholder":"​","style":"IPY_MODEL_e78fc6999a0e451b9b821e0578706540","value":" 2.00/2.00 [00:00&lt;00:00, 153B/s]"}},"a6a1b9c4d7ca4f19bbf5dcd961ab6462":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a772e0e95cce48f8a03a5ac9f2de9e8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a96102b5a6224d08adc0f5dc0f800baf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad2637bb7fca4b1cb8525a152c07b99a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef70f9a76ab74eeb8d6700ed3f9b7e4d","placeholder":"​","style":"IPY_MODEL_c40417881a9a4969b0a40154726f80e4","value":" 409/409 [00:00&lt;00:00, 28.4kB/s]"}},"af5c39705db44dc9a1e70c00da9a0214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b72719882c61485990b424540684ce5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7b38673d41340fdba947a93dabfd462":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_791b866925dc44e4a5ce2bda758c3cc5","placeholder":"​","style":"IPY_MODEL_063f42fcf5be4c1cbf0c58735c5f6547","value":"Downloading: 100%"}},"be66c8351228415d8b5a506ae8d07136":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd1d905665b64be894a724acd5dfde0a","max":466081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90996a2e531544b393d5a7d2f71dd263","value":466081}},"be89ad3989ea4511b62d031a64895141":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e142f2288c7a44f99dd60da44730c8d5","placeholder":"​","style":"IPY_MODEL_52be9ecbb5fa4a5086a013b0fe063ebb","value":"Downloading: 100%"}},"c40417881a9a4969b0a40154726f80e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c62da119e31c4641954b56b25c79c772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7a825793e9445caba328cb4f9c18645":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16d7077da7474bbf8c77ee89ac497d73","placeholder":"​","style":"IPY_MODEL_0c9c9343f404423a9accefc76095897d","value":" 466k/466k [00:00&lt;00:00, 1.87MB/s]"}},"c92356df80674b08b26d95ef20847f93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce50e82623cf4f55a0102541c75d23ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be89ad3989ea4511b62d031a64895141","IPY_MODEL_be66c8351228415d8b5a506ae8d07136","IPY_MODEL_c7a825793e9445caba328cb4f9c18645"],"layout":"IPY_MODEL_596f7d3d232a407383b39de2b4eaa6d2"}},"db9c0a3196a248bcbbcf660504208943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_143da96a82e942d8bc71fd2ffcf3f932","IPY_MODEL_e1c5e52d61484539ad717f2f3c678edb","IPY_MODEL_a622def7ec154d53ba2abb47ed121b3a"],"layout":"IPY_MODEL_47d5fdc1e91c4cacb9eb18286c1eb9fd"}},"dd1d905665b64be894a724acd5dfde0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e142f2288c7a44f99dd60da44730c8d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1c5e52d61484539ad717f2f3c678edb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_848e599fb9e24f9885de88896a2e81ed","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2339ed21727143a4a9860943fd16f09a","value":2}},"e225c13f0cb74f52b577429bb8174975":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e78fc6999a0e451b9b821e0578706540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e95d12714fe340aa9bc9baf37b58e217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef70f9a76ab74eeb8d6700ed3f9b7e4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f65cc3c23dfa4e61b6e98448b11e185b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9416200cdd148f99d85db7a1f9a924e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3189d22c5c5d4456b4568774b3a805bd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a96102b5a6224d08adc0f5dc0f800baf","value":231508}},"f97a92256cb54c85a1add4270889f252":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}