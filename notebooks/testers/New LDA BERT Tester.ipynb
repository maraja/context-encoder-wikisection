{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b816077",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e50641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb492ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.insert(0, config.root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811f4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python import keras\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.encoders.context_encoder_ldabert_2 import ContextEncoder\n",
    "from src.dataset.ldabert_2 import LDABERT2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1810fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7808d62a",
   "metadata": {},
   "source": [
    "## LDA BERT 2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LDABERT2Dataset(dataset_type=\"clinical\",\n",
    "                       pct_data=0.001,\n",
    "                          max_seq_length=128,\n",
    "                       max_segment_length=5,\n",
    "                       augment_pct=0.001,\n",
    "                         split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5557f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tokenized_sentences, labels = dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e8c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing raw texts ...\n",
      "sentences length 10\n",
      "10.0 %\r",
      "20.0 %\r",
      "30.0 %\r",
      "40.0 %\r",
      "50.0 %\r",
      "60.0 %\r",
      "70.0 %\r",
      "80.0 %\r",
      "90.0 %\r",
      "100.0 %\r",
      "Preprocessing raw texts. Done!\n",
      "lda sentences length 10\n"
     ]
    }
   ],
   "source": [
    "lda_sentences, lda_token_lists, lda_new_labels = dataset.preprocess_lda(sentences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c5771",
   "metadata": {},
   "source": [
    "## Tri Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a2c1248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "context_encoder = ContextEncoder(final_dropout=0.5, dense_neurons=64, max_sentence_length=128, gamma=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = [['This is an example sentence', 'This is a new sentence', 'And this is a continuation'], \n",
    "#              ['This is a new sentence', 'And this is a continuation', 'And another continuation'], \n",
    "#              ['And this is a continuation', 'And another continuation', 'And yet another continuation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76644b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d893c81db81a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontext_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmid_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_left_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_mid_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_right_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\\src\\encoders\\context_encoder_ldabert_2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mbert_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mlda_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Compute token embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "context_encoder([[left_input, mid_input, right_input, lda_left_input, lda_mid_input, lda_right_input]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c52b0492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"context_encoder_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tf_bert_model_24 (TFBertMode multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dense_input_left (Dense)     multiple                  49856     \n",
      "_________________________________________________________________\n",
      "dense_input_mid (Dense)      multiple                  49856     \n",
      "_________________________________________________________________\n",
      "dense_input_right (Dense)    multiple                  49856     \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         multiple                  193       \n",
      "_________________________________________________________________\n",
      "final_dropout (Dropout)      multiple                  0         \n",
      "=================================================================\n",
      "Total params: 109,632,001\n",
      "Trainable params: 109,632,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "context_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd429a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c604490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66881c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b718000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cebf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b15556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef699155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b5bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6ef0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ba592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a13a07e6",
   "metadata": {},
   "source": [
    "## Generate Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5575373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing raw texts ...\n",
      "10259 10259\n",
      "Preprocessing raw texts. Done!\n",
      "something went wrong [Errno 2] No such file or directory: 'C:\\\\Users\\\\Computer\\\\Google Drive\\\\SCHOOL\\\\PhD\\\\Code\\\\context-encoder-v2\\\\data\\\\generated_vectors\\\\clinical_vectors\\\\lda_bert_clinical_1_0.5.pkl'\n",
      "root path C:\\Users\\Computer\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\n",
      "Getting vector representations for LDA ...\n",
      "Getting vector representations for LDA. Done!\n",
      "Getting vector representations for S_BERT ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d018a3997c4e29a12cad8c291efd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting vector representations for BERT. Done!\n",
      "[[ 1.5030304   0.6538147   1.2617971  ... -0.07280263  0.23336096\n",
      "   0.8262265 ]\n",
      " [ 1.1767309   0.5364523   1.2677495  ...  0.11217795  0.09784786\n",
      "  -0.03438686]\n",
      " [ 0.62225527  1.0551611   2.202089   ...  1.1347252   0.14224464\n",
      "   0.05253705]\n",
      " ...\n",
      " [ 0.84182185  0.9099033   1.3536335  ...  0.15851161 -0.2311791\n",
      "   0.06266249]\n",
      " [ 1.803962    1.047267    0.59083563 ...  0.8280431   0.17820705\n",
      "   1.4119322 ]\n",
      " [ 0.9566428   0.61323845  0.62884104 ...  0.358712    0.46842542\n",
      "   0.9512988 ]]\n",
      "(10093, 768)\n",
      "Fitting Autoencoder ...\n",
      "Fitting Autoencoder Done!\n",
      "Preprocessing raw texts ...\n",
      "10316 10316\n",
      "Preprocessing raw texts. Done!\n",
      "something went wrong [Errno 2] No such file or directory: 'C:\\\\Users\\\\Computer\\\\Google Drive\\\\SCHOOL\\\\PhD\\\\Code\\\\context-encoder-v2\\\\data\\\\generated_vectors\\\\wiki_vectors\\\\lda_bert_wiki_1_0.5.pkl'\n",
      "root path C:\\Users\\Computer\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\n",
      "Getting vector representations for LDA ...\n",
      "Getting vector representations for LDA. Done!\n",
      "Getting vector representations for S_BERT ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98694a4af834edba1f95baa4a6f9e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting vector representations for BERT. Done!\n",
      "[[ 0.8427308   2.1591754   0.699877   ...  0.8665418   1.1667999\n",
      "   0.4564934 ]\n",
      " [ 0.83219594  1.2316083   1.1702161  ...  0.49829528  0.6233119\n",
      "   0.06990469]\n",
      " [ 0.3945257   1.6743623   0.38195902 ...  0.46317536  1.0000203\n",
      "   0.16089   ]\n",
      " ...\n",
      " [ 0.76700145  1.1213465   0.20496714 ...  1.2895375   0.69258344\n",
      "   0.6362469 ]\n",
      " [ 0.92033386  0.65964675  0.28187832 ...  0.70216185  0.95357805\n",
      "   0.51770526]\n",
      " [ 0.36274368  0.16606128  1.0401337  ...  0.64025915  0.34550846\n",
      "  -0.128405  ]]\n",
      "(10055, 768)\n",
      "Fitting Autoencoder ...\n",
      "Fitting Autoencoder Done!\n",
      "Preprocessing raw texts ...\n",
      "15055 15055\n",
      "Preprocessing raw texts. Done!\n",
      "something went wrong [Errno 2] No such file or directory: 'C:\\\\Users\\\\Computer\\\\Google Drive\\\\SCHOOL\\\\PhD\\\\Code\\\\context-encoder-v2\\\\data\\\\generated_vectors\\\\fiction_vectors\\\\lda_bert_fiction_1_0.5.pkl'\n",
      "root path C:\\Users\\Computer\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\n",
      "Getting vector representations for LDA ...\n",
      "Getting vector representations for LDA. Done!\n",
      "Getting vector representations for S_BERT ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee17e15803c948c2a794fcf09762b9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting vector representations for BERT. Done!\n",
      "[[ 1.2645738   0.86432266  0.5193494  ... -0.02081079  0.5192658\n",
      "   0.43456942]\n",
      " [ 0.8827983   0.71797484  0.20867829 ...  1.2551633   0.83528435\n",
      "   0.05350147]\n",
      " [ 0.7183079   2.2732043   1.5674933  ...  0.41826937  1.3192451\n",
      "   0.8833546 ]\n",
      " ...\n",
      " [ 1.0824481   0.60173595  1.460718   ...  0.67573845  0.58170366\n",
      "   0.15544572]\n",
      " [ 0.739459    1.11267     1.5335777  ...  0.5901724   0.93928665\n",
      "   0.7587939 ]\n",
      " [ 0.97557276  1.5640703   1.6278915  ...  0.54493403  0.67613524\n",
      "   0.49542746]]\n",
      "(13651, 768)\n",
      "Fitting Autoencoder ...\n",
      "Fitting Autoencoder Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_types = [\"clinical\", \"wiki\", \"fiction\"]\n",
    "\n",
    "for d in dataset_types:\n",
    "    dataset = LDABERTDataset(dataset_type=d,\n",
    "                           pct_data=1,\n",
    "                           max_segment_length=5,\n",
    "                           augment_pct=0.5)\n",
    "    \n",
    "    sentences, tokenized_sentences, labels = dataset.process(preprocess=True)\n",
    "    \n",
    "    # vectors_path = '../data/clinical_vectors/lda_bert_{}_{}.pkl'.format(dataset_type, len(sentences))\n",
    "    vectors_path = '../../data/{}_vectors/lda_bert_{}_{}_{}.pkl'.format(d, d, \n",
    "                                                                        dataset.pct_data, \n",
    "                                                                        dataset.augment_pct)\n",
    "\n",
    "    saved_vectors, saved_tokens, saved_labels = dataset.get_vectors(vectors_path)\n",
    "\n",
    "    if len(saved_vectors) == 0:\n",
    "        saved_vectors, saved_tokens, saved_labels = dataset.create_vectors(vectors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f82d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LDABERTDataset(dataset_type=\"clinical\",\n",
    "                       pct_data=1,\n",
    "                       max_segment_length=5,\n",
    "                       augment_pct=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e7aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tokenized_sentences, labels = dataset.process(preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25364d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb35b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a203d1",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e627399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Computer\\\\Google Drive\\\\SCHOOL\\\\PhD\\\\Code\\\\context-encoder-v2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b31d578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors_path = '../data/clinical_vectors/lda_bert_{}_{}.pkl'.format(dataset_type, len(sentences))\n",
    "vectors_path = '../../data/lda_bert_2/{}/{}_{}.pkl'.format(dataset.dataset_type, \n",
    "                                                        dataset.pct_data, \n",
    "                                                        dataset.augment_pct)\n",
    "\n",
    "saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.get_saved_vectors(vectors_path)\n",
    "\n",
    "if len(saved_vectors) == 0:\n",
    "    saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.create_vectors(vectors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "616fbbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input, mid_input, right_input = dataset.format_sentences_tri_input_plus(saved_tokenized_sentences)\n",
    "lda_left_input, lda_mid_input, lda_right_input = dataset.format_sentences_tri_input(saved_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b855c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(6, 87), dtype=int32, numpy=\n",
       " array([[  101,  2065,  1037,  2711,  1005,  1055,  2310, 18674,  2668,\n",
       "          4834,  2003,  6022,  2896,  2084,  2030,  5020,  2000,  2216,\n",
       "          1997,  1037,  2711,  1005,  1055,  3671,  5505,  3446,  1010,\n",
       "          2027,  2071,  2022,  4039,  2000,  2079,  2172,  2000,  7200,\n",
       "          1998,  2947,  2097,  2025,  4503,  2151,  3255,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2019, 17577,  2015,  2089,  2022,  6219,  2241,  2006,\n",
       "          2037,  3802, 20569,  1041,  1043, 19610,  4747, 21252, 19610,\n",
       "          2953, 25032, 22974,  2278,  4385,  9413, 22123,  8093,  7361,\n",
       "         10448, 16530,  3433,  1041,  1043,  1044, 22571,  7361, 13153,\n",
       "         23780,  8082, 20694,  2030,  3526, 19476,  1041,  1043, 26632,\n",
       "          5666,  4588, 12702,  5666,  4588,  1044, 22571, 11663, 21716,\n",
       "          2594, 23760, 25643, 19357,  2140,  1051,  7361, 16892,  6593,\n",
       "         16940,  1044, 22571, 11636,  2594,  1051, 28788,  1041,  1043,\n",
       "         23760, 15000,  4747, 21252,  2002, 24952,  2278, 23760, 11636,\n",
       "          8524,  6024,  2002, 24952,  2278,   102],\n",
       "        [  101,  9312,  1997,  1996, 26536,  7934,  2310, 18674,  8187,\n",
       "          2003,  3383,  2028,  1997,  1996,  2087, 28947,  1998,  3697,\n",
       "          2000,  3040,  3558, 11616,  5461,  1998,  2001,  2034,  2109,\n",
       "          1999,  1996,  2220,  3983,  2301,  1999,  1996,  2142,  2163,\n",
       "          2011,  2028,  1997,  1996,  2149,  2390,  1005,  1055,  2327,\n",
       "          2310,  3678, 15879, 19684,  2015,  1012,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1996, 26536,  7934,  2310, 18674,  8187,  2003,  1037,\n",
       "          3696,  1997,  1037,  2711,  1005,  1055,  3754,  2000,  2693,\n",
       "          2830,  1998,  2830,  1010,  2096,  2145,  8498,  2037,  3052,\n",
       "          2306,  1037,  2445,  2181,  1998,  9992,  3778,  2006,  2037,\n",
       "          8948,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1996, 26536,  7934,  2310, 18674,  8187,  2003,  1037,\n",
       "          3696,  1997,  1996,  2711,  1005,  1055,  3754,  2000,  7200,\n",
       "          2153,  2044,  1996,  2051, 10876,  2063,  1997,  2037,  2219,\n",
       "          2895,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2023,  2003,  2138,  2009,  3431,  1996,  5505,  3446,\n",
       "          1997,  1037,  2711,  1998,  2064,  7461,  2668,  4834,  1010,\n",
       "         22935,  3853,  1010,  1998,  1996,  3754,  2000,  2693,  2830,\n",
       "          1998,  2830,  1999,  2023,  2051, 13483,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]])>,\n",
       " 'token_type_ids': <tf.Tensor: shape=(6, 87), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(6, 87), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd5721",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d68092d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextEncoder(final_dropout=0.8,\n",
    "                               dense_neurons=256,\n",
    "                             lstm_size=256,\n",
    "                             lstm_dropout_percentage=0.75,\n",
    "                             cnn_filters=8,\n",
    "                             cnn_kernel_size=3,\n",
    "                             pool_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ef40dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2]]\n",
      "\n",
      " [[3 4]]\n",
      "\n",
      " [[5 6]]], shape=(3, 1, 2), dtype=int32)\n",
      "tf.Tensor([[1 2]], shape=(1, 2), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "in user code:\n\n    C:\\Users\\Computer\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\\src\\encoders\\context_encoder.py:58 None  *\n        lambda t: tf.reshape(t, [rows, cols]), elems=input_tensor)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8372 reshape\n        tensor, shape, name=name, ctx=_ctx)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8397 reshape_eager_fallback\n        ctx=ctx, name=name)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60 quick_execute\n        inputs, attrs, num_outputs)\n\n    InvalidArgumentError: Input to reshape is a tensor with 2 values, but the requested shape has 0 [Op:Reshape]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2bbb74fb9c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfake_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\\src\\encoders\\context_encoder_ldabert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mstacked_left_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mstacked_mid_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mstacked_right_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\\src\\encoders\\context_encoder.py\u001b[0m in \u001b[0;36mstack_input\u001b[1;34m(input_tensor, cols, rows)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \"\"\"\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# assert (len(input_tensor)/cols) == rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 605\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                 instructions)\n\u001b[1;32m--> 538\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\u001b[0m in \u001b[0;36mmap_fn_v2\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       \u001b[0minfer_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       name=name)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                 instructions)\n\u001b[1;32m--> 538\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m         maximum_iterations=n)\n\u001b[0m\u001b[0;32m    516\u001b[0m     \u001b[0mresult_batchable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2734\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2735\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2724\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2725\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2726\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(i, tas)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[0mag_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m       \u001b[0mautographed_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m       \u001b[0mresult_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautographed_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melems_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m       \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_output_signature\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[0mresult_value_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: in user code:\n\n    C:\\Users\\Computer\\Google Drive\\SCHOOL\\PhD\\Code\\context-encoder-v2\\src\\encoders\\context_encoder.py:58 None  *\n        lambda t: tf.reshape(t, [rows, cols]), elems=input_tensor)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8372 reshape\n        tensor, shape, name=name, ctx=_ctx)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8397 reshape_eager_fallback\n        ctx=ctx, name=name)\n    C:\\Users\\Computer\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60 quick_execute\n        inputs, attrs, num_outputs)\n\n    InvalidArgumentError: Input to reshape is a tensor with 2 values, but the requested shape has 0 [Op:Reshape]\n"
     ]
    }
   ],
   "source": [
    "fake_output = model(tf.constant([[[1,2]],[[3,4]],[[5,6]]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc04c7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.67855525]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5f55d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"context_encoder_complex\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bi-directional_left (Bidirec multiple                  140288    \n",
      "_________________________________________________________________\n",
      "bi-directional_mid (Bidirect multiple                  140288    \n",
      "_________________________________________________________________\n",
      "bi-directional_right (Bidire multiple                  140288    \n",
      "_________________________________________________________________\n",
      "left_context (Attention)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "mid_sentence (Attention)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "right_context (Attention)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1D_left (Conv1D)         multiple                  776       \n",
      "_________________________________________________________________\n",
      "conv1D_mid (Conv1D)          multiple                  776       \n",
      "_________________________________________________________________\n",
      "conv1D_right (Conv1D)        multiple                  776       \n",
      "_________________________________________________________________\n",
      "maxpooling1D_left (MaxPoolin multiple                  0         \n",
      "_________________________________________________________________\n",
      "maxpooling1D_mid (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "maxpooling1D_right (MaxPooli multiple                  0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You tried to call `count_params` on dense_input_left, but the layer isn't built. You can build it manually via: `dense_input_left.build(batch_input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2382\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2383\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2384\u001b[1;33m                               print_fn=print_fn)\n\u001b[0m\u001b[0;32m   2385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[1;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m    250\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m       \u001b[0mprint_layer_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[1;34m(layer)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' ('\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m')'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2206\u001b[0m                          \u001b[1;34m', but the layer isn\\'t built. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m                          \u001b[1;34m'You can build it manually via: `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2208\u001b[1;33m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[0;32m   2209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You tried to call `count_params` on dense_input_left, but the layer isn't built. You can build it manually via: `dense_input_left.build(batch_input_shape)`."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14939ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91574f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "021f90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# balanced = balanced binary crossentropy\n",
    "checkpoint_filepath = '../models/LDABERT/complex/{}-{}-{}-pct-{}-aug/checkpoint.ckpt'.format(\n",
    "                        dataset.dataset_type,                    \n",
    "                        len(sentences), \n",
    "                        dataset.pct_data,\n",
    "                        dataset.augment_pct)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "callbacks = [\n",
    "#     early_stopping,\n",
    "    model_checkpoint_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0d0170c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/LDABERT/complex/clinical-16122-1-pct-1-aug/checkpoint.ckpt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d5e4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fb95835",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "except:\n",
    "    print(\"No checkpoint available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7aedf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8526 - val_loss: 0.2992 - val_accuracy: 0.8714\n",
      "Epoch 2/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8520 - val_loss: 0.3009 - val_accuracy: 0.8739\n",
      "Epoch 3/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8545 - val_loss: 0.2997 - val_accuracy: 0.8726\n",
      "Epoch 4/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8507 - val_loss: 0.3055 - val_accuracy: 0.8752\n",
      "Epoch 5/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8508 - val_loss: 0.2999 - val_accuracy: 0.8689\n",
      "Epoch 6/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8527 - val_loss: 0.3038 - val_accuracy: 0.8663\n",
      "Epoch 7/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8514 - val_loss: 0.2996 - val_accuracy: 0.8739\n",
      "Epoch 8/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8526 - val_loss: 0.2986 - val_accuracy: 0.8689\n",
      "Epoch 9/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8545 - val_loss: 0.2997 - val_accuracy: 0.8670\n",
      "Epoch 10/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8566 - val_loss: 0.3003 - val_accuracy: 0.8720\n",
      "Epoch 11/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8543 - val_loss: 0.3038 - val_accuracy: 0.8714\n",
      "Epoch 12/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8548 - val_loss: 0.2991 - val_accuracy: 0.8720\n",
      "Epoch 13/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8531 - val_loss: 0.2978 - val_accuracy: 0.8682\n",
      "Epoch 14/300\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.3349 - accuracy: 0.8539 - val_loss: 0.2976 - val_accuracy: 0.8689\n",
      "Epoch 15/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8513 - val_loss: 0.3022 - val_accuracy: 0.8758\n",
      "Epoch 16/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8560 - val_loss: 0.2987 - val_accuracy: 0.8720\n",
      "Epoch 17/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8540 - val_loss: 0.2986 - val_accuracy: 0.8707\n",
      "Epoch 18/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8533 - val_loss: 0.2979 - val_accuracy: 0.8689\n",
      "Epoch 19/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8555 - val_loss: 0.2991 - val_accuracy: 0.8701\n",
      "Epoch 20/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8552 - val_loss: 0.2989 - val_accuracy: 0.8739\n",
      "Epoch 21/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8552 - val_loss: 0.2988 - val_accuracy: 0.8726\n",
      "Epoch 22/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8561 - val_loss: 0.2957 - val_accuracy: 0.8701\n",
      "Epoch 23/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8545 - val_loss: 0.2974 - val_accuracy: 0.8720\n",
      "Epoch 24/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8552 - val_loss: 0.2974 - val_accuracy: 0.8682\n",
      "Epoch 25/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8559 - val_loss: 0.3005 - val_accuracy: 0.8726\n",
      "Epoch 26/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8568 - val_loss: 0.2992 - val_accuracy: 0.8764\n",
      "Epoch 27/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8560 - val_loss: 0.2977 - val_accuracy: 0.8707\n",
      "Epoch 28/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8592 - val_loss: 0.3000 - val_accuracy: 0.8714\n",
      "Epoch 29/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8562 - val_loss: 0.3121 - val_accuracy: 0.8670\n",
      "Epoch 30/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8553 - val_loss: 0.2987 - val_accuracy: 0.8720\n",
      "Epoch 31/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8553 - val_loss: 0.2966 - val_accuracy: 0.8720\n",
      "Epoch 32/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8558 - val_loss: 0.3095 - val_accuracy: 0.8695\n",
      "Epoch 33/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8556 - val_loss: 0.2949 - val_accuracy: 0.8739\n",
      "Epoch 34/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8553 - val_loss: 0.2974 - val_accuracy: 0.8726\n",
      "Epoch 35/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8547 - val_loss: 0.2974 - val_accuracy: 0.8726\n",
      "Epoch 36/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8552 - val_loss: 0.2985 - val_accuracy: 0.8733\n",
      "Epoch 37/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8566 - val_loss: 0.2973 - val_accuracy: 0.8752\n",
      "Epoch 38/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8557 - val_loss: 0.2948 - val_accuracy: 0.8726\n",
      "Epoch 39/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8588 - val_loss: 0.2977 - val_accuracy: 0.8707\n",
      "Epoch 40/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8591 - val_loss: 0.2949 - val_accuracy: 0.8726\n",
      "Epoch 41/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8555 - val_loss: 0.3031 - val_accuracy: 0.8733\n",
      "Epoch 42/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8548 - val_loss: 0.2947 - val_accuracy: 0.8695\n",
      "Epoch 43/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8558 - val_loss: 0.2945 - val_accuracy: 0.8726\n",
      "Epoch 44/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8578 - val_loss: 0.2943 - val_accuracy: 0.8720\n",
      "Epoch 45/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8562 - val_loss: 0.2960 - val_accuracy: 0.8764\n",
      "Epoch 46/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8561 - val_loss: 0.2944 - val_accuracy: 0.8707\n",
      "Epoch 47/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8573 - val_loss: 0.2992 - val_accuracy: 0.8657\n",
      "Epoch 48/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8559 - val_loss: 0.2967 - val_accuracy: 0.8701\n",
      "Epoch 49/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8556 - val_loss: 0.2939 - val_accuracy: 0.8707\n",
      "Epoch 50/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8617 - val_loss: 0.3001 - val_accuracy: 0.8745\n",
      "Epoch 51/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8611 - val_loss: 0.2935 - val_accuracy: 0.8752\n",
      "Epoch 52/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8534 - val_loss: 0.2984 - val_accuracy: 0.8676\n",
      "Epoch 53/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8580 - val_loss: 0.2976 - val_accuracy: 0.8764\n",
      "Epoch 54/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8582 - val_loss: 0.2935 - val_accuracy: 0.8726\n",
      "Epoch 55/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8578 - val_loss: 0.2943 - val_accuracy: 0.8745\n",
      "Epoch 56/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8583 - val_loss: 0.2938 - val_accuracy: 0.8714\n",
      "Epoch 57/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8571 - val_loss: 0.2971 - val_accuracy: 0.8714\n",
      "Epoch 58/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8631 - val_loss: 0.2933 - val_accuracy: 0.8739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8599 - val_loss: 0.2919 - val_accuracy: 0.8701\n",
      "Epoch 60/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8580 - val_loss: 0.2940 - val_accuracy: 0.8739\n",
      "Epoch 61/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8574 - val_loss: 0.3038 - val_accuracy: 0.8638\n",
      "Epoch 62/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8545 - val_loss: 0.2933 - val_accuracy: 0.8689\n",
      "Epoch 63/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8572 - val_loss: 0.2938 - val_accuracy: 0.8739\n",
      "Epoch 64/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8571 - val_loss: 0.2958 - val_accuracy: 0.8745\n",
      "Epoch 65/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8576 - val_loss: 0.3050 - val_accuracy: 0.8707\n",
      "Epoch 66/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8580 - val_loss: 0.2926 - val_accuracy: 0.8733\n",
      "Epoch 67/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8658 - val_loss: 0.2952 - val_accuracy: 0.8720\n",
      "Epoch 68/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8568 - val_loss: 0.2934 - val_accuracy: 0.8695\n",
      "Epoch 69/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8628 - val_loss: 0.2920 - val_accuracy: 0.8720\n",
      "Epoch 70/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8604 - val_loss: 0.2929 - val_accuracy: 0.8733\n",
      "Epoch 71/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8578 - val_loss: 0.3057 - val_accuracy: 0.8745\n",
      "Epoch 72/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8612 - val_loss: 0.2932 - val_accuracy: 0.8752\n",
      "Epoch 73/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8622 - val_loss: 0.2914 - val_accuracy: 0.8726\n",
      "Epoch 74/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8592 - val_loss: 0.2909 - val_accuracy: 0.8695\n",
      "Epoch 75/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8571 - val_loss: 0.2947 - val_accuracy: 0.8770\n",
      "Epoch 76/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8605 - val_loss: 0.2934 - val_accuracy: 0.8707\n",
      "Epoch 77/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8569 - val_loss: 0.2971 - val_accuracy: 0.8682\n",
      "Epoch 78/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8639 - val_loss: 0.2927 - val_accuracy: 0.8720\n",
      "Epoch 79/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8619 - val_loss: 0.2933 - val_accuracy: 0.8726\n",
      "Epoch 80/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8595 - val_loss: 0.2970 - val_accuracy: 0.8752\n",
      "Epoch 81/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8601 - val_loss: 0.2965 - val_accuracy: 0.8689\n",
      "Epoch 82/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8576 - val_loss: 0.2929 - val_accuracy: 0.8739\n",
      "Epoch 83/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8568 - val_loss: 0.2948 - val_accuracy: 0.8752\n",
      "Epoch 84/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8577 - val_loss: 0.2938 - val_accuracy: 0.8752\n",
      "Epoch 85/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8620 - val_loss: 0.3041 - val_accuracy: 0.8726\n",
      "Epoch 86/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8580 - val_loss: 0.2922 - val_accuracy: 0.8733\n",
      "Epoch 87/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8622 - val_loss: 0.2934 - val_accuracy: 0.8752\n",
      "Epoch 88/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8645 - val_loss: 0.2891 - val_accuracy: 0.8770\n",
      "Epoch 89/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8582 - val_loss: 0.2900 - val_accuracy: 0.8758\n",
      "Epoch 90/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8606 - val_loss: 0.2909 - val_accuracy: 0.8745\n",
      "Epoch 91/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8642 - val_loss: 0.2904 - val_accuracy: 0.8733\n",
      "Epoch 92/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8592 - val_loss: 0.2976 - val_accuracy: 0.8745\n",
      "Epoch 93/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8587 - val_loss: 0.2910 - val_accuracy: 0.8758\n",
      "Epoch 94/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8605 - val_loss: 0.2915 - val_accuracy: 0.8752\n",
      "Epoch 95/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8605 - val_loss: 0.2897 - val_accuracy: 0.8739\n",
      "Epoch 96/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.8618 - val_loss: 0.3046 - val_accuracy: 0.8575\n",
      "Epoch 97/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8590 - val_loss: 0.2922 - val_accuracy: 0.8720\n",
      "Epoch 98/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8625 - val_loss: 0.2889 - val_accuracy: 0.8726\n",
      "Epoch 99/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8637 - val_loss: 0.2996 - val_accuracy: 0.8739\n",
      "Epoch 100/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.8627 - val_loss: 0.2948 - val_accuracy: 0.8739\n",
      "Epoch 101/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8610 - val_loss: 0.2885 - val_accuracy: 0.8758\n",
      "Epoch 102/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8625 - val_loss: 0.2902 - val_accuracy: 0.8758\n",
      "Epoch 103/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8651 - val_loss: 0.2957 - val_accuracy: 0.8764\n",
      "Epoch 104/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8586 - val_loss: 0.2888 - val_accuracy: 0.8739\n",
      "Epoch 105/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8636 - val_loss: 0.3017 - val_accuracy: 0.8745\n",
      "Epoch 106/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8618 - val_loss: 0.2925 - val_accuracy: 0.8745\n",
      "Epoch 107/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8620 - val_loss: 0.2945 - val_accuracy: 0.8783\n",
      "Epoch 108/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8647 - val_loss: 0.2936 - val_accuracy: 0.8770\n",
      "Epoch 109/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8601 - val_loss: 0.2922 - val_accuracy: 0.8739\n",
      "Epoch 110/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8623 - val_loss: 0.2889 - val_accuracy: 0.8745\n",
      "Epoch 111/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8634 - val_loss: 0.2882 - val_accuracy: 0.8739\n",
      "Epoch 112/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8648 - val_loss: 0.2896 - val_accuracy: 0.8720\n",
      "Epoch 113/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8660 - val_loss: 0.2980 - val_accuracy: 0.8733\n",
      "Epoch 114/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8606 - val_loss: 0.2903 - val_accuracy: 0.8714\n",
      "Epoch 115/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8626 - val_loss: 0.2901 - val_accuracy: 0.8739\n",
      "Epoch 116/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8620 - val_loss: 0.2909 - val_accuracy: 0.8764\n",
      "Epoch 117/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8608 - val_loss: 0.2963 - val_accuracy: 0.8758\n",
      "Epoch 118/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8612 - val_loss: 0.2938 - val_accuracy: 0.8676\n",
      "Epoch 119/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8645 - val_loss: 0.2970 - val_accuracy: 0.8758\n",
      "Epoch 120/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8648 - val_loss: 0.2909 - val_accuracy: 0.8739\n",
      "Epoch 121/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8632 - val_loss: 0.2945 - val_accuracy: 0.8752\n",
      "Epoch 122/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8664 - val_loss: 0.2879 - val_accuracy: 0.8745\n",
      "Epoch 123/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8627 - val_loss: 0.2882 - val_accuracy: 0.8758\n",
      "Epoch 124/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8651 - val_loss: 0.2906 - val_accuracy: 0.8720\n",
      "Epoch 125/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8620 - val_loss: 0.3002 - val_accuracy: 0.8733\n",
      "Epoch 126/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8613 - val_loss: 0.2882 - val_accuracy: 0.8745\n",
      "Epoch 127/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8653 - val_loss: 0.2980 - val_accuracy: 0.8745\n",
      "Epoch 128/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8637 - val_loss: 0.2889 - val_accuracy: 0.8752\n",
      "Epoch 129/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8672 - val_loss: 0.2899 - val_accuracy: 0.8758\n",
      "Epoch 130/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8661 - val_loss: 0.2882 - val_accuracy: 0.8739\n",
      "Epoch 131/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8642 - val_loss: 0.2905 - val_accuracy: 0.8752\n",
      "Epoch 132/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8643 - val_loss: 0.2989 - val_accuracy: 0.8770\n",
      "Epoch 133/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8607 - val_loss: 0.2868 - val_accuracy: 0.8764\n",
      "Epoch 134/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8647 - val_loss: 0.2871 - val_accuracy: 0.8752\n",
      "Epoch 135/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8660 - val_loss: 0.2872 - val_accuracy: 0.8764\n",
      "Epoch 136/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8632 - val_loss: 0.2885 - val_accuracy: 0.8745\n",
      "Epoch 137/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8658 - val_loss: 0.2884 - val_accuracy: 0.8745\n",
      "Epoch 138/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8644 - val_loss: 0.2875 - val_accuracy: 0.8752\n",
      "Epoch 139/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8670 - val_loss: 0.2861 - val_accuracy: 0.8777\n",
      "Epoch 140/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8648 - val_loss: 0.2874 - val_accuracy: 0.8789\n",
      "Epoch 141/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8618 - val_loss: 0.2885 - val_accuracy: 0.8758\n",
      "Epoch 142/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8662 - val_loss: 0.2991 - val_accuracy: 0.8764\n",
      "Epoch 143/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8637 - val_loss: 0.2876 - val_accuracy: 0.8752\n",
      "Epoch 144/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8648 - val_loss: 0.2880 - val_accuracy: 0.8770\n",
      "Epoch 145/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8694 - val_loss: 0.2867 - val_accuracy: 0.8745\n",
      "Epoch 146/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8690 - val_loss: 0.2893 - val_accuracy: 0.8739\n",
      "Epoch 147/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8660 - val_loss: 0.2912 - val_accuracy: 0.8777\n",
      "Epoch 148/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8695 - val_loss: 0.2864 - val_accuracy: 0.8752\n",
      "Epoch 149/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8683 - val_loss: 0.2882 - val_accuracy: 0.8752\n",
      "Epoch 150/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8647 - val_loss: 0.2857 - val_accuracy: 0.8783\n",
      "Epoch 151/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8618 - val_loss: 0.2862 - val_accuracy: 0.8764\n",
      "Epoch 152/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8673 - val_loss: 0.3053 - val_accuracy: 0.8745\n",
      "Epoch 153/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8658 - val_loss: 0.2864 - val_accuracy: 0.8752\n",
      "Epoch 154/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8648 - val_loss: 0.2864 - val_accuracy: 0.8777\n",
      "Epoch 155/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8672 - val_loss: 0.2872 - val_accuracy: 0.8777\n",
      "Epoch 156/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8655 - val_loss: 0.2878 - val_accuracy: 0.8752\n",
      "Epoch 157/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8662 - val_loss: 0.2964 - val_accuracy: 0.8745\n",
      "Epoch 158/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8655 - val_loss: 0.2868 - val_accuracy: 0.8752\n",
      "Epoch 159/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8638 - val_loss: 0.2845 - val_accuracy: 0.8783\n",
      "Epoch 160/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8653 - val_loss: 0.2995 - val_accuracy: 0.8726\n",
      "Epoch 161/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 0.2892 - val_accuracy: 0.8752\n",
      "Epoch 162/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.8642 - val_loss: 0.2858 - val_accuracy: 0.8764\n",
      "Epoch 163/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8653 - val_loss: 0.2861 - val_accuracy: 0.8752\n",
      "Epoch 164/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8679 - val_loss: 0.2872 - val_accuracy: 0.8770\n",
      "Epoch 165/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8642 - val_loss: 0.2883 - val_accuracy: 0.8783\n",
      "Epoch 166/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8663 - val_loss: 0.2843 - val_accuracy: 0.8758\n",
      "Epoch 167/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8685 - val_loss: 0.2896 - val_accuracy: 0.8783\n",
      "Epoch 168/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8676 - val_loss: 0.2858 - val_accuracy: 0.8752\n",
      "Epoch 169/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8705 - val_loss: 0.2858 - val_accuracy: 0.8758\n",
      "Epoch 170/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8687 - val_loss: 0.2895 - val_accuracy: 0.8758\n",
      "Epoch 171/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8688 - val_loss: 0.2878 - val_accuracy: 0.8752\n",
      "Epoch 172/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8686 - val_loss: 0.2911 - val_accuracy: 0.8752\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8668 - val_loss: 0.2868 - val_accuracy: 0.8758\n",
      "Epoch 174/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8686 - val_loss: 0.2877 - val_accuracy: 0.8770\n",
      "Epoch 175/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8708 - val_loss: 0.2901 - val_accuracy: 0.8777\n",
      "Epoch 176/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8689 - val_loss: 0.2838 - val_accuracy: 0.8764\n",
      "Epoch 177/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.2830 - val_accuracy: 0.8745\n",
      "Epoch 178/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8676 - val_loss: 0.2979 - val_accuracy: 0.8783\n",
      "Epoch 179/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8709 - val_loss: 0.2921 - val_accuracy: 0.8764\n",
      "Epoch 180/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8676 - val_loss: 0.2830 - val_accuracy: 0.8764\n",
      "Epoch 181/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8691 - val_loss: 0.2854 - val_accuracy: 0.8770\n",
      "Epoch 182/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8719 - val_loss: 0.2828 - val_accuracy: 0.8777\n",
      "Epoch 183/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.8672 - val_loss: 0.2821 - val_accuracy: 0.8783\n",
      "Epoch 184/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8716 - val_loss: 0.2852 - val_accuracy: 0.8764\n",
      "Epoch 185/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8719 - val_loss: 0.2937 - val_accuracy: 0.8770\n",
      "Epoch 186/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8702 - val_loss: 0.2905 - val_accuracy: 0.8758\n",
      "Epoch 187/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8707 - val_loss: 0.2858 - val_accuracy: 0.8783\n",
      "Epoch 188/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8667 - val_loss: 0.2825 - val_accuracy: 0.8764\n",
      "Epoch 189/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8665 - val_loss: 0.2917 - val_accuracy: 0.8770\n",
      "Epoch 190/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8695 - val_loss: 0.2822 - val_accuracy: 0.8770\n",
      "Epoch 191/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8714 - val_loss: 0.2842 - val_accuracy: 0.8777\n",
      "Epoch 192/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8690 - val_loss: 0.2822 - val_accuracy: 0.8789\n",
      "Epoch 193/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8704 - val_loss: 0.2843 - val_accuracy: 0.8739\n",
      "Epoch 194/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8644 - val_loss: 0.2827 - val_accuracy: 0.8739\n",
      "Epoch 195/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8679 - val_loss: 0.2820 - val_accuracy: 0.8764\n",
      "Epoch 196/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8739 - val_loss: 0.2850 - val_accuracy: 0.8739\n",
      "Epoch 197/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8705 - val_loss: 0.2845 - val_accuracy: 0.8783\n",
      "Epoch 198/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8716 - val_loss: 0.2828 - val_accuracy: 0.8770\n",
      "Epoch 199/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8710 - val_loss: 0.2823 - val_accuracy: 0.8739\n",
      "Epoch 200/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8686 - val_loss: 0.2867 - val_accuracy: 0.8777\n",
      "Epoch 201/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8742 - val_loss: 0.2809 - val_accuracy: 0.8764\n",
      "Epoch 202/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8728 - val_loss: 0.2848 - val_accuracy: 0.8789\n",
      "Epoch 203/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8660 - val_loss: 0.2839 - val_accuracy: 0.8783\n",
      "Epoch 204/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8679 - val_loss: 0.2863 - val_accuracy: 0.8770\n",
      "Epoch 205/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8733 - val_loss: 0.2821 - val_accuracy: 0.8752\n",
      "Epoch 206/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8697 - val_loss: 0.2812 - val_accuracy: 0.8733\n",
      "Epoch 207/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8687 - val_loss: 0.3116 - val_accuracy: 0.8720\n",
      "Epoch 208/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8721 - val_loss: 0.2824 - val_accuracy: 0.8815\n",
      "Epoch 209/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8717 - val_loss: 0.2860 - val_accuracy: 0.8758\n",
      "Epoch 210/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8723 - val_loss: 0.2823 - val_accuracy: 0.8770\n",
      "Epoch 211/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8705 - val_loss: 0.2816 - val_accuracy: 0.8796\n",
      "Epoch 212/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8698 - val_loss: 0.2816 - val_accuracy: 0.8789\n",
      "Epoch 213/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8718 - val_loss: 0.2819 - val_accuracy: 0.8770\n",
      "Epoch 214/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8716 - val_loss: 0.2805 - val_accuracy: 0.8770\n",
      "Epoch 215/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8737 - val_loss: 0.2914 - val_accuracy: 0.8758\n",
      "Epoch 216/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8724 - val_loss: 0.2818 - val_accuracy: 0.8777\n",
      "Epoch 217/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8694 - val_loss: 0.2844 - val_accuracy: 0.8783\n",
      "Epoch 218/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8765 - val_loss: 0.2827 - val_accuracy: 0.8770\n",
      "Epoch 219/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8768 - val_loss: 0.2806 - val_accuracy: 0.8764\n",
      "Epoch 220/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8743 - val_loss: 0.2892 - val_accuracy: 0.8783\n",
      "Epoch 221/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8723 - val_loss: 0.2772 - val_accuracy: 0.8827\n",
      "Epoch 222/300\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.8733 - val_loss: 0.2800 - val_accuracy: 0.8789\n",
      "Epoch 223/300\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8709 - val_loss: 0.2832 - val_accuracy: 0.8745\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: ../models/LDABERT/complex/clinical-16122-1-pct-1-aug\\checkpoint.tmpd9a0d0c56e0e4831bd0e9c7ea405e7cd to: ../models/LDABERT/complex/clinical-16122-1-pct-1-aug\\checkpoint : Access is denied.\r\n; Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-d21be0994ccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#                     class_weight=class_weight,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1404\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             self.model.save_weights(\n\u001b[1;32m-> 1406\u001b[1;33m                 filepath, overwrite=True, options=self._options)\n\u001b[0m\u001b[0;32m   1407\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2128\u001b[0m           \u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m           \u001b[0msave_relative_paths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2130\u001b[1;33m           all_model_checkpoint_paths=[filepath])\n\u001b[0m\u001b[0;32m   2131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m   def load_weights(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36mupdate_checkpoint_state_internal\u001b[1;34m(save_dir, model_checkpoint_path, all_model_checkpoint_paths, latest_filename, save_relative_paths, all_model_checkpoint_timestamps, last_preserved_timestamp)\u001b[0m\n\u001b[0;32m    246\u001b[0m   \u001b[1;31m# file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m   file_io.atomic_write_string_to_file(coord_checkpoint_filename,\n\u001b[1;32m--> 248\u001b[1;33m                                       text_format.MessageToString(ckpt))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[0mwrite_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m       \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m       \u001b[0mdelete_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(oldname, newname, overwrite)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \"\"\"\n\u001b[1;32m--> 532\u001b[1;33m   \u001b[0mrename_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moldname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\phd\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[1;34m(src, dst, overwrite)\u001b[0m\n\u001b[0;32m    547\u001b[0m   \"\"\"\n\u001b[0;32m    548\u001b[0m   _pywrap_file_io.RenameFile(\n\u001b[1;32m--> 549\u001b[1;33m       compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: ../models/LDABERT/complex/clinical-16122-1-pct-1-aug\\checkpoint.tmpd9a0d0c56e0e4831bd0e9c7ea405e7cd to: ../models/LDABERT/complex/clinical-16122-1-pct-1-aug\\checkpoint : Access is denied.\r\n; Input/output error"
     ]
    }
   ],
   "source": [
    "history = model.fit([left_input, mid_input, right_input], \n",
    "                    tf.convert_to_tensor(saved_labels), \n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose=1, \n",
    "#                     class_weight=class_weight,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b480d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6ade9c3",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a47d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.experiments import get_experiments_json, get_experiments, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b684a829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_type</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>final_dropout</th>\n",
       "      <th>dense_neurons</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>augment_pct</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ldabert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bert_type dataset_type  final_dropout  dense_neurons  pct_data  \\\n",
       "0    ldabert     clinical            0.5             64         1   \n",
       "1    ldabert     clinical            0.5             64         1   \n",
       "2    ldabert     clinical            0.5            256         1   \n",
       "3    ldabert     clinical            0.5            256         1   \n",
       "4    ldabert         wiki            0.5             64         1   \n",
       "5    ldabert         wiki            0.5             64         1   \n",
       "6    ldabert         wiki            0.5            256         1   \n",
       "7    ldabert         wiki            0.5            256         1   \n",
       "8    ldabert      fiction            0.5             64         1   \n",
       "9    ldabert      fiction            0.5             64         1   \n",
       "10   ldabert      fiction            0.5            256         1   \n",
       "11   ldabert      fiction            0.5            256         1   \n",
       "\n",
       "    augment_pct  epochs  \n",
       "0           0.5    1000  \n",
       "1           1.0    1000  \n",
       "2           0.5    1000  \n",
       "3           1.0    1000  \n",
       "4           0.5    1000  \n",
       "5           1.0    1000  \n",
       "6           0.5    1000  \n",
       "7           1.0    1000  \n",
       "8           0.5    1000  \n",
       "9           1.0    1000  \n",
       "10          0.5    1000  \n",
       "11          1.0    1000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_config = get_experiments_json('ldabert_simple_test')\n",
    "epxeriments_config_df = pd.DataFrame.from_dict(experiments_config)\n",
    "epxeriments_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0f1e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_type</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>finetune_bert</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>augment_pct</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert</td>\n",
       "      <td>clinical</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>albert</td>\n",
       "      <td>fiction</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>albert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>albert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>albert</td>\n",
       "      <td>wiki</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bert_type dataset_type  finetune_bert  pct_data  augment_pct  epochs\n",
       "0    albert     clinical           True         1          0.1     200\n",
       "1    albert     clinical           True         1          0.5     200\n",
       "2    albert     clinical           True         1          1.0     200\n",
       "3    albert      fiction           True         1          0.1     200\n",
       "4    albert      fiction           True         1          0.5     200\n",
       "5    albert      fiction           True         1          1.0     200\n",
       "6    albert         wiki           True         1          0.1     200\n",
       "7    albert         wiki           True         1          0.5     200\n",
       "8    albert         wiki           True         1          1.0     200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read local `config.toml` file.\n",
    "config = get_experiments('ALBERT_FINETUNE_SIMPLE')\n",
    "config_df = pd.DataFrame.from_dict(config)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e7f80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df.to_csv(r'../models/experiment.csv', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a65dfad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcebcc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for experiment in config:\n",
    "    bert_type = config['bert_type']\n",
    "    dataset_type = config['dataset_type']\n",
    "    finetune_bert = config['finetune_bert']\n",
    "    pct_data = config['pct_data']\n",
    "    augment_pct = config['augment_pct']\n",
    "    epochs = config['epochs']\n",
    "    print(\"params:\", bert_type, dataset_type, finetune_bert, pct_data, augment_pct, epochs)\n",
    "    \n",
    "    # init model\n",
    "    print(\"initializing model...\")\n",
    "    model = ContextEncoder(final_dropout=0.5,\n",
    "                           dense_neurons=64,\n",
    "                           bert_trainable=finetune_bert,\n",
    "                           bert_type=\"albert-base-v2\")\n",
    "    \n",
    "    # init dataset\n",
    "    print(\"initializing dataset...\")\n",
    "    dataset = AlbertDataset(dataset_type=dataset_type,\n",
    "                           pct_data=pct_data,\n",
    "                           max_segment_length=5,\n",
    "                           augment_pct=augment_pct)\n",
    "    \n",
    "    # process dataset\n",
    "    print(\"processing dataset...\")\n",
    "    sentences, tokenized_sentences, labels = dataset.process()\n",
    "    \n",
    "    # create checkpoint path\n",
    "    checkpoint_filepath = '../models/ALBERT/finetune/simple/{}-{}-{}-pct-{}-aug/checkpoint'.format(\n",
    "                            dataset_type,                    \n",
    "                            len(sentences), \n",
    "                            pct_data,\n",
    "                            augment_pct)\n",
    "    print(checkpoint_filepath)\n",
    "    \n",
    "    # compiling model\n",
    "    print(\"compiling the model...\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=METRICS)\n",
    "    \n",
    "    try:\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        print(\"model loaded.\")\n",
    "    except:\n",
    "        print(\"No checkpoint available.\")\n",
    "    \n",
    "    # \n",
    "    print(\"starting the training process...\")\n",
    "    history = model.fit(dataset.format_sentences_tri_input(tokenized_sentences), \n",
    "                        tf.convert_to_tensor(labels), \n",
    "                        epochs=EPOCHS,\n",
    "                        validation_split=0.1,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        verbose=1, \n",
    "                        # class_weight=class_weight,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    # assigning history to experiment object for saving.\n",
    "    experiment[\"history\"] = history\n",
    "    \n",
    "    print(\"saving results...\")\n",
    "    save_results(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323dd2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd] *",
   "language": "python",
   "name": "conda-env-phd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
